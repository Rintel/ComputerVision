{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 6: Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronal Netze benötigen oft eine große Menge an Trainingsdaten, damit es nicht zu overfitting kommt. Transfer learning erlaubt es, mit relativ geringen Datenmenge dennoch erfolgreiche große Netze zu trainieren. Dabei verwendet man ein bereits auf einen anderen Datensatz (z.b. ImageNet) vortrainiertes Netzwerk, und ersetzt nur das letzte Layer durch ein neues. In dieser Übung geht es darum, ein Netzwerk für die Erkennung von Geparden und Leoparden in der freien Wildbahn zu trainineren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Lade die Daten hier herunter: http://tonic.imp.fu-berlin.de/cv_data/data.tar.gz\n",
    "\n",
    "Die Daten wurde bereits in ein Trainings- und Validierungsset geteilt. Die Ordnerstruktur ist wie bei vielen Bildklassifierungsdatensetzen so aufgebaut. Es gibt zwei Unterordner für die Trainings- und Validierunsdaten. In diesen Ordnern liegen dann jeweils alle Bilder von einer Klasse in einem Unterordner mit dem Namen der Klasse.\n",
    "\n",
    "Ein Beispiel: Die Trainingsbilder für die Klasse \"cheetah\" liegen in dem Unterordner train/cheetah\n",
    "\n",
    "Diese Orderstruktur wird auch von dem in keras enhaltenen ImageDataGenerator unterstützt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import itertools\n",
    "from keras.backend.tensorflow_backend import set_session, get_session\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import binarize\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix',  cmap=plt.cm.Blues):\n",
    "    \n",
    "    # http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "   \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    " \n",
    "    # https://github.com/deeplizard/Keras_Jupyter_Notebooks/blob/master/CNN.ipynb\n",
    "    \n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_input_size = (112, 112)\n",
    "\n",
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17857 images belonging to 3 classes.\n",
      "Found 1915 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(data_path, 'train')\n",
    "valid_path = os.path.join(data_path, 'val')\n",
    "\n",
    "classes = ('unknown', 'cheetah', 'leopard')\n",
    "\n",
    "train_batches = ImageDataGenerator(horizontal_flip=True).flow_from_directory(\n",
    "    train_path, \n",
    "    target_size = image_input_size,\n",
    "    classes = classes,\n",
    "    batch_size = batch_size)\n",
    "\n",
    "valid_batches = ImageDataGenerator(horizontal_flip=False).flow_from_directory(\n",
    "    valid_path, \n",
    "    target_size = image_input_size,\n",
    "    classes=classes,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ohne transfer learning\n",
    "\n",
    "Trainiere zuerst ein kleines Classifer-Netzwerk ohne transfer learning. Falls du keine Grafikkarte hast, solltest du nicht die volle Auflösung (siehe Variable image_input_size) verwenden, da das Training sonst zu lange dauert. Eine Bildgröße von 32x32 Pixeln wäre zum Beispiel möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 56, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 55, 27, 256)       2560      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 55, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 53, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 51, 23, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 51, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 49, 9, 96)         55392     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 47, 7, 64)         55360     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 47, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 45, 5, 32)         18464     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                460864    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 1,484,099\n",
      "Trainable params: 1,484,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (image_input_size[0], image_input_size[1], 3)\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\", input_shape=input_shape))\n",
    "model.add(Conv2D(256, (3, 3), strides=2, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\"))                            \n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))                      \n",
    "\n",
    "model.add(Conv2D(96, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=lr),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "47/56 [========================>.....] - ETA: 43s - loss: 5.6690 - acc: 0.6263"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_batches,\n",
    "        steps_per_epoch = 1800 // batch_size,\n",
    "        epochs = 2,\n",
    "        validation_data = valid_batches,\n",
    "        validation_steps = 250 // batch_size)\n",
    "\n",
    "model.load_weights('models/weights-8449.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle eine Confusion matrix basierend auf den Ausgaben des Netzes für die Validierungsdaten und berechne den ROC AUC für die Klasse cheetah. Du kannst hierfür optional die scikit-learn Bibliothek verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(valid_batches)\n",
    "\n",
    "valid_labels = valid_batches.classes\n",
    "\n",
    "cm = confusion_matrix(valid_labels, predictions.argmax(axis = 1))\n",
    "\n",
    "plot_confusion_matrix(cm, classes, title=\"Confusion Matrix\")\n",
    "\n",
    "valid_labels_auc = np.copy(valid_labels) #if cheetah, set true (1)\n",
    "np.place(valid_labels_auc, valid_labels_auc == 2, 0)\n",
    "\n",
    "roc_score = roc_auc_score(valid_labels_auc, predictions[:,1])\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network\n",
    "\n",
    "Lade nun ein auf Imagenet vortrainiertes Netzwerk und klassifiziere damit die Validierungsdaten. Eine Anleitung für keras findest du hier: https://keras.io/applications\n",
    "\n",
    "Du kannst selber entscheiden, welche Netzwerkarchitektur du verwendest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights = 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der ImageNet-Datensatz auch die Klassen cheetah und leopard enthält, können wir sogar ohne transfer learning das vortrainierte Netzwerk evaluieren. Interpretiere alle Klassen außer cheetah und leopard als unknown und berechne wie im vorherigen Schritt die Confusion matrix und den ROC AUC score für die Klasse cheetah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = model.predict_generator(valid_batches)\n",
    "\n",
    "valid_labels = valid_batches.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "Das vortrainierte Netzwerk kann nun mit unseren Daten weitertrainiert werden. Ersetze dafür das letzte Layer in dem Netzwerk mit einem Dense Layer mit 3 Ausgaben für unsere Klassen cheetah, leopard und unknown. Du kannst selbst entscheiden, ob du nun das komplette Netzwerk mit trainierst oder nur das neu eingefügte, letzte Layer.\n",
    "\n",
    "Auch hierfür kannst du dich wieder an der keras Anleitung orientieren: https://keras.io/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers:\n",
    "    custom_layer = layer\n",
    "    custom_layer.trainable = False\n",
    "    custom_model.add(custom_layer)\n",
    "    \n",
    "custom_model.layers.pop()\n",
    "custom_model.add(Dense(3, activation=\"softmax\"))\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluiere das so trainierte Netzwerk wie in den letzten beiden Aufgaben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung\n",
    "\n",
    "Beschreibe kurz qualitativ die Resultate. Wie unterscheiden sich die trainierten Netzwerke, zum Beispiel im Bezug auf die Genauigkeit oder die Laufzeit? Welche Entscheidungen musstest du bei der Erfüllung der Aufgaben treffen und warum hast du dich für den von dir gewählten Weg entschieden?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
