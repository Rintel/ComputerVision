{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 6: Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronal Netze benötigen oft eine große Menge an Trainingsdaten, damit es nicht zu overfitting kommt. Transfer learning erlaubt es, mit relativ geringen Datenmenge dennoch erfolgreiche große Netze zu trainieren. Dabei verwendet man ein bereits auf einen anderen Datensatz (z.b. ImageNet) vortrainiertes Netzwerk, und ersetzt nur das letzte Layer durch ein neues. In dieser Übung geht es darum, ein Netzwerk für die Erkennung von Geparden und Leoparden in der freien Wildbahn zu trainineren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Lade die Daten hier herunter: http://tonic.imp.fu-berlin.de/cv_data/data.tar.gz\n",
    "\n",
    "Die Daten wurde bereits in ein Trainings- und Validierungsset geteilt. Die Ordnerstruktur ist wie bei vielen Bildklassifierungsdatensetzen so aufgebaut. Es gibt zwei Unterordner für die Trainings- und Validierunsdaten. In diesen Ordnern liegen dann jeweils alle Bilder von einer Klasse in einem Unterordner mit dem Namen der Klasse.\n",
    "\n",
    "Ein Beispiel: Die Trainingsbilder für die Klasse \"cheetah\" liegen in dem Unterordner train/cheetah\n",
    "\n",
    "Diese Orderstruktur wird auch von dem in keras enhaltenen ImageDataGenerator unterstützt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import pathlib\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session, get_session\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "#from keras.applications.inception_v3 import InceptionV3, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config = config))\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_input_size = (224, 224)\n",
    "data_path = './data/'\n",
    "\n",
    "prob_drop_conv = 0.5              \n",
    "pool_size = (2, 2) \n",
    "nb_epoch = 150\n",
    "\n",
    "opt = optimizers.RMSprop(lr = 0.000001, rho = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17857 images belonging to 3 classes.\n",
      "Found 1915 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join(data_path, 'train')\n",
    "val_data_path = os.path.join(data_path, 'val')\n",
    "\n",
    "classes = ('unknown', 'cheetah', 'leopard')\n",
    "\n",
    "train_gen = ImageDataGenerator(horizontal_flip=True).flow_from_directory(\n",
    "    train_data_path, \n",
    "    target_size = image_input_size,\n",
    "    classes = classes,\n",
    "    batch_size = batch_size)\n",
    "\n",
    "val_gen = ImageDataGenerator(horizontal_flip=False).flow_from_directory(\n",
    "    val_data_path, \n",
    "    target_size = image_input_size,\n",
    "    classes = classes,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ohne transfer learning\n",
    "\n",
    "Trainiere zuerst ein kleines Classifer-Netzwerk ohne transfer learning. Falls du keine Grafikkarte hast, solltest du nicht die volle Auflösung (siehe Variable image_input_size) verwenden, da das Training sonst zu lange dauert. Eine Bildgröße von 32x32 Pixeln wäre zum Beispiel möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONV MODEL\n",
    "model = Sequential()\n",
    "steps_per_epoch=len(pool_size)/batch_size\n",
    "\n",
    "# FIRST CONV LAYER\n",
    "model.add(Convolution2D(8, 3, 3, border_mode = 'same', activation = 'relu', input_shape = [224,224,3]))\n",
    "model.add(MaxPooling2D(pool_size = pool_size, strides=(2,2), border_mode = 'same'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# SECOND CONV LAYER\n",
    "model.add(Convolution2D(16, 3, 3, border_mode = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size, strides = (2,2), border_mode = 'same'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# THIRD CONV LAYER\n",
    "model.add(Convolution2D(4, 3, 3, border_mode = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size, strides = (2,2), border_mode = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# FIRST FC LAYER\n",
    "model.add(Dense(625, activation = 'relu'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# SECOND FC LAYER\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit_generator(train_gen,steps_per_epoch, nb_epoch = nb_epoch, shuffle = False, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluation = model.evaluate_generator(val_gen, 1)\n",
    "\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle eine Confusion matrix basierend auf den Ausgaben des Netzes für die Validierungsdaten und berechne den ROC AUC für die Klasse cheetah. Du kannst hierfür optional die scikit-learn Bibliothek verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_test_samples = 1915\n",
    "\n",
    "Y_pred = model.predict_generator(val_gen, num_of_test_samples // batch_size + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "conf_matrix = confusion_matrix(val_gen.classes, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(val_gen.classes, y_pred, target_names=['unknown', 'cheetah', 'leopard']))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('ROC AUC Score')\n",
    "#print(sklearn.metrics.roc_auc_score(y_true, y_score))\n",
    "0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network\n",
    "\n",
    "Lade nun ein auf Imagenet vortrainiertes Netzwerk und klassifiziere damit die Validierungsdaten. Eine Anleitung für keras findest du hier: https://keras.io/applications\n",
    "\n",
    "Du kannst selber entscheiden, welche Netzwerkarchitektur du verwendest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(weights='imagenet')\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der ImageNet-Datensatz auch die Klassen cheetah und leopard enthält, können wir sogar ohne transfer learning das vortrainierte Netzwerk evaluieren. Interpretiere alle Klassen außer cheetah und leopard als unknown und berechne wie im vorherigen Schritt die Confusion matrix und den ROC AUC score für die Klasse cheetah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_predictions = vgg16_model.predict_generator(val_gen, steps=len(val_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1915,) (1915, 1000)\n"
     ]
    }
   ],
   "source": [
    "valid_labels = val_gen.classes\n",
    "print(valid_labels.shape, vgg_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('unknown', 'cheetah', 'leopard')\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_predictions = vgg_predictions.argmax(axis = 1)\n",
    "\n",
    "# replace all unknown classes with a zero\n",
    "np.place(vgg16_predictions, vgg16_predictions == 1, 0)\n",
    "np.place(vgg16_predictions, vgg16_predictions == 2, 0)\n",
    "np.place(vgg16_predictions, vgg16_predictions == 293, 1)\n",
    "np.place(vgg16_predictions, vgg16_predictions == 288, 2)\n",
    "np.place(vgg16_predictions, vgg16_predictions > 2, 0)\n",
    "\n",
    "# Matrix\n",
    "vgg_conf_matrix = confusion_matrix(valid_labels, vgg16_predictions)\n",
    "\n",
    "\n",
    "# ROC AUC Score\n",
    "valid_labels_auc_value = np.copy(valid_labels)\n",
    "roc_curve_predictions = np.copy(vgg_predictions)\n",
    "\n",
    "np.place(valid_labels_auc_value, valid_labels_auc_value == 2, 0)\n",
    "\n",
    "roc_score = roc_auc_score(valid_labels_auc_value, roc_curve_predictions[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 352    9    3]\n",
      " [1205  228    7]\n",
      " [  84   25    2]]\n",
      "\n",
      "ROC AUC Score\n",
      "0.4237616959064327\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(vgg_conf_matrix)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('ROC AUC Score')\n",
    "print(roc_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "Das vortrainierte Netzwerk kann nun mit unseren Daten weitertrainiert werden. Ersetze dafür das letzte Layer in dem Netzwerk mit einem Dense Layer mit 3 Ausgaben für unsere Klassen cheetah, leopard und unknown. Du kannst selbst entscheiden, ob du nun das komplette Netzwerk mit trainierst oder nur das neu eingefügte, letzte Layer.\n",
    "\n",
    "Auch hierfür kannst du dich wieder an der keras Anleitung orientieren: https://keras.io/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3003      \n",
      "=================================================================\n",
      "Total params: 138,360,547\n",
      "Trainable params: 3,003\n",
      "Non-trainable params: 138,357,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model = Sequential()\n",
    "for layer in vgg16_model.layers:\n",
    "    custom_layer = layer\n",
    "    custom_layer.trainable = False\n",
    "    custom_model.add(custom_layer)\n",
    "    \n",
    "custom_model.layers.pop()\n",
    "custom_model.add(Dense(3, activation = \"softmax\"))\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1210 21:58:14.361592 4661394880 deprecation_wrapper.py:119] From /Users/ced/miniconda3/envs/PythonCPU/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizers.Adam(lr = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3003      \n",
      "=================================================================\n",
      "Total params: 138,360,547\n",
      "Trainable params: 3,003\n",
      "Non-trainable params: 138,357,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1210 21:59:12.251341 4661394880 deprecation.py:323] From /Users/ced/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 269s 5s/step - loss: 1.0715 - acc: 0.5725 - val_loss: 1.0049 - val_acc: 0.9375\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 263s 5s/step - loss: 1.0123 - acc: 0.6540 - val_loss: 0.9036 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 274s 5s/step - loss: 0.9654 - acc: 0.6490 - val_loss: 0.8157 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 254s 5s/step - loss: 0.9308 - acc: 0.6378 - val_loss: 0.7489 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 251s 4s/step - loss: 0.9009 - acc: 0.6406 - val_loss: 0.6834 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.8704 - acc: 0.6562 - val_loss: 0.6414 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 250s 4s/step - loss: 0.8443 - acc: 0.6557 - val_loss: 1.1461 - val_acc: 0.4932\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 250s 4s/step - loss: 0.8243 - acc: 0.6663 - val_loss: 1.1827 - val_acc: 0.0089\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 250s 4s/step - loss: 0.8042 - acc: 0.6624 - val_loss: 0.9212 - val_acc: 0.3929\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 246s 4s/step - loss: 0.7797 - acc: 0.6919 - val_loss: 0.4988 - val_acc: 0.9866\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.7899 - acc: 0.6763 - val_loss: 0.5411 - val_acc: 0.9643\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 251s 4s/step - loss: 0.7662 - acc: 0.6875 - val_loss: 0.4703 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.7757 - acc: 0.6847 - val_loss: 0.4460 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 254s 5s/step - loss: 0.7644 - acc: 0.6992 - val_loss: 0.4194 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 253s 5s/step - loss: 0.7672 - acc: 0.6975 - val_loss: 0.4214 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 251s 4s/step - loss: 0.7477 - acc: 0.7132 - val_loss: 1.6297 - val_acc: 0.1187\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.7171 - acc: 0.7321 - val_loss: 1.0949 - val_acc: 0.1830\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.7000 - acc: 0.7316 - val_loss: 0.5245 - val_acc: 0.8348\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.7289 - acc: 0.7137 - val_loss: 0.4158 - val_acc: 0.9464\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 247s 4s/step - loss: 0.6970 - acc: 0.7404 - val_loss: 0.4062 - val_acc: 0.9688\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 253s 5s/step - loss: 0.7092 - acc: 0.7327 - val_loss: 0.4033 - val_acc: 0.9866\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 253s 5s/step - loss: 0.7192 - acc: 0.7310 - val_loss: 0.3709 - val_acc: 0.9911\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.7065 - acc: 0.7193 - val_loss: 0.3362 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.7013 - acc: 0.7310 - val_loss: 1.1371 - val_acc: 0.6250\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 251s 4s/step - loss: 0.6799 - acc: 0.7467 - val_loss: 1.1658 - val_acc: 0.2511\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6878 - acc: 0.7388 - val_loss: 0.8392 - val_acc: 0.4911\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 253s 5s/step - loss: 0.6845 - acc: 0.7344 - val_loss: 0.3491 - val_acc: 0.9866\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6932 - acc: 0.7422 - val_loss: 0.4640 - val_acc: 0.8839\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 254s 5s/step - loss: 0.6915 - acc: 0.7355 - val_loss: 0.3694 - val_acc: 0.9554\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 248s 4s/step - loss: 0.6736 - acc: 0.7633 - val_loss: 0.3458 - val_acc: 0.9866\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 253s 5s/step - loss: 0.7027 - acc: 0.7243 - val_loss: 0.3395 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6558 - acc: 0.7561 - val_loss: 0.2878 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 251s 4s/step - loss: 0.6790 - acc: 0.7344 - val_loss: 1.6479 - val_acc: 0.2557\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6765 - acc: 0.7439 - val_loss: 0.8550 - val_acc: 0.4554\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.6561 - acc: 0.7539 - val_loss: 0.5924 - val_acc: 0.7366\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 253s 5s/step - loss: 0.6664 - acc: 0.7411 - val_loss: 0.3405 - val_acc: 0.9464\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 254s 5s/step - loss: 0.6577 - acc: 0.7550 - val_loss: 0.4009 - val_acc: 0.9018\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6502 - acc: 0.7573 - val_loss: 0.3731 - val_acc: 0.9509\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6569 - acc: 0.7433 - val_loss: 0.3263 - val_acc: 0.9866\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 249s 4s/step - loss: 0.6303 - acc: 0.7672 - val_loss: 0.2824 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6566 - acc: 0.7400 - val_loss: 0.8286 - val_acc: 0.7679\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.6169 - acc: 0.7640 - val_loss: 1.2947 - val_acc: 0.3379\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.6596 - acc: 0.7450 - val_loss: 0.8663 - val_acc: 0.4420\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6385 - acc: 0.7673 - val_loss: 0.2930 - val_acc: 0.9821\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6531 - acc: 0.7416 - val_loss: 0.4144 - val_acc: 0.9018\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.6484 - acc: 0.7506 - val_loss: 0.3708 - val_acc: 0.9062\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 252s 4s/step - loss: 0.6454 - acc: 0.7511 - val_loss: 0.3408 - val_acc: 0.9643\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6380 - acc: 0.7567 - val_loss: 0.3104 - val_acc: 0.9866\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 252s 5s/step - loss: 0.6222 - acc: 0.7612 - val_loss: 0.2419 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 248s 4s/step - loss: 0.6348 - acc: 0.7555 - val_loss: 1.5791 - val_acc: 0.3836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a302d3090>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch = 1800 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data = val_gen,\n",
    "        validation_steps = 250 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Model-Weights saved!\n"
     ]
    }
   ],
   "source": [
    "custom_model.save('models/custom-model.h5')\n",
    "print('Model saved!')\n",
    "custom_model.save_weights('models/custom-model-weights.h5')\n",
    "print('Model-Weights saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_model.load_weights('models/custom-model-weights.h5')\n",
    "#print(Model-Weights loaded!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluiere das so trainierte Netzwerk wie in den letzten beiden Aufgaben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('unknown', 'cheetah', 'leopard')\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_predictions = custom_model.predict_generator(val_gen, steps=len(val_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels_2 = val_gen.classes\n",
    "\n",
    "# ROC AUC Score\n",
    "# set all cheetahs to 1, all other to zero:\n",
    "valid_labels_auc_vaule_2 = np.copy(valid_labels_2)\n",
    "roc_curve_predictions_2 = np.copy(custom_model_predictions)\n",
    "np.place(valid_labels_auc_vaule_2, valid_labels_auc_vaule_2 == 2, 0)\n",
    "\n",
    "roc_score_2 = roc_auc_score(valid_labels_auc_vaule_2, roc_curve_predictions_2[:, 1])\n",
    "\n",
    "custom_model_predictions = custom_model_predictions.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[   0  364    0]\n",
      " [ 233 1207    0]\n",
      " [   0  111    0]]\n",
      "\n",
      "ROC AUC Score\n",
      "0.34604970760233916\n"
     ]
    }
   ],
   "source": [
    "custom_model_conf_matrix = confusion_matrix(valid_labels_2, custom_model_predictions)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(custom_model_conf_matrix)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('ROC AUC Score')\n",
    "print(roc_score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung\n",
    "\n",
    "Beschreibe kurz qualitativ die Resultate. Wie unterscheiden sich die trainierten Netzwerke, zum Beispiel im Bezug auf die Genauigkeit oder die Laufzeit? Welche Entscheidungen musstest du bei der Erfüllung der Aufgaben treffen und warum hast du dich für den von dir gewählten Weg entschieden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
