{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 6: Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronal Netze benötigen oft eine große Menge an Trainingsdaten, damit es nicht zu overfitting kommt. Transfer learning erlaubt es, mit relativ geringen Datenmenge dennoch erfolgreiche große Netze zu trainieren. Dabei verwendet man ein bereits auf einen anderen Datensatz (z.b. ImageNet) vortrainiertes Netzwerk, und ersetzt nur das letzte Layer durch ein neues. In dieser Übung geht es darum, ein Netzwerk für die Erkennung von Geparden und Leoparden in der freien Wildbahn zu trainineren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Lade die Daten hier herunter: http://tonic.imp.fu-berlin.de/cv_data/data.tar.gz\n",
    "\n",
    "Die Daten wurde bereits in ein Trainings- und Validierungsset geteilt. Die Ordnerstruktur ist wie bei vielen Bildklassifierungsdatensetzen so aufgebaut. Es gibt zwei Unterordner für die Trainings- und Validierunsdaten. In diesen Ordnern liegen dann jeweils alle Bilder von einer Klasse in einem Unterordner mit dem Namen der Klasse.\n",
    "\n",
    "Ein Beispiel: Die Trainingsbilder für die Klasse \"cheetah\" liegen in dem Unterordner train/cheetah\n",
    "\n",
    "Diese Orderstruktur wird auch von dem in keras enhaltenen ImageDataGenerator unterstützt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session, get_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "from keras import optimizers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Hi Tim, vorrangig aus GPU-Gründen haben wir die Jan(n)is-Gruppe bei dieser Übung als auch bei den nächsten beiden mit ins Boot geholt.\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"Hi Tim, vorrangig aus GPU-Gründen haben wir die Jan(n)is-Gruppe bei dieser Übung als auch bei den nächsten beiden mit ins Boot geholt.\")\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_input_size = (224, 224)\n",
    "data_path = './data/'\n",
    "\n",
    "prob_drop_conv = 0.5              \n",
    "pool_size = (2, 2) \n",
    "nb_epoch = 150\n",
    "opt = optimizers.RMSprop(lr=0.000001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17857 images belonging to 3 classes.\n",
      "Found 1915 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join(data_path, 'train')\n",
    "val_data_path = os.path.join(data_path, 'val')\n",
    "\n",
    "izw_classes = ('unknown', 'cheetah', 'leopard')\n",
    "\n",
    "generator = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True)\n",
    "val_generator = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=False)\n",
    "\n",
    "train_gen = generator.flow_from_directory(\n",
    "    train_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_gen = val_generator.flow_from_directory(\n",
    "    val_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ohne transfer learning\n",
    "\n",
    "Trainiere zuerst ein kleines Classifer-Netzwerk ohne transfer learning. Falls du keine Grafikkarte hast, solltest du nicht die volle Auflösung (siehe Variable image_input_size) verwenden, da das Training sonst zu lange dauert. Eine Bildgröße von 32x32 Pixeln wäre zum Beispiel möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 17:07:03.143175 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=[224, 224,..., padding=\"same\")`\n",
      "  \n",
      "W0815 17:07:03.145573 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0815 17:07:03.149528 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "W0815 17:07:03.163352 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0815 17:07:03.165059 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0815 17:07:03.171863 4509324736 deprecation.py:506] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")`\n",
      "  \n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")`\n",
      "W0815 17:07:03.323299 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0815 17:07:03.327963 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/Users/ced/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., 0.0625, shuffle=True, verbose=1, epochs=150)`\n",
      "W0815 17:07:03.403031 4509324736 deprecation.py:323] From /Users/ced/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 4)         580       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 625)               1960625   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 1,964,475\n",
      "Trainable params: 1,964,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 980ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 2/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 287ms/step - loss: 13.4922 - acc: 0.1562\n",
      "Epoch 3/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 278ms/step - loss: 13.3631 - acc: 0.1562\n",
      "Epoch 4/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 259ms/step - loss: 14.1320 - acc: 0.0938\n",
      "Epoch 5/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 261ms/step - loss: 13.8359 - acc: 0.1250\n",
      "Epoch 6/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 281ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 7/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 341ms/step - loss: 13.4686 - acc: 0.1562\n",
      "Epoch 8/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 364ms/step - loss: 15.0274 - acc: 0.0625\n",
      "Epoch 9/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 357ms/step - loss: 13.0963 - acc: 0.1875\n",
      "Epoch 10/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 359ms/step - loss: 13.5997 - acc: 0.1562\n",
      "Epoch 11/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 321ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 12/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 377ms/step - loss: 14.3875 - acc: 0.0938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 341ms/step - loss: 15.1107 - acc: 0.0625\n",
      "Epoch 14/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 335ms/step - loss: 12.9356 - acc: 0.1875\n",
      "Epoch 15/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 378ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 16/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 342ms/step - loss: 15.1107 - acc: 0.0625\n",
      "Epoch 17/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 373ms/step - loss: 12.5772 - acc: 0.2188\n",
      "Epoch 18/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 379ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 19/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 376ms/step - loss: 11.0818 - acc: 0.3125\n",
      "Epoch 20/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 366ms/step - loss: 13.1010 - acc: 0.1875\n",
      "Epoch 21/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 370ms/step - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 22/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 421ms/step - loss: 15.0775 - acc: 0.0625\n",
      "Epoch 23/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 383ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 24/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 354ms/step - loss: 12.1865 - acc: 0.2188\n",
      "Epoch 25/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 304ms/step - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 26/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 388ms/step - loss: 12.2862 - acc: 0.2188\n",
      "Epoch 27/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 367ms/step - loss: 12.7642 - acc: 0.1875\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 372ms/step - loss: 13.6082 - acc: 0.1562\n",
      "Epoch 29/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 350ms/step - loss: 13.1960 - acc: 0.1562\n",
      "Epoch 30/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 319ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 31/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 354ms/step - loss: 11.5446 - acc: 0.2500\n",
      "Epoch 32/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 484ms/step - loss: 13.3180 - acc: 0.1250\n",
      "Epoch 33/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 419ms/step - loss: 11.5849 - acc: 0.2812\n",
      "Epoch 34/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 394ms/step - loss: 13.3768 - acc: 0.1562\n",
      "Epoch 35/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 376ms/step - loss: 13.5080 - acc: 0.1562\n",
      "Epoch 36/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 391ms/step - loss: 10.9600 - acc: 0.3125\n",
      "Epoch 37/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 384ms/step - loss: 13.6126 - acc: 0.1562\n",
      "Epoch 38/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 386ms/step - loss: 13.2554 - acc: 0.1562\n",
      "Epoch 39/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 396ms/step - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 40/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 392ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 41/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 344ms/step - loss: 12.5924 - acc: 0.2188\n",
      "Epoch 42/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 375ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 43/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 363ms/step - loss: 12.9041 - acc: 0.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 349ms/step - loss: 14.5927 - acc: 0.0938\n",
      "Epoch 45/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 374ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 46/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 363ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 47/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 354ms/step - loss: 13.3955 - acc: 0.1562\n",
      "Epoch 48/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 349ms/step - loss: 13.5440 - acc: 0.0938\n",
      "Epoch 49/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 362ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 50/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 380ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 51/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 395ms/step - loss: 13.1037 - acc: 0.1562\n",
      "Epoch 52/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 364ms/step - loss: 11.4359 - acc: 0.2812\n",
      "Epoch 53/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 347ms/step - loss: 11.8066 - acc: 0.2500\n",
      "Epoch 54/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 413ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 55/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 376ms/step - loss: 12.6281 - acc: 0.1875\n",
      "Epoch 56/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 383ms/step - loss: 12.4570 - acc: 0.2188\n",
      "Epoch 57/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 371ms/step - loss: 13.5067 - acc: 0.1250\n",
      "Epoch 58/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 348ms/step - loss: 14.0331 - acc: 0.1250\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 335ms/step - loss: 13.2453 - acc: 0.1562\n",
      "Epoch 60/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 379ms/step - loss: 11.0812 - acc: 0.3125\n",
      "Epoch 61/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 330ms/step - loss: 11.9956 - acc: 0.2188\n",
      "Epoch 62/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 386ms/step - loss: 10.8160 - acc: 0.3125\n",
      "Epoch 63/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 365ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 64/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 382ms/step - loss: 14.6070 - acc: 0.0938\n",
      "Epoch 65/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 355ms/step - loss: 14.4854 - acc: 0.0938\n",
      "Epoch 66/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 400ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 67/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 347ms/step - loss: 14.1033 - acc: 0.1250\n",
      "Epoch 68/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 369ms/step - loss: 14.6077 - acc: 0.0938\n",
      "Epoch 69/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 370ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 70/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 334ms/step - loss: 13.0675 - acc: 0.1875\n",
      "Epoch 71/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 333ms/step - loss: 11.0941 - acc: 0.3125\n",
      "Epoch 72/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 395ms/step - loss: 14.6070 - acc: 0.0938\n",
      "Epoch 73/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 366ms/step - loss: 14.1033 - acc: 0.1250\n",
      "Epoch 74/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 347ms/step - loss: 12.7665 - acc: 0.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 323ms/step - loss: 14.1033 - acc: 0.1250\n",
      "Epoch 76/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 456ms/step - loss: 12.5303 - acc: 0.2188\n",
      "Epoch 77/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 490ms/step - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 78/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 503ms/step - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 79/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 408ms/step - loss: 9.0903 - acc: 0.4062\n",
      "Epoch 80/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 458ms/step - loss: 12.9649 - acc: 0.1562\n",
      "Epoch 81/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 424ms/step - loss: 11.5859 - acc: 0.2812\n",
      "Epoch 82/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 454ms/step - loss: 12.9226 - acc: 0.1875\n",
      "Epoch 83/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 407ms/step - loss: 11.5849 - acc: 0.2812\n",
      "Epoch 84/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 414ms/step - loss: 12.5935 - acc: 0.2188\n",
      "Epoch 85/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 465ms/step - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 86/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 458ms/step - loss: 12.5923 - acc: 0.2188\n",
      "Epoch 87/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 460ms/step - loss: 12.6962 - acc: 0.1875\n",
      "Epoch 88/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 470ms/step - loss: 14.1033 - acc: 0.1250\n",
      "Epoch 89/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 414ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 511ms/step - loss: 11.5315 - acc: 0.2500\n",
      "Epoch 91/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 586ms/step - loss: 13.6591 - acc: 0.1250\n",
      "Epoch 92/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 464ms/step - loss: 12.3529 - acc: 0.2188\n",
      "Epoch 93/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 414ms/step - loss: 11.0072 - acc: 0.3125\n",
      "Epoch 94/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 350ms/step - loss: 11.5011 - acc: 0.2500\n",
      "Epoch 95/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 381ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 96/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 376ms/step - loss: 13.7395 - acc: 0.0938\n",
      "Epoch 97/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 369ms/step - loss: 15.1107 - acc: 0.0625\n",
      "Epoch 98/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 333ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 99/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 387ms/step - loss: 11.0812 - acc: 0.3125\n",
      "Epoch 100/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 342ms/step - loss: 12.0915 - acc: 0.2500\n",
      "Epoch 101/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 375ms/step - loss: 14.6070 - acc: 0.0938\n",
      "Epoch 102/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 365ms/step - loss: 11.0814 - acc: 0.3125\n",
      "Epoch 103/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 330ms/step - loss: 15.3551 - acc: 0.0312\n",
      "Epoch 104/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 354ms/step - loss: 12.0657 - acc: 0.2500\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 338ms/step - loss: 11.5966 - acc: 0.2500\n",
      "Epoch 106/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 382ms/step - loss: 9.3096 - acc: 0.3750\n",
      "Epoch 107/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 330ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 108/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 385ms/step - loss: 11.5069 - acc: 0.2500\n",
      "Epoch 109/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 349ms/step - loss: 11.2147 - acc: 0.2812\n",
      "Epoch 110/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 357ms/step - loss: 9.8867 - acc: 0.3750\n",
      "Epoch 111/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 409ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 112/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 329ms/step - loss: 12.4112 - acc: 0.1875\n",
      "Epoch 113/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 356ms/step - loss: 14.1033 - acc: 0.1250\n",
      "Epoch 114/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 361ms/step - loss: 12.6822 - acc: 0.1562\n",
      "Epoch 115/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 362ms/step - loss: 13.7337 - acc: 0.1250\n",
      "Epoch 116/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 336ms/step - loss: 12.5761 - acc: 0.2188\n",
      "Epoch 117/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 371ms/step - loss: 13.2257 - acc: 0.0938\n",
      "Epoch 118/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 361ms/step - loss: 14.6070 - acc: 0.0938\n",
      "Epoch 119/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 293ms/step - loss: 12.6879 - acc: 0.1875\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 353ms/step - loss: 13.6014 - acc: 0.1562\n",
      "Epoch 121/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 388ms/step - loss: 11.5862 - acc: 0.2812\n",
      "Epoch 122/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 370ms/step - loss: 13.3623 - acc: 0.1250\n",
      "Epoch 123/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 394ms/step - loss: 12.8125 - acc: 0.1875\n",
      "Epoch 124/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 380ms/step - loss: 13.2985 - acc: 0.1562\n",
      "Epoch 125/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 378ms/step - loss: 12.1553 - acc: 0.2188\n",
      "Epoch 126/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 385ms/step - loss: 10.5876 - acc: 0.3438\n",
      "Epoch 127/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 341ms/step - loss: 14.6070 - acc: 0.0938\n",
      "Epoch 128/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 325ms/step - loss: 12.7155 - acc: 0.1562\n",
      "Epoch 129/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 381ms/step - loss: 13.0960 - acc: 0.1875\n",
      "Epoch 130/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 355ms/step - loss: 10.3517 - acc: 0.3438\n",
      "Epoch 131/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 353ms/step - loss: 13.0961 - acc: 0.1875\n",
      "Epoch 132/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 372ms/step - loss: 12.4262 - acc: 0.2188\n",
      "Epoch 133/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 327ms/step - loss: 11.1988 - acc: 0.2812\n",
      "Epoch 134/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 394ms/step - loss: 14.6070 - acc: 0.0938\n",
      "Epoch 135/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 379ms/step - loss: 13.1521 - acc: 0.1562\n",
      "Epoch 136/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 366ms/step - loss: 10.0738 - acc: 0.3750\n",
      "Epoch 137/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 357ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 138/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 370ms/step - loss: 12.5925 - acc: 0.2188\n",
      "Epoch 139/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 393ms/step - loss: 10.9679 - acc: 0.2812\n",
      "Epoch 140/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 373ms/step - loss: 11.5860 - acc: 0.2812\n",
      "Epoch 141/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 382ms/step - loss: 9.6114 - acc: 0.3750\n",
      "Epoch 142/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 374ms/step - loss: 12.1163 - acc: 0.2188\n",
      "Epoch 143/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 373ms/step - loss: 12.4746 - acc: 0.2188\n",
      "Epoch 144/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 399ms/step - loss: 13.5996 - acc: 0.1562\n",
      "Epoch 145/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 383ms/step - loss: 10.8447 - acc: 0.2812\n",
      "Epoch 146/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 349ms/step - loss: 13.0769 - acc: 0.1875\n",
      "Epoch 147/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 383ms/step - loss: 15.0766 - acc: 0.0625\n",
      "Epoch 148/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 351ms/step - loss: 12.0887 - acc: 0.2500\n",
      "Epoch 149/150\n",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 355ms/step - loss: 15.1107 - acc: 0.0625\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/0 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 384ms/step - loss: 12.0961 - acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#das convolutional net tutorial von keras\n",
    "\n",
    "# Convolutional model\n",
    "model = Sequential()\n",
    "steps_per_epoch=len(pool_size)/batch_size\n",
    "\n",
    "# conv1 layer\n",
    "model.add(Convolution2D(8, 3, 3, border_mode='same', activation='relu', input_shape=[224,224,3]))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2), border_mode='same'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# conv2 layer\n",
    "model.add(Convolution2D(16, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2), border_mode='same'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# conv3 layer\n",
    "model.add(Convolution2D(4, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2), border_mode='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# fc1 layer\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "# fc2 layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "history = model.fit_generator(train_gen,steps_per_epoch, nb_epoch=nb_epoch, shuffle=True, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Loss over the test dataset: 14.62, Accuracy: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "#evaluation = model.evaluate_generator(val_gen, verbose=1)\n",
    "evaluation = model.evaluate_generator(val_gen, 1)\n",
    "\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstelle eine Confusion matrix basierend auf den Ausgaben des Netzes für die Validierungsdaten und berechne den ROC AUC für die Klasse cheetah. Du kannst hierfür optional die scikit-learn Bibliothek verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network\n",
    "\n",
    "Lade nun ein auf Imagenet vortrainiertes Netzwerk und klassifiziere damit die Validierungsdaten. Eine Anleitung für keras findest du hier: https://keras.io/applications\n",
    "\n",
    "Du kannst selber entscheiden, welche Netzwerkarchitektur du verwendest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0815 17:08:01.007290 4509324736 deprecation_wrapper.py:119] From /Users/ced/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = ResNet50(weights = 'imagenet')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 174s 3s/step\n"
     ]
    }
   ],
   "source": [
    "evaluation2 = model2.predict_generator(val_gen, steps=(len(val_gen)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TODO DELETE THIS\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[('n02114855', 'coyote', 0.4485118)], [('n03788365', 'mosquito_net', 0.2686611)], [('n03891251', 'park_bench', 0.10064046)], [('n04371774', 'swing', 0.22957754)], [('n02114855', 'coyote', 0.45637178)], [('n03388043', 'fountain', 0.97615653)], [('n03891251', 'park_bench', 0.113026984)], [('n02130308', 'cheetah', 0.91280824)], [('n03388043', 'fountain', 0.18641663)], [('n03388043', 'fountain', 0.96286756)], [('n03388043', 'fountain', 0.97800064)], [('n03743016', 'megalith', 0.46531516)], [('n15075141', 'toilet_tissue', 0.63400984)], [('n02130308', 'cheetah', 0.36803973)], [('n03788365', 'mosquito_net', 0.33781677)], [('n03388043', 'fountain', 0.63867)], [('n03388043', 'fountain', 0.7120134)], [('n02125311', 'cougar', 0.16781376)], [('n03388043', 'fountain', 0.2860591)], [('n09193705', 'alp', 0.24350822)], [('n02130308', 'cheetah', 0.17853816)], [('n01877812', 'wallaby', 0.428212)], [('n02130308', 'cheetah', 0.8734413)], [('n02391049', 'zebra', 0.46828696)], [('n02130308', 'cheetah', 0.9901253)], [('n04371774', 'swing', 0.15860552)], [('n03388043', 'fountain', 0.25812358)], [('n03388043', 'fountain', 0.7995078)], [('n02497673', 'Madagascar_cat', 0.8590698)], [('n03388043', 'fountain', 0.96922195)], [('n02130308', 'cheetah', 0.5669322)], [('n03388043', 'fountain', 0.21539517)], [('n03388043', 'fountain', 0.9742063)], [('n04371774', 'swing', 0.8624022)], [('n03388043', 'fountain', 0.84824264)], [('n02965783', 'car_mirror', 0.27982944)], [('n03388043', 'fountain', 0.50372356)], [('n03388043', 'fountain', 0.3379324)], [('n02105412', 'kelpie', 0.13040696)], [('n02130308', 'cheetah', 0.9422332)], [('n01855672', 'goose', 0.21248884)], [('n02130308', 'cheetah', 0.9340594)], [('n03388043', 'fountain', 0.5655494)], [('n02128925', 'jaguar', 0.37905586)], [('n02130308', 'cheetah', 0.17885485)], [('n02130308', 'cheetah', 0.93868583)], [('n03388043', 'fountain', 0.27300423)], [('n02130308', 'cheetah', 0.9113838)], [('n03498962', 'hatchet', 0.08375412)], [('n02130308', 'cheetah', 0.9979772)], [('n02130308', 'cheetah', 0.98583996)], [('n03388043', 'fountain', 0.17576833)], [('n02480855', 'gorilla', 0.07467955)], [('n03788365', 'mosquito_net', 0.88445264)], [('n02391049', 'zebra', 0.8323043)], [('n02410509', 'bison', 0.2890928)], [('n03388043', 'fountain', 0.08426755)], [('n03388043', 'fountain', 0.20591642)], [('n02130308', 'cheetah', 0.68013906)], [('n02114548', 'white_wolf', 0.40428647)], [('n02965783', 'car_mirror', 0.17723554)], [('n03388043', 'fountain', 0.5720468)], [('n03388043', 'fountain', 0.8849891)], [('n02130308', 'cheetah', 0.8978765)], [('n03388043', 'fountain', 0.52928525)], [('n03388043', 'fountain', 0.8750907)], [('n03958227', 'plastic_bag', 0.24608329)], [('n03042490', 'cliff_dwelling', 0.15751168)], [('n02410509', 'bison', 0.65539706)], [('n03388043', 'fountain', 0.95038164)], [('n03042490', 'cliff_dwelling', 0.19041564)], [('n02130308', 'cheetah', 0.36671934)], [('n01756291', 'sidewinder', 0.43752557)], [('n03388043', 'fountain', 0.69088364)], [('n03388043', 'fountain', 0.17273818)], [('n03388043', 'fountain', 0.9401031)], [('n03388043', 'fountain', 0.544642)], [('n02130308', 'cheetah', 0.26873538)], [('n02130308', 'cheetah', 0.99646497)], [('n02130308', 'cheetah', 0.30068493)], [('n02130308', 'cheetah', 0.18951732)], [('n02130308', 'cheetah', 0.48314652)], [('n03388043', 'fountain', 0.6513552)], [('n02130308', 'cheetah', 0.9955244)], [('n03388043', 'fountain', 0.43448028)], [('n02128385', 'leopard', 0.44170153)], [('n03388043', 'fountain', 0.69503754)], [('n02965783', 'car_mirror', 0.26490712)], [('n03388043', 'fountain', 0.66229516)], [('n03388043', 'fountain', 0.8716154)], [('n03388043', 'fountain', 0.8900832)], [('n02130308', 'cheetah', 0.70363945)], [('n02098286', 'West_Highland_white_terrier', 0.08118564)], [('n02130308', 'cheetah', 0.842136)], [('n03388043', 'fountain', 0.98118526)], [('n03388043', 'fountain', 0.9671561)], [('n02130308', 'cheetah', 0.27657798)], [('n03388043', 'fountain', 0.9093265)], [('n03388043', 'fountain', 0.8627345)], [('n03388043', 'fountain', 0.15254612)], [('n02130308', 'cheetah', 0.99566746)], [('n03388043', 'fountain', 0.7822586)], [('n03891251', 'park_bench', 0.332368)], [('n02130308', 'cheetah', 0.6180662)], [('n03388043', 'fountain', 0.64342374)], [('n03388043', 'fountain', 0.95780426)], [('n02410509', 'bison', 0.06358359)], [('n03788365', 'mosquito_net', 0.16614729)], [('n02130308', 'cheetah', 0.98817027)], [('n02965783', 'car_mirror', 0.36270612)], [('n03388043', 'fountain', 0.6909481)], [('n02892201', 'brass', 0.11124743)], [('n03388043', 'fountain', 0.82719713)], [('n04371774', 'swing', 0.09934311)], [('n02965783', 'car_mirror', 0.3823005)], [('n03891251', 'park_bench', 0.20658867)], [('n04589890', 'window_screen', 0.20688571)], [('n03388043', 'fountain', 0.22233868)], [('n03388043', 'fountain', 0.36211878)], [('n02130308', 'cheetah', 0.91404283)], [('n03388043', 'fountain', 0.17328684)], [('n02130308', 'cheetah', 0.9854945)], [('n04423845', 'thimble', 0.38958976)], [('n02130308', 'cheetah', 0.9137152)], [('n03388043', 'fountain', 0.33872053)], [('n03388043', 'fountain', 0.30891278)], [('n03160309', 'dam', 0.15776281)], [('n02130308', 'cheetah', 0.9748312)], [('n02107312', 'miniature_pinscher', 0.40338418)], [('n02417914', 'ibex', 0.17281748)], [('n03388043', 'fountain', 0.91531986)], [('n02130308', 'cheetah', 0.3372228)], [('n02965783', 'car_mirror', 0.2966119)], [('n03388043', 'fountain', 0.29685786)], [('n03388043', 'fountain', 0.6345985)], [('n02130308', 'cheetah', 0.80193067)], [('n02130308', 'cheetah', 0.3388494)], [('n02130308', 'cheetah', 0.94871575)], [('n03042490', 'cliff_dwelling', 0.1345378)], [('n03388043', 'fountain', 0.99032146)], [('n02130308', 'cheetah', 0.9612684)], [('n03388043', 'fountain', 0.84723204)], [('n02480855', 'gorilla', 0.1577619)], [('n03388043', 'fountain', 0.94693595)], [('n03388043', 'fountain', 0.9983339)], [('n04371774', 'swing', 0.1979082)], [('n03891251', 'park_bench', 0.72263587)], [('n03388043', 'fountain', 0.97680306)], [('n03388043', 'fountain', 0.8674678)], [('n03388043', 'fountain', 0.9330591)], [('n03042490', 'cliff_dwelling', 0.11448119)], [('n02130308', 'cheetah', 0.95007056)], [('n02130308', 'cheetah', 0.7936924)], [('n02130308', 'cheetah', 0.72003686)], [('n03388043', 'fountain', 0.72507733)], [('n02130308', 'cheetah', 0.42630067)], [('n03388043', 'fountain', 0.4813579)], [('n02094433', 'Yorkshire_terrier', 0.16299687)], [('n02793495', 'barn', 0.08154502)], [('n02130308', 'cheetah', 0.97193253)], [('n02130308', 'cheetah', 0.6784697)], [('n07248320', 'book_jacket', 0.2080608)], [('n02965783', 'car_mirror', 0.26654622)], [('n02130308', 'cheetah', 0.9083858)], [('n03388043', 'fountain', 0.9957795)], [('n02130308', 'cheetah', 0.463532)], [('n02130308', 'cheetah', 0.61389387)], [('n03388043', 'fountain', 0.8223227)], [('n03388043', 'fountain', 0.76999176)], [('n01855672', 'goose', 0.20069627)], [('n03388043', 'fountain', 0.55104315)], [('n02130308', 'cheetah', 0.84459317)], [('n02130308', 'cheetah', 0.99978906)], [('n02130308', 'cheetah', 0.90853566)], [('n03388043', 'fountain', 0.23016347)], [('n03388043', 'fountain', 0.10317724)], [('n03788365', 'mosquito_net', 0.22873986)], [('n03388043', 'fountain', 0.24585073)], [('n03958227', 'plastic_bag', 0.23734029)], [('n03388043', 'fountain', 0.7296057)], [('n03388043', 'fountain', 0.6204165)], [('n03388043', 'fountain', 0.85723585)], [('n02130308', 'cheetah', 0.9485855)], [('n03388043', 'fountain', 0.4022922)], [('n02130308', 'cheetah', 0.99725145)], [('n03388043', 'fountain', 0.68323153)], [('n03388043', 'fountain', 0.45160627)], [('n03388043', 'fountain', 0.9013916)], [('n03388043', 'fountain', 0.938639)], [('n02130308', 'cheetah', 0.14133337)], [('n03388043', 'fountain', 0.91380703)], [('n02391049', 'zebra', 0.28651562)], [('n03388043', 'fountain', 0.89541495)], [('n02130308', 'cheetah', 0.4318297)], [('n03388043', 'fountain', 0.5252564)], [('n02423022', 'gazelle', 0.10487956)], [('n02130308', 'cheetah', 0.30881703)], [('n03388043', 'fountain', 0.25616103)], [('n02130308', 'cheetah', 0.28578338)], [('n02105056', 'groenendael', 0.23671672)], [('n03891251', 'park_bench', 0.18261498)], [('n02130308', 'cheetah', 0.5133224)], [('n02130308', 'cheetah', 0.80240613)], [('n02114548', 'white_wolf', 0.7770068)], [('n02130308', 'cheetah', 0.7640214)], [('n03388043', 'fountain', 0.9017075)], [('n03532672', 'hook', 0.18507257)], [('n02130308', 'cheetah', 0.99221873)], [('n04371774', 'swing', 0.18503106)], [('n03042490', 'cliff_dwelling', 0.3854978)], [('n03788365', 'mosquito_net', 0.22940461)], [('n02130308', 'cheetah', 0.99559)], [('n02115641', 'dingo', 0.12621173)], [('n02130308', 'cheetah', 0.7617955)], [('n03388043', 'fountain', 0.92312187)], [('n02114367', 'timber_wolf', 0.46315384)], [('n04589890', 'window_screen', 0.2863952)], [('n02130308', 'cheetah', 0.5576128)], [('n02130308', 'cheetah', 0.7790939)], [('n02130308', 'cheetah', 0.97439843)], [('n03388043', 'fountain', 0.7333551)], [('n02130308', 'cheetah', 0.81605065)], [('n03891251', 'park_bench', 0.42224059)], [('n03388043', 'fountain', 0.612895)], [('n02977058', 'cash_machine', 0.07682405)], [('n03388043', 'fountain', 0.9771757)], [('n03891251', 'park_bench', 0.20562261)], [('n02130308', 'cheetah', 0.6616896)], [('n02504458', 'African_elephant', 0.67548203)], [('n03388043', 'fountain', 0.92871296)], [('n03788365', 'mosquito_net', 0.24731992)], [('n03042490', 'cliff_dwelling', 0.08003061)], [('n03388043', 'fountain', 0.91705644)], [('n07248320', 'book_jacket', 0.23245484)], [('n03388043', 'fountain', 0.87670654)], [('n03891251', 'park_bench', 0.2627497)], [('n03388043', 'fountain', 0.29158902)], [('n02965783', 'car_mirror', 0.5053253)], [('n03388043', 'fountain', 0.2014017)], [('n02114367', 'timber_wolf', 0.43000174)], [('n02130308', 'cheetah', 0.9265043)], [('n02114855', 'coyote', 0.6961738)], [('n03388043', 'fountain', 0.1551674)], [('n03388043', 'fountain', 0.9958192)], [('n03388043', 'fountain', 0.1935196)], [('n03891251', 'park_bench', 0.3391802)], [('n04371774', 'swing', 0.20380285)], [('n02130308', 'cheetah', 0.6258601)], [('n03388043', 'fountain', 0.7987057)], [('n03042490', 'cliff_dwelling', 0.17992528)], [('n02130308', 'cheetah', 0.8096468)], [('n01698640', 'American_alligator', 0.07592856)], [('n02130308', 'cheetah', 0.94958425)], [('n02403003', 'ox', 0.33336583)], [('n03388043', 'fountain', 0.97494954)], [('n03891251', 'park_bench', 0.25069743)], [('n03388043', 'fountain', 0.9930647)], [('n03388043', 'fountain', 0.74524957)], [('n02437616', 'llama', 0.5392128)], [('n03891251', 'park_bench', 0.15817907)], [('n03788365', 'mosquito_net', 0.4843419)], [('n03388043', 'fountain', 0.74502194)], [('n04589890', 'window_screen', 0.08674977)], [('n03388043', 'fountain', 0.55838597)], [('n02130308', 'cheetah', 0.9754916)], [('n02130308', 'cheetah', 0.9957106)], [('n03388043', 'fountain', 0.41213593)], [('n03388043', 'fountain', 0.47554132)], [('n02130308', 'cheetah', 0.2698031)], [('n03891251', 'park_bench', 0.107062906)], [('n03388043', 'fountain', 0.47577614)], [('n02100735', 'English_setter', 0.63496655)], [('n03388043', 'fountain', 0.24348928)], [('n02130308', 'cheetah', 0.22366455)], [('n02130308', 'cheetah', 0.8148926)], [('n02130308', 'cheetah', 0.9749347)], [('n03388043', 'fountain', 0.9348767)], [('n02130308', 'cheetah', 0.9522158)], [('n02130308', 'cheetah', 0.9417154)], [('n02130308', 'cheetah', 0.2583309)], [('n02130308', 'cheetah', 0.40988266)], [('n02130308', 'cheetah', 0.48182157)], [('n03388043', 'fountain', 0.6990998)], [('n03388043', 'fountain', 0.89722645)], [('n03388043', 'fountain', 0.9924942)], [('n03788365', 'mosquito_net', 0.47747263)], [('n02130308', 'cheetah', 0.7664311)], [('n02480855', 'gorilla', 0.12743221)], [('n02130308', 'cheetah', 0.8005285)], [('n02130308', 'cheetah', 0.90335375)], [('n03388043', 'fountain', 0.77632684)], [('n03388043', 'fountain', 0.1868203)], [('n04371774', 'swing', 0.11419992)], [('n02130308', 'cheetah', 0.9906827)], [('n03388043', 'fountain', 0.36015958)], [('n03388043', 'fountain', 0.913669)], [('n03388043', 'fountain', 0.20013437)], [('n02117135', 'hyena', 0.17369452)], [('n03388043', 'fountain', 0.8659595)], [('n03788365', 'mosquito_net', 0.8547006)], [('n04606251', 'wreck', 0.12478996)], [('n03891251', 'park_bench', 0.17084864)], [('n03388043', 'fountain', 0.47427592)], [('n02114548', 'white_wolf', 0.51987964)], [('n03388043', 'fountain', 0.9295071)], [('n04371774', 'swing', 0.47866565)], [('n02130308', 'cheetah', 0.9749572)], [('n03388043', 'fountain', 0.736127)], [('n02130308', 'cheetah', 0.9032757)], [('n03388043', 'fountain', 0.10089963)], [('n03388043', 'fountain', 0.22431743)], [('n03042490', 'cliff_dwelling', 0.22266039)], [('n02130308', 'cheetah', 0.9010836)], [('n02437312', 'Arabian_camel', 0.19658297)], [('n02130308', 'cheetah', 0.20675497)], [('n03388043', 'fountain', 0.66047144)], [('n02130308', 'cheetah', 0.86761487)], [('n03388043', 'fountain', 0.5410964)], [('n02130308', 'cheetah', 0.6177604)], [('n02130308', 'cheetah', 0.80177385)], [('n03388043', 'fountain', 0.16087054)], [('n03388043', 'fountain', 0.9201312)], [('n02130308', 'cheetah', 0.40921938)], [('n03388043', 'fountain', 0.67688125)], [('n02130308', 'cheetah', 0.6972959)], [('n01855672', 'goose', 0.1633371)], [('n03388043', 'fountain', 0.9413987)], [('n03388043', 'fountain', 0.06916297)], [('n07248320', 'book_jacket', 0.4426976)], [('n03388043', 'fountain', 0.20848206)], [('n02125311', 'cougar', 0.63224804)], [('n02115641', 'dingo', 0.1177609)], [('n02130308', 'cheetah', 0.9501236)], [('n02130308', 'cheetah', 0.36070713)], [('n03042490', 'cliff_dwelling', 0.13773875)], [('n02130308', 'cheetah', 0.619408)], [('n03891251', 'park_bench', 0.08493599)], [('n03388043', 'fountain', 0.7918797)], [('n01910747', 'jellyfish', 0.7401728)], [('n03042490', 'cliff_dwelling', 0.17045258)], [('n02130308', 'cheetah', 0.49297044)], [('n03388043', 'fountain', 0.8267985)], [('n02130308', 'cheetah', 0.9868587)], [('n02115641', 'dingo', 0.447603)], [('n02130308', 'cheetah', 0.7837954)], [('n02965783', 'car_mirror', 0.34751478)], [('n02317335', 'starfish', 0.18712609)], [('n02130308', 'cheetah', 0.9900322)], [('n03388043', 'fountain', 0.43815556)], [('n03788365', 'mosquito_net', 0.44757676)], [('n03788365', 'mosquito_net', 0.5799771)], [('n04423845', 'thimble', 0.6558767)], [('n03388043', 'fountain', 0.2689571)], [('n03388043', 'fountain', 0.976383)], [('n03388043', 'fountain', 0.929828)], [('n03388043', 'fountain', 0.88552684)], [('n02130308', 'cheetah', 0.75241446)], [('n03388043', 'fountain', 0.3955288)], [('n03388043', 'fountain', 0.61022866)], [('n02130308', 'cheetah', 0.74622846)], [('n02130308', 'cheetah', 0.9900129)], [('n03788365', 'mosquito_net', 0.6018483)], [('n03891251', 'park_bench', 0.33498552)], [('n02130308', 'cheetah', 0.9659182)], [('n02130308', 'cheetah', 0.80368894)], [('n02437616', 'llama', 0.42894307)], [('n03388043', 'fountain', 0.9770141)], [('n02389026', 'sorrel', 0.06807605)], [('n03388043', 'fountain', 0.8009772)], [('n03388043', 'fountain', 0.99565214)], [('n03388043', 'fountain', 0.8654328)], [('n02130308', 'cheetah', 0.23058096)], [('n03388043', 'fountain', 0.7000695)], [('n02437616', 'llama', 0.18722375)], [('n02130308', 'cheetah', 0.99146956)], [('n03388043', 'fountain', 0.9744883)], [('n03388043', 'fountain', 0.83618623)], [('n04493381', 'tub', 0.14436927)], [('n03388043', 'fountain', 0.83797157)], [('n02965783', 'car_mirror', 0.14527714)], [('n03388043', 'fountain', 0.73040664)], [('n02130308', 'cheetah', 0.9777386)], [('n01687978', 'agama', 0.08535272)], [('n04589890', 'window_screen', 0.18377624)], [('n03388043', 'fountain', 0.9843567)], [('n02130308', 'cheetah', 0.37714687)], [('n03000134', 'chainlink_fence', 0.44829878)], [('n02130308', 'cheetah', 0.9034129)], [('n02130308', 'cheetah', 0.9572687)], [('n03388043', 'fountain', 0.8753842)], [('n02130308', 'cheetah', 0.5269292)], [('n03388043', 'fountain', 0.5963916)], [('n03891251', 'park_bench', 0.35324934)], [('n02130308', 'cheetah', 0.46145776)], [('n03388043', 'fountain', 0.61035377)], [('n02130308', 'cheetah', 0.5955861)], [('n02130308', 'cheetah', 0.89494926)], [('n03388043', 'fountain', 0.23843601)], [('n04371774', 'swing', 0.1585096)], [('n04371774', 'swing', 0.11884119)], [('n03388043', 'fountain', 0.68080896)], [('n02127052', 'lynx', 0.23655091)], [('n03388043', 'fountain', 0.9757371)], [('n03891251', 'park_bench', 0.088747755)], [('n02130308', 'cheetah', 0.78972566)], [('n03388043', 'fountain', 0.85175914)], [('n03042490', 'cliff_dwelling', 0.20861137)], [('n03388043', 'fountain', 0.47475788)], [('n03388043', 'fountain', 0.6779015)], [('n03388043', 'fountain', 0.27930003)], [('n03388043', 'fountain', 0.7653905)], [('n03388043', 'fountain', 0.83233356)], [('n03388043', 'fountain', 0.9985688)], [('n02130308', 'cheetah', 0.9346624)], [('n02130308', 'cheetah', 0.9981919)], [('n03388043', 'fountain', 0.48547664)], [('n04332243', 'strainer', 0.39598647)], [('n02110341', 'dalmatian', 0.7377885)], [('n03388043', 'fountain', 0.6597005)], [('n02130308', 'cheetah', 0.87923354)], [('n03388043', 'fountain', 0.11059603)], [('n02130308', 'cheetah', 0.90462905)], [('n02130308', 'cheetah', 0.07473535)], [('n03388043', 'fountain', 0.6363751)], [('n01877812', 'wallaby', 0.13878979)], [('n04371774', 'swing', 0.20415898)], [('n02130308', 'cheetah', 0.7800831)], [('n02130308', 'cheetah', 0.24974215)], [('n04589890', 'window_screen', 0.19625922)], [('n02504013', 'Indian_elephant', 0.20606272)], [('n03388043', 'fountain', 0.99805546)], [('n02497673', 'Madagascar_cat', 0.21619624)], [('n03388043', 'fountain', 0.1426817)], [('n03388043', 'fountain', 0.63827306)], [('n02130308', 'cheetah', 0.9051469)], [('n02130308', 'cheetah', 0.9637554)], [('n03388043', 'fountain', 0.5052158)], [('n03042490', 'cliff_dwelling', 0.12398182)], [('n02130308', 'cheetah', 0.25548366)], [('n02130308', 'cheetah', 0.49210986)], [('n02130308', 'cheetah', 0.9867611)], [('n03388043', 'fountain', 0.2589586)], [('n03388043', 'fountain', 0.97710085)], [('n02130308', 'cheetah', 0.8061891)], [('n03388043', 'fountain', 0.67330116)], [('n03388043', 'fountain', 0.84715724)], [('n02130308', 'cheetah', 0.98354256)], [('n02965783', 'car_mirror', 0.29859117)], [('n02130308', 'cheetah', 0.93505096)], [('n01748264', 'Indian_cobra', 0.26811585)], [('n02130308', 'cheetah', 0.9937251)], [('n03042490', 'cliff_dwelling', 0.33016354)], [('n02130308', 'cheetah', 0.95586324)], [('n02130308', 'cheetah', 0.65010625)], [('n03891251', 'park_bench', 0.16362077)], [('n02107312', 'miniature_pinscher', 0.24767153)], [('n04589890', 'window_screen', 0.2879168)], [('n02115641', 'dingo', 0.064950444)], [('n02808440', 'bathtub', 0.405127)], [('n02130308', 'cheetah', 0.7379434)], [('n03388043', 'fountain', 0.68961954)], [('n01748264', 'Indian_cobra', 0.19265541)], [('n04589890', 'window_screen', 0.2562227)], [('n02130308', 'cheetah', 0.9534872)], [('n02130308', 'cheetah', 0.45709762)], [('n02130308', 'cheetah', 0.97099113)], [('n03388043', 'fountain', 0.7661337)], [('n02391049', 'zebra', 0.29456615)], [('n03388043', 'fountain', 0.6865408)], [('n03388043', 'fountain', 0.9857371)], [('n03388043', 'fountain', 0.60831314)], [('n02130308', 'cheetah', 0.9865486)], [('n02130308', 'cheetah', 0.97946703)], [('n01883070', 'wombat', 0.31391296)], [('n03788365', 'mosquito_net', 0.86894095)], [('n04366367', 'suspension_bridge', 0.20164117)], [('n03388043', 'fountain', 0.96794564)], [('n03388043', 'fountain', 0.5822387)], [('n02130308', 'cheetah', 0.93294066)], [('n02130308', 'cheetah', 0.96936274)], [('n02130308', 'cheetah', 0.9997607)], [('n03743016', 'megalith', 0.24399962)], [('n04371774', 'swing', 0.2057642)], [('n02130308', 'cheetah', 0.6225737)], [('n02130308', 'cheetah', 0.97166765)], [('n03388043', 'fountain', 0.31363043)], [('n03388043', 'fountain', 0.7530831)], [('n03042490', 'cliff_dwelling', 0.09184262)], [('n02504013', 'Indian_elephant', 0.25328785)], [('n02504013', 'Indian_elephant', 0.4654535)], [('n03388043', 'fountain', 0.30571628)], [('n02130308', 'cheetah', 0.8834719)], [('n02088632', 'bluetick', 0.17044936)], [('n02130308', 'cheetah', 0.9389889)], [('n03743016', 'megalith', 0.19442339)], [('n02389026', 'sorrel', 0.07213969)], [('n04371774', 'swing', 0.06279561)], [('n03388043', 'fountain', 0.77036643)], [('n03788365', 'mosquito_net', 0.3012318)], [('n03388043', 'fountain', 0.6257039)], [('n02130308', 'cheetah', 0.98510736)], [('n02130308', 'cheetah', 0.9770567)], [('n02013706', 'limpkin', 0.527552)], [('n02130308', 'cheetah', 0.9106028)], [('n03388043', 'fountain', 0.51998997)], [('n02437312', 'Arabian_camel', 0.48404387)], [('n02130308', 'cheetah', 0.39041388)], [('n07248320', 'book_jacket', 0.503584)], [('n03788365', 'mosquito_net', 0.28189087)], [('n03388043', 'fountain', 0.6224247)], [('n03388043', 'fountain', 0.45496944)], [('n02130308', 'cheetah', 0.14468591)], [('n02130308', 'cheetah', 0.77204096)], [('n02965783', 'car_mirror', 0.40834326)], [('n03743016', 'megalith', 0.22741283)], [('n03388043', 'fountain', 0.70222056)], [('n09246464', 'cliff', 0.10458993)], [('n02130308', 'cheetah', 0.1980521)], [('n03388043', 'fountain', 0.78186697)], [('n03388043', 'fountain', 0.9401943)], [('n02130308', 'cheetah', 0.90202785)], [('n03788365', 'mosquito_net', 0.18441074)], [('n03891251', 'park_bench', 0.17138326)], [('n02231487', 'walking_stick', 0.25048864)], [('n03042490', 'cliff_dwelling', 0.1747923)], [('n03388043', 'fountain', 0.7610027)], [('n03388043', 'fountain', 0.16444153)], [('n02130308', 'cheetah', 0.5034014)], [('n03388043', 'fountain', 0.64352185)], [('n02130308', 'cheetah', 0.4131326)], [('n02130308', 'cheetah', 0.925042)], [('n02130308', 'cheetah', 0.9661873)], [('n03891251', 'park_bench', 0.15451221)], [('n02130308', 'cheetah', 0.7736311)], [('n02130308', 'cheetah', 0.8173801)], [('n07248320', 'book_jacket', 0.44159544)], [('n02130308', 'cheetah', 0.97350353)], [('n04589890', 'window_screen', 0.3081844)], [('n02130308', 'cheetah', 0.9233834)], [('n03788365', 'mosquito_net', 0.25037533)], [('n02130308', 'cheetah', 0.5791791)], [('n02480855', 'gorilla', 0.1576769)], [('n02130308', 'cheetah', 0.10758358)], [('n02793495', 'barn', 0.12006405)], [('n03388043', 'fountain', 0.42622364)], [('n03388043', 'fountain', 0.82920396)], [('n04371774', 'swing', 0.1666468)], [('n02130308', 'cheetah', 0.99125576)], [('n02130308', 'cheetah', 0.85149556)], [('n01877812', 'wallaby', 0.5721826)], [('n03388043', 'fountain', 0.27281502)], [('n02130308', 'cheetah', 0.9932115)], [('n02965783', 'car_mirror', 0.27970782)], [('n02965783', 'car_mirror', 0.27738714)], [('n03388043', 'fountain', 0.70071524)], [('n03388043', 'fountain', 0.98749393)], [('n03891251', 'park_bench', 0.21555)], [('n04371774', 'swing', 0.100422)], [('n04493381', 'tub', 0.132748)], [('n02123159', 'tiger_cat', 0.5392494)], [('n04371774', 'swing', 0.46971172)], [('n02115641', 'dingo', 0.06779094)], [('n02130308', 'cheetah', 0.9605037)], [('n02130308', 'cheetah', 0.6478821)], [('n02130308', 'cheetah', 0.99009484)], [('n03388043', 'fountain', 0.18749556)], [('n02130308', 'cheetah', 0.99707735)], [('n03388043', 'fountain', 0.3208865)], [('n03388043', 'fountain', 0.89687175)], [('n03891251', 'park_bench', 0.12158043)], [('n03388043', 'fountain', 0.9228643)], [('n02793495', 'barn', 0.1611584)], [('n03788365', 'mosquito_net', 0.12560989)], [('n02130308', 'cheetah', 0.6770753)], [('n02977058', 'cash_machine', 0.09669482)], [('n02965783', 'car_mirror', 0.38588724)], [('n02130308', 'cheetah', 0.6850624)], [('n03388043', 'fountain', 0.93562555)], [('n02130308', 'cheetah', 0.8358352)], [('n04371774', 'swing', 0.11850129)], [('n01877812', 'wallaby', 0.2166286)], [('n03388043', 'fountain', 0.9055973)], [('n02130308', 'cheetah', 0.99349797)], [('n03788365', 'mosquito_net', 0.4464121)], [('n02130308', 'cheetah', 0.8545347)], [('n02130308', 'cheetah', 0.85847193)], [('n03891251', 'park_bench', 0.10016612)], [('n04589890', 'window_screen', 0.23157388)], [('n02133161', 'American_black_bear', 0.2923692)], [('n03388043', 'fountain', 0.18979432)], [('n02130308', 'cheetah', 0.85461694)], [('n02130308', 'cheetah', 0.9473697)], [('n02130308', 'cheetah', 0.88119674)], [('n03388043', 'fountain', 0.77554494)], [('n02130308', 'cheetah', 0.89586717)], [('n02130308', 'cheetah', 0.5995932)], [('n03388043', 'fountain', 0.6003021)], [('n02130308', 'cheetah', 0.44769362)], [('n03891251', 'park_bench', 0.18806577)], [('n01855672', 'goose', 0.22456874)], [('n03891251', 'park_bench', 0.241724)], [('n03388043', 'fountain', 0.4769351)], [('n02454379', 'armadillo', 0.26137573)], [('n04371774', 'swing', 0.4338064)], [('n04371774', 'swing', 0.34044835)], [('n02480855', 'gorilla', 0.12064496)], [('n03388043', 'fountain', 0.72539914)], [('n03788365', 'mosquito_net', 0.41985613)], [('n02130308', 'cheetah', 0.92908084)], [('n02437312', 'Arabian_camel', 0.60206056)], [('n02130308', 'cheetah', 0.56716764)], [('n02130308', 'cheetah', 0.95105195)], [('n02114855', 'coyote', 0.70992833)], [('n03388043', 'fountain', 0.96572846)], [('n02130308', 'cheetah', 0.9648542)], [('n02130308', 'cheetah', 0.9528929)], [('n03388043', 'fountain', 0.96979314)], [('n03388043', 'fountain', 0.44747376)], [('n03388043', 'fountain', 0.95657915)], [('n02130308', 'cheetah', 0.9368013)], [('n02127052', 'lynx', 0.1820534)], [('n02130308', 'cheetah', 0.9880724)], [('n02114855', 'coyote', 0.44905904)], [('n02130308', 'cheetah', 0.73309815)], [('n03388043', 'fountain', 0.56051105)], [('n03388043', 'fountain', 0.8214951)], [('n03388043', 'fountain', 0.9716304)], [('n02130308', 'cheetah', 0.9944878)], [('n03388043', 'fountain', 0.5389355)], [('n02130308', 'cheetah', 0.351326)], [('n03388043', 'fountain', 0.57607555)], [('n02130308', 'cheetah', 0.9640341)], [('n03788365', 'mosquito_net', 0.65271467)], [('n03160309', 'dam', 0.35026163)], [('n02130308', 'cheetah', 0.97234815)], [('n02130308', 'cheetah', 0.9712506)], [('n03388043', 'fountain', 0.87201697)], [('n02504458', 'African_elephant', 0.06381175)], [('n02130308', 'cheetah', 0.45792508)], [('n03891251', 'park_bench', 0.09519778)], [('n02130308', 'cheetah', 0.8538495)], [('n02130308', 'cheetah', 0.99674857)], [('n03388043', 'fountain', 0.9634136)], [('n02130308', 'cheetah', 0.4232692)], [('n07802026', 'hay', 0.14927468)], [('n03388043', 'fountain', 0.43291104)], [('n02130308', 'cheetah', 0.9379049)], [('n02114367', 'timber_wolf', 0.2988538)], [('n03788365', 'mosquito_net', 0.524431)], [('n03788365', 'mosquito_net', 0.13927554)], [('n02100735', 'English_setter', 0.31369132)], [('n03388043', 'fountain', 0.18646367)], [('n03388043', 'fountain', 0.3155158)], [('n03388043', 'fountain', 0.59394985)], [('n02437312', 'Arabian_camel', 0.5318943)], [('n03000134', 'chainlink_fence', 0.48799938)], [('n02130308', 'cheetah', 0.94064796)], [('n02965783', 'car_mirror', 0.24220309)], [('n03388043', 'fountain', 0.679585)], [('n03388043', 'fountain', 0.4929051)], [('n02130308', 'cheetah', 0.98518735)], [('n02130308', 'cheetah', 0.9585263)], [('n02965783', 'car_mirror', 0.19749494)], [('n03891251', 'park_bench', 0.26240665)], [('n02130308', 'cheetah', 0.99475807)], [('n02391049', 'zebra', 0.4388931)], [('n02130308', 'cheetah', 0.7680213)], [('n02130308', 'cheetah', 0.9947747)], [('n02130308', 'cheetah', 0.9659305)], [('n03388043', 'fountain', 0.509526)], [('n02497673', 'Madagascar_cat', 0.96014136)], [('n02130308', 'cheetah', 0.9935277)], [('n03388043', 'fountain', 0.87508935)], [('n02417914', 'ibex', 0.20470287)], [('n02130308', 'cheetah', 0.9763581)], [('n03388043', 'fountain', 0.24222831)], [('n02130308', 'cheetah', 0.32832375)], [('n03743016', 'megalith', 0.22399293)], [('n03388043', 'fountain', 0.84474343)], [('n02504013', 'Indian_elephant', 0.19645604)], [('n03042490', 'cliff_dwelling', 0.13351354)], [('n03958227', 'plastic_bag', 0.12895812)], [('n02130308', 'cheetah', 0.6670938)], [('n02128925', 'jaguar', 0.18187582)], [('n02130308', 'cheetah', 0.9883555)], [('n03388043', 'fountain', 0.60071856)], [('n03388043', 'fountain', 0.40014005)], [('n02130308', 'cheetah', 0.37142485)], [('n02130308', 'cheetah', 0.221341)], [('n02437312', 'Arabian_camel', 0.22484866)], [('n02130308', 'cheetah', 0.9494358)], [('n03388043', 'fountain', 0.96318626)], [('n03788365', 'mosquito_net', 0.4280261)], [('n02130308', 'cheetah', 0.9418832)], [('n02130308', 'cheetah', 0.9852064)], [('n03388043', 'fountain', 0.21100737)], [('n02130308', 'cheetah', 0.55151653)], [('n03788365', 'mosquito_net', 0.7442884)], [('n02325366', 'wood_rabbit', 0.68997926)], [('n03388043', 'fountain', 0.76316595)], [('n02130308', 'cheetah', 0.63095057)], [('n03388043', 'fountain', 0.94165885)], [('n02965783', 'car_mirror', 0.42925537)], [('n03388043', 'fountain', 0.8073652)], [('n03388043', 'fountain', 0.8971921)], [('n03388043', 'fountain', 0.43478)], [('n02130308', 'cheetah', 0.90152013)], [('n03388043', 'fountain', 0.67808694)], [('n03388043', 'fountain', 0.08960592)], [('n03388043', 'fountain', 0.7886164)], [('n03388043', 'fountain', 0.81796014)], [('n03388043', 'fountain', 0.9046078)], [('n02480855', 'gorilla', 0.084751695)], [('n01855672', 'goose', 0.18806271)], [('n02114855', 'coyote', 0.19669461)], [('n03891251', 'park_bench', 0.51043755)], [('n03388043', 'fountain', 0.9593513)], [('n02480855', 'gorilla', 0.15271857)], [('n04371774', 'swing', 0.19867495)], [('n03891251', 'park_bench', 0.14422974)], [('n04371774', 'swing', 0.40435788)], [('n02130308', 'cheetah', 0.9967278)], [('n02130308', 'cheetah', 0.2046805)], [('n03388043', 'fountain', 0.7096143)], [('n03388043', 'fountain', 0.6617482)], [('n03388043', 'fountain', 0.66315866)], [('n03388043', 'fountain', 0.68647945)], [('n02130308', 'cheetah', 0.90601236)], [('n02130308', 'cheetah', 0.97850716)], [('n03388043', 'fountain', 0.9303661)], [('n02130308', 'cheetah', 0.35388532)], [('n03388043', 'fountain', 0.9063668)], [('n03388043', 'fountain', 0.7143723)], [('n02130308', 'cheetah', 0.9964089)], [('n03388043', 'fountain', 0.9961571)], [('n03388043', 'fountain', 0.95831996)], [('n02808440', 'bathtub', 0.2519923)], [('n09229709', 'bubble', 0.11376262)], [('n03000134', 'chainlink_fence', 0.3407187)], [('n02130308', 'cheetah', 0.9936579)], [('n03388043', 'fountain', 0.85346705)], [('n02130308', 'cheetah', 0.6497548)], [('n02130308', 'cheetah', 0.8010895)], [('n02130308', 'cheetah', 0.99105096)], [('n02130308', 'cheetah', 0.43300074)], [('n03388043', 'fountain', 0.29292327)], [('n02130308', 'cheetah', 0.29865152)], [('n03388043', 'fountain', 0.28825113)], [('n03388043', 'fountain', 0.9797775)], [('n02808440', 'bathtub', 0.18293642)], [('n02504458', 'African_elephant', 0.6447565)], [('n03388043', 'fountain', 0.67281103)], [('n02130308', 'cheetah', 0.9267372)], [('n02396427', 'wild_boar', 0.1318092)], [('n03388043', 'fountain', 0.89694995)], [('n02130308', 'cheetah', 0.13651833)], [('n04589890', 'window_screen', 0.20030397)], [('n03388043', 'fountain', 0.69445336)], [('n02130308', 'cheetah', 0.991861)], [('n02130308', 'cheetah', 0.7448943)], [('n02130308', 'cheetah', 0.92536175)], [('n02130308', 'cheetah', 0.99237216)], [('n03388043', 'fountain', 0.49317107)], [('n03891251', 'park_bench', 0.09456409)], [('n02130308', 'cheetah', 0.39856207)], [('n02130308', 'cheetah', 0.31108055)], [('n02130308', 'cheetah', 0.9423946)], [('n03388043', 'fountain', 0.062173508)], [('n03388043', 'fountain', 0.95323974)], [('n03481172', 'hammer', 0.1297492)], [('n03891251', 'park_bench', 0.14560932)], [('n03388043', 'fountain', 0.84963596)], [('n03388043', 'fountain', 0.9668122)], [('n03388043', 'fountain', 0.8542653)], [('n02398521', 'hippopotamus', 0.23941994)], [('n02437312', 'Arabian_camel', 0.4208287)], [('n03388043', 'fountain', 0.9960444)], [('n02130308', 'cheetah', 0.78178084)], [('n03788365', 'mosquito_net', 0.399955)], [('n02130308', 'cheetah', 0.9514134)], [('n02130308', 'cheetah', 0.5086038)], [('n02130308', 'cheetah', 0.53655326)], [('n03388043', 'fountain', 0.7046256)], [('n02504458', 'African_elephant', 0.07675048)], [('n03388043', 'fountain', 0.10992675)], [('n02965783', 'car_mirror', 0.2539234)], [('n04404412', 'television', 0.06759575)], [('n03388043', 'fountain', 0.14549904)], [('n02130308', 'cheetah', 0.58491117)], [('n03388043', 'fountain', 0.7796511)], [('n03388043', 'fountain', 0.45611158)], [('n02130308', 'cheetah', 0.93884444)], [('n02391049', 'zebra', 0.11592631)], [('n03388043', 'fountain', 0.54215145)], [('n02130308', 'cheetah', 0.96005136)], [('n03388043', 'fountain', 0.9972134)], [('n02504458', 'African_elephant', 0.101804584)], [('n02130308', 'cheetah', 0.4193449)], [('n03891251', 'park_bench', 0.19657919)], [('n03042490', 'cliff_dwelling', 0.21666405)], [('n03388043', 'fountain', 0.79094565)], [('n02130308', 'cheetah', 0.123095356)], [('n02130308', 'cheetah', 0.52448875)], [('n03388043', 'fountain', 0.17477655)], [('n03388043', 'fountain', 0.9285479)], [('n02130308', 'cheetah', 0.47942826)], [('n02130308', 'cheetah', 0.5078136)], [('n03388043', 'fountain', 0.9449477)], [('n02130308', 'cheetah', 0.9849502)], [('n01751748', 'sea_snake', 0.28506407)], [('n03388043', 'fountain', 0.7085145)], [('n02130308', 'cheetah', 0.9803759)], [('n03891251', 'park_bench', 0.17362797)], [('n02504013', 'Indian_elephant', 0.10893508)], [('n02130308', 'cheetah', 0.96859556)], [('n02130308', 'cheetah', 0.94861627)], [('n02437312', 'Arabian_camel', 0.5676301)], [('n02130308', 'cheetah', 0.8727589)], [('n03788365', 'mosquito_net', 0.82672)], [('n03388043', 'fountain', 0.13641955)], [('n04589890', 'window_screen', 0.35730937)], [('n02130308', 'cheetah', 0.85103226)], [('n02130308', 'cheetah', 0.9968065)], [('n02130308', 'cheetah', 0.2017593)], [('n02115641', 'dingo', 0.3877763)], [('n07248320', 'book_jacket', 0.42034167)], [('n02410509', 'bison', 0.3193938)], [('n04371774', 'swing', 0.16600966)], [('n02130308', 'cheetah', 0.74558485)], [('n01756291', 'sidewinder', 0.16742067)], [('n02130308', 'cheetah', 0.21899866)], [('n02130308', 'cheetah', 0.9339893)], [('n02130308', 'cheetah', 0.83122057)], [('n03388043', 'fountain', 0.15879063)], [('n03388043', 'fountain', 0.9820342)], [('n03388043', 'fountain', 0.86736584)], [('n03388043', 'fountain', 0.604569)], [('n03042490', 'cliff_dwelling', 0.25026685)], [('n02130308', 'cheetah', 0.9700154)], [('n03388043', 'fountain', 0.31141105)], [('n03388043', 'fountain', 0.998708)], [('n03388043', 'fountain', 0.49455532)], [('n02130308', 'cheetah', 0.9836474)], [('n03388043', 'fountain', 0.38742512)], [('n02130308', 'cheetah', 0.9844422)], [('n03042490', 'cliff_dwelling', 0.14637968)], [('n02130308', 'cheetah', 0.9666137)], [('n04371774', 'swing', 0.15406106)], [('n02130308', 'cheetah', 0.47673056)], [('n02130308', 'cheetah', 0.99482155)], [('n03388043', 'fountain', 0.54639995)], [('n03388043', 'fountain', 0.9850028)], [('n02130308', 'cheetah', 0.46283916)], [('n02130308', 'cheetah', 0.9703128)], [('n03388043', 'fountain', 0.45225605)], [('n02130308', 'cheetah', 0.4324649)], [('n03388043', 'fountain', 0.7172298)], [('n02110341', 'dalmatian', 0.939961)], [('n02130308', 'cheetah', 0.9445147)], [('n02130308', 'cheetah', 0.9518949)], [('n02130308', 'cheetah', 0.83536166)], [('n02130308', 'cheetah', 0.9943646)], [('n03388043', 'fountain', 0.825309)], [('n03388043', 'fountain', 0.09311957)], [('n03388043', 'fountain', 0.9617154)], [('n02130308', 'cheetah', 0.8037729)], [('n03388043', 'fountain', 0.09386698)], [('n03388043', 'fountain', 0.32331112)], [('n04275548', 'spider_web', 0.12182998)], [('n02130308', 'cheetah', 0.4603846)], [('n03388043', 'fountain', 0.47873685)], [('n03388043', 'fountain', 0.2671524)], [('n02480855', 'gorilla', 0.1547686)], [('n02130308', 'cheetah', 0.6326983)], [('n03388043', 'fountain', 0.6287586)], [('n03388043', 'fountain', 0.7168042)], [('n02130308', 'cheetah', 0.9980597)], [('n03388043', 'fountain', 0.8864494)], [('n03788365', 'mosquito_net', 0.86886436)], [('n03788365', 'mosquito_net', 0.54278606)], [('n03388043', 'fountain', 0.5346504)], [('n03388043', 'fountain', 0.7592817)], [('n03388043', 'fountain', 0.45957074)], [('n02130308', 'cheetah', 0.5751046)], [('n02130308', 'cheetah', 0.9847926)], [('n02130308', 'cheetah', 0.9763387)], [('n03388043', 'fountain', 0.41635337)], [('n02130308', 'cheetah', 0.32189256)], [('n02114855', 'coyote', 0.43566802)], [('n03388043', 'fountain', 0.73864114)], [('n02130308', 'cheetah', 0.9996543)], [('n02099712', 'Labrador_retriever', 0.092879355)], [('n03388043', 'fountain', 0.15756997)], [('n01855672', 'goose', 0.16860889)], [('n03042490', 'cliff_dwelling', 0.12983927)], [('n03042490', 'cliff_dwelling', 0.2660512)], [('n02130308', 'cheetah', 0.38025364)], [('n02130308', 'cheetah', 0.88023317)], [('n03388043', 'fountain', 0.80823547)], [('n03388043', 'fountain', 0.33666977)], [('n03042490', 'cliff_dwelling', 0.4076954)], [('n02130308', 'cheetah', 0.20739716)], [('n03388043', 'fountain', 0.10307834)], [('n03388043', 'fountain', 0.60496414)], [('n03958227', 'plastic_bag', 0.10617014)], [('n04589890', 'window_screen', 0.24700151)], [('n02130308', 'cheetah', 0.77407646)], [('n03388043', 'fountain', 0.7792868)], [('n02480855', 'gorilla', 0.07807285)], [('n03388043', 'fountain', 0.24279517)], [('n02115641', 'dingo', 0.6582343)], [('n02114855', 'coyote', 0.17088278)], [('n02130308', 'cheetah', 0.8100101)], [('n02130308', 'cheetah', 0.9994273)], [('n03388043', 'fountain', 0.1571989)], [('n02130308', 'cheetah', 0.43014288)], [('n02130308', 'cheetah', 0.95722306)], [('n03388043', 'fountain', 0.41241282)], [('n02130308', 'cheetah', 0.9973103)], [('n02130308', 'cheetah', 0.6148177)], [('n03388043', 'fountain', 0.90612566)], [('n02130308', 'cheetah', 0.97568107)], [('n02130308', 'cheetah', 0.99474573)], [('n03388043', 'fountain', 0.97691035)], [('n02130308', 'cheetah', 0.968113)], [('n03042490', 'cliff_dwelling', 0.21543491)], [('n02130308', 'cheetah', 0.8197078)], [('n03000134', 'chainlink_fence', 0.11125712)], [('n02130308', 'cheetah', 0.34685457)], [('n02130308', 'cheetah', 0.98700386)], [('n03891251', 'park_bench', 0.68136907)], [('n03958227', 'plastic_bag', 0.16192566)], [('n02130308', 'cheetah', 0.99598527)], [('n02114548', 'white_wolf', 0.3596033)], [('n02130308', 'cheetah', 0.85456115)], [('n03388043', 'fountain', 0.98194444)], [('n07248320', 'book_jacket', 0.29660255)], [('n03388043', 'fountain', 0.83157414)], [('n02130308', 'cheetah', 0.8388279)], [('n03743016', 'megalith', 0.15137708)], [('n02130308', 'cheetah', 0.8165182)], [('n02130308', 'cheetah', 0.16761911)], [('n02417914', 'ibex', 0.09632848)], [('n02130308', 'cheetah', 0.90398866)], [('n03388043', 'fountain', 0.36240682)], [('n07248320', 'book_jacket', 0.15818584)], [('n03388043', 'fountain', 0.10503531)], [('n02437616', 'llama', 0.29997304)], [('n03788365', 'mosquito_net', 0.561587)], [('n03388043', 'fountain', 0.23701964)], [('n02130308', 'cheetah', 0.98719865)], [('n02125311', 'cougar', 0.19482514)], [('n04371774', 'swing', 0.08880147)], [('n03388043', 'fountain', 0.8613517)], [('n03388043', 'fountain', 0.3520048)], [('n03388043', 'fountain', 0.22920848)], [('n02130308', 'cheetah', 0.8700119)], [('n02130308', 'cheetah', 0.27749282)], [('n02130308', 'cheetah', 0.5376926)], [('n02130308', 'cheetah', 0.7487131)], [('n02110341', 'dalmatian', 0.104983896)], [('n02134084', 'ice_bear', 0.18382812)], [('n02130308', 'cheetah', 0.85691977)], [('n03388043', 'fountain', 0.14270817)], [('n03042490', 'cliff_dwelling', 0.30236238)], [('n02130308', 'cheetah', 0.17150311)], [('n02965783', 'car_mirror', 0.3196115)], [('n04371774', 'swing', 0.17024292)], [('n02130308', 'cheetah', 0.99168384)], [('n02130308', 'cheetah', 0.8953599)], [('n07753592', 'banana', 0.20233187)], [('n02130308', 'cheetah', 0.9980135)], [('n03388043', 'fountain', 0.81412476)], [('n02110341', 'dalmatian', 0.6352027)], [('n03388043', 'fountain', 0.7365158)], [('n03388043', 'fountain', 0.5323641)], [('n02965783', 'car_mirror', 0.25510183)], [('n02130308', 'cheetah', 0.3900264)], [('n03388043', 'fountain', 0.6621719)], [('n02130308', 'cheetah', 0.96425927)], [('n02437616', 'llama', 0.5691273)], [('n02133161', 'American_black_bear', 0.24446605)], [('n02130308', 'cheetah', 0.67767715)], [('n02125311', 'cougar', 0.162105)], [('n03388043', 'fountain', 0.13695243)], [('n03388043', 'fountain', 0.9044142)], [('n02114855', 'coyote', 0.082299225)], [('n04589890', 'window_screen', 0.25251454)], [('n03388043', 'fountain', 0.5011996)], [('n03891251', 'park_bench', 0.6193404)], [('n03388043', 'fountain', 0.93240154)], [('n03388043', 'fountain', 0.8627663)], [('n03388043', 'fountain', 0.6152578)], [('n02130308', 'cheetah', 0.56347215)], [('n02130308', 'cheetah', 0.49129173)], [('n03388043', 'fountain', 0.10173483)], [('n02130308', 'cheetah', 0.59600055)], [('n03388043', 'fountain', 0.92299867)], [('n02410509', 'bison', 0.22068985)], [('n02130308', 'cheetah', 0.6381334)], [('n02130308', 'cheetah', 0.99556714)], [('n03388043', 'fountain', 0.7084504)], [('n03388043', 'fountain', 0.9744228)], [('n03388043', 'fountain', 0.4921973)], [('n02130308', 'cheetah', 0.8047618)], [('n03388043', 'fountain', 0.7396712)], [('n02130308', 'cheetah', 0.66602033)], [('n04326547', 'stone_wall', 0.04903343)], [('n03388043', 'fountain', 0.9532906)], [('n03388043', 'fountain', 0.6517602)], [('n03388043', 'fountain', 0.9889515)], [('n03388043', 'fountain', 0.9855112)], [('n01855672', 'goose', 0.14926298)], [('n03788365', 'mosquito_net', 0.09278791)], [('n02130308', 'cheetah', 0.92502576)], [('n02130308', 'cheetah', 0.9729662)], [('n02130308', 'cheetah', 0.9921295)], [('n03891251', 'park_bench', 0.18674983)], [('n04589890', 'window_screen', 0.13469723)], [('n02130308', 'cheetah', 0.98887515)], [('n02130308', 'cheetah', 0.9929858)], [('n03388043', 'fountain', 0.43174177)], [('n03388043', 'fountain', 0.9755106)], [('n02130308', 'cheetah', 0.520409)], [('n03388043', 'fountain', 0.37116972)], [('n04423845', 'thimble', 0.8435431)], [('n03388043', 'fountain', 0.5666149)], [('n03743016', 'megalith', 0.12681785)], [('n02808440', 'bathtub', 0.321718)], [('n03388043', 'fountain', 0.73355514)], [('n02130308', 'cheetah', 0.98791516)], [('n03388043', 'fountain', 0.95194143)], [('n02130308', 'cheetah', 0.28192475)], [('n03788365', 'mosquito_net', 0.3197199)], [('n02130308', 'cheetah', 0.93328166)], [('n02130308', 'cheetah', 0.29834118)], [('n02130308', 'cheetah', 0.86553377)], [('n03388043', 'fountain', 0.8742507)], [('n02130308', 'cheetah', 0.98470795)], [('n02130308', 'cheetah', 0.9642321)], [('n02480855', 'gorilla', 0.13770849)], [('n03388043', 'fountain', 0.94725895)], [('n04371774', 'swing', 0.18147008)], [('n02130308', 'cheetah', 0.5392784)], [('n09246464', 'cliff', 0.28114903)], [('n02965783', 'car_mirror', 0.40150866)], [('n02130308', 'cheetah', 0.6841345)], [('n03388043', 'fountain', 0.16095152)], [('n02130308', 'cheetah', 0.26437387)], [('n03388043', 'fountain', 0.45557272)], [('n03388043', 'fountain', 0.7379797)], [('n03388043', 'fountain', 0.5221809)], [('n03891251', 'park_bench', 0.37290218)], [('n03388043', 'fountain', 0.21144252)], [('n03388043', 'fountain', 0.2008764)], [('n03388043', 'fountain', 0.89499325)], [('n03388043', 'fountain', 0.2596641)], [('n02130308', 'cheetah', 0.9860465)], [('n02130308', 'cheetah', 0.9870172)], [('n04371774', 'swing', 0.26658183)], [('n03388043', 'fountain', 0.8126748)], [('n02130308', 'cheetah', 0.80074155)], [('n03743016', 'megalith', 0.28515694)], [('n02130308', 'cheetah', 0.81653965)], [('n02130308', 'cheetah', 0.83673406)], [('n03958227', 'plastic_bag', 0.29346892)], [('n09246464', 'cliff', 0.47808683)], [('n03388043', 'fountain', 0.46912116)], [('n04423845', 'thimble', 0.97712165)], [('n02130308', 'cheetah', 0.36871797)], [('n03891251', 'park_bench', 0.19310248)], [('n03788365', 'mosquito_net', 0.41526625)], [('n02130308', 'cheetah', 0.9977348)], [('n02125311', 'cougar', 0.26417798)], [('n04371774', 'swing', 0.29832405)], [('n02130308', 'cheetah', 0.96558636)], [('n03388043', 'fountain', 0.5083944)], [('n02128385', 'leopard', 0.54014385)], [('n02107312', 'miniature_pinscher', 0.44167054)], [('n02130308', 'cheetah', 0.82453233)], [('n07248320', 'book_jacket', 0.10677735)], [('n04371774', 'swing', 0.17962627)], [('n02114548', 'white_wolf', 0.16718562)], [('n02130308', 'cheetah', 0.9107293)], [('n02115641', 'dingo', 0.9516452)], [('n03388043', 'fountain', 0.8032525)], [('n02130308', 'cheetah', 0.8921053)], [('n03891251', 'park_bench', 0.14680922)], [('n03388043', 'fountain', 0.51400405)], [('n03788365', 'mosquito_net', 0.8867632)], [('n02130308', 'cheetah', 0.873212)], [('n02130308', 'cheetah', 0.25480643)], [('n02130308', 'cheetah', 0.4068876)], [('n03388043', 'fountain', 0.5441685)], [('n02130308', 'cheetah', 0.9873518)], [('n03388043', 'fountain', 0.47598287)], [('n02346627', 'porcupine', 0.09624559)], [('n03891251', 'park_bench', 0.16378748)], [('n02130308', 'cheetah', 0.97906494)], [('n02504013', 'Indian_elephant', 0.100349635)], [('n03388043', 'fountain', 0.16665117)], [('n03388043', 'fountain', 0.5150262)], [('n03388043', 'fountain', 0.81792974)], [('n02130308', 'cheetah', 0.9576994)], [('n03388043', 'fountain', 0.8214986)], [('n03388043', 'fountain', 0.98517555)], [('n03388043', 'fountain', 0.996234)], [('n02965783', 'car_mirror', 0.33435386)], [('n02130308', 'cheetah', 0.9887581)], [('n02130308', 'cheetah', 0.13121508)], [('n02130308', 'cheetah', 0.99877983)], [('n02127052', 'lynx', 0.23228872)], [('n03388043', 'fountain', 0.19850224)], [('n02130308', 'cheetah', 0.99531245)], [('n02504458', 'African_elephant', 0.05856052)], [('n03388043', 'fountain', 0.9508953)], [('n02130308', 'cheetah', 0.31605554)], [('n02130308', 'cheetah', 0.2976949)], [('n02130308', 'cheetah', 0.7939272)], [('n03388043', 'fountain', 0.34276858)], [('n03388043', 'fountain', 0.6267337)], [('n04371774', 'swing', 0.16992536)], [('n02130308', 'cheetah', 0.77277553)], [('n03042490', 'cliff_dwelling', 0.2129241)], [('n02326432', 'hare', 0.22265215)], [('n03388043', 'fountain', 0.869672)], [('n02965783', 'car_mirror', 0.24823943)], [('n02130308', 'cheetah', 0.19071704)], [('n03388043', 'fountain', 0.95597476)], [('n07248320', 'book_jacket', 0.5416864)], [('n03788365', 'mosquito_net', 0.810308)], [('n02130308', 'cheetah', 0.22883123)], [('n03388043', 'fountain', 0.62582815)], [('n02085620', 'Chihuahua', 0.06568755)], [('n02130308', 'cheetah', 0.63729316)], [('n03388043', 'fountain', 0.26033708)], [('n02480855', 'gorilla', 0.11600904)], [('n02114855', 'coyote', 0.06735386)], [('n03388043', 'fountain', 0.65644336)], [('n03388043', 'fountain', 0.6231625)], [('n04371774', 'swing', 0.21982838)], [('n02130308', 'cheetah', 0.9559052)], [('n02965783', 'car_mirror', 0.26542425)], [('n04275548', 'spider_web', 0.09871946)], [('n03388043', 'fountain', 0.5790054)], [('n02130308', 'cheetah', 0.97957486)], [('n03042490', 'cliff_dwelling', 0.32107958)], [('n03388043', 'fountain', 0.86074877)], [('n02130308', 'cheetah', 0.6580637)], [('n02130308', 'cheetah', 0.9942987)], [('n07248320', 'book_jacket', 0.2572471)], [('n03788365', 'mosquito_net', 0.89837444)], [('n04371774', 'swing', 0.23723277)], [('n03388043', 'fountain', 0.8920967)], [('n02391049', 'zebra', 0.8535444)], [('n03388043', 'fountain', 0.13492812)], [('n02125311', 'cougar', 0.42351806)], [('n03388043', 'fountain', 0.8623801)], [('n02965783', 'car_mirror', 0.26198983)], [('n02130308', 'cheetah', 0.9989116)], [('n03788365', 'mosquito_net', 0.39634842)], [('n03388043', 'fountain', 0.48053643)], [('n03388043', 'fountain', 0.91986173)], [('n02391049', 'zebra', 0.22911012)], [('n03388043', 'fountain', 0.8473956)], [('n03788365', 'mosquito_net', 0.3256397)], [('n02480855', 'gorilla', 0.07698156)], [('n02130308', 'cheetah', 0.9701418)], [('n02125311', 'cougar', 0.17799011)], [('n02130308', 'cheetah', 0.98745805)], [('n03388043', 'fountain', 0.9991721)], [('n02130308', 'cheetah', 0.82581246)], [('n02130308', 'cheetah', 0.777069)], [('n03388043', 'fountain', 0.97369677)], [('n02130308', 'cheetah', 0.69673294)], [('n03388043', 'fountain', 0.33750373)], [('n07248320', 'book_jacket', 0.07480544)], [('n02114855', 'coyote', 0.6500089)], [('n02130308', 'cheetah', 0.55497175)], [('n02130308', 'cheetah', 0.77852035)], [('n04371774', 'swing', 0.852901)], [('n02130308', 'cheetah', 0.92492783)], [('n02110185', 'Siberian_husky', 0.14462768)], [('n02504013', 'Indian_elephant', 0.26242885)], [('n03388043', 'fountain', 0.9802476)], [('n02130308', 'cheetah', 0.8406799)], [('n03788365', 'mosquito_net', 0.17570105)], [('n02130308', 'cheetah', 0.91170293)], [('n03388043', 'fountain', 0.47738242)], [('n03788365', 'mosquito_net', 0.86167413)], [('n02130308', 'cheetah', 0.47922942)], [('n02130308', 'cheetah', 0.9948856)], [('n07248320', 'book_jacket', 0.2620156)], [('n02415577', 'bighorn', 0.3291312)], [('n02130308', 'cheetah', 0.8126156)], [('n03388043', 'fountain', 0.85340905)], [('n02130308', 'cheetah', 0.8709358)], [('n03388043', 'fountain', 0.753239)], [('n03388043', 'fountain', 0.82041323)], [('n03388043', 'fountain', 0.94080764)], [('n03388043', 'fountain', 0.38002017)], [('n02130308', 'cheetah', 0.48882514)], [('n02130308', 'cheetah', 0.22730945)], [('n03388043', 'fountain', 0.7081985)], [('n02123159', 'tiger_cat', 0.3752692)], [('n03788365', 'mosquito_net', 0.60540485)], [('n03388043', 'fountain', 0.6233162)], [('n03388043', 'fountain', 0.3275634)], [('n02130308', 'cheetah', 0.91687435)], [('n02130308', 'cheetah', 0.5127541)], [('n03388043', 'fountain', 0.74769473)], [('n02454379', 'armadillo', 0.70940787)], [('n03042490', 'cliff_dwelling', 0.1848493)], [('n02643566', 'lionfish', 0.21222246)], [('n02130308', 'cheetah', 0.994007)], [('n04589890', 'window_screen', 0.10749079)], [('n09229709', 'bubble', 0.2674213)], [('n02130308', 'cheetah', 0.9712752)], [('n03388043', 'fountain', 0.08462649)], [('n02130308', 'cheetah', 0.63065773)], [('n03788365', 'mosquito_net', 0.24758586)], [('n03388043', 'fountain', 0.42246446)], [('n03388043', 'fountain', 0.30767366)], [('n02130308', 'cheetah', 0.9221915)], [('n03891251', 'park_bench', 0.13413793)], [('n03388043', 'fountain', 0.39146984)], [('n02504013', 'Indian_elephant', 0.08797813)], [('n02130308', 'cheetah', 0.75742763)], [('n03388043', 'fountain', 0.28600377)], [('n03743016', 'megalith', 0.6810503)], [('n02130308', 'cheetah', 0.38386703)], [('n02130308', 'cheetah', 0.6285589)], [('n03388043', 'fountain', 0.670649)], [('n02130308', 'cheetah', 0.99127626)], [('n02130308', 'cheetah', 0.99661034)], [('n03388043', 'fountain', 0.9633969)], [('n03388043', 'fountain', 0.7810629)], [('n02130308', 'cheetah', 0.9968359)], [('n02130308', 'cheetah', 0.5175336)], [('n03388043', 'fountain', 0.76835513)], [('n02130308', 'cheetah', 0.22701491)], [('n02114548', 'white_wolf', 0.40581715)], [('n02391049', 'zebra', 0.2710949)], [('n01855672', 'goose', 0.17285296)], [('n02130308', 'cheetah', 0.95635843)], [('n03388043', 'fountain', 0.4489337)], [('n02130308', 'cheetah', 0.4020017)], [('n02130308', 'cheetah', 0.917632)], [('n03788365', 'mosquito_net', 0.7685281)], [('n03388043', 'fountain', 0.15970501)], [('n01698640', 'American_alligator', 0.28275284)], [('n03388043', 'fountain', 0.595625)], [('n02130308', 'cheetah', 0.5745609)], [('n02130308', 'cheetah', 0.91432416)], [('n02965783', 'car_mirror', 0.14222674)], [('n02965783', 'car_mirror', 0.11192344)], [('n03788365', 'mosquito_net', 0.3069361)], [('n02497673', 'Madagascar_cat', 0.35545722)], [('n02130308', 'cheetah', 0.39499432)], [('n02107312', 'miniature_pinscher', 0.20680462)], [('n02130308', 'cheetah', 0.99901485)], [('n03388043', 'fountain', 0.38500673)], [('n03388043', 'fountain', 0.956347)], [('n02504458', 'African_elephant', 0.06465912)], [('n03388043', 'fountain', 0.80843866)], [('n07248320', 'book_jacket', 0.28922963)], [('n02130308', 'cheetah', 0.65541726)], [('n02130308', 'cheetah', 0.09501839)], [('n03388043', 'fountain', 0.98885137)], [('n02130308', 'cheetah', 0.8494039)], [('n02125311', 'cougar', 0.30566117)], [('n03891251', 'park_bench', 0.28888166)], [('n03388043', 'fountain', 0.97864586)], [('n02110341', 'dalmatian', 0.33029512)], [('n03388043', 'fountain', 0.88191545)], [('n02130308', 'cheetah', 0.9805679)], [('n03788365', 'mosquito_net', 0.43872228)], [('n03891251', 'park_bench', 0.11909788)], [('n03891251', 'park_bench', 0.46001127)], [('n02130308', 'cheetah', 0.9391096)], [('n01748264', 'Indian_cobra', 0.45463192)], [('n02123159', 'tiger_cat', 0.08604425)], [('n01855672', 'goose', 0.18648402)], [('n03042490', 'cliff_dwelling', 0.48309496)], [('n03388043', 'fountain', 0.21666622)], [('n02130308', 'cheetah', 0.6154845)], [('n01695060', 'Komodo_dragon', 0.07781505)], [('n03388043', 'fountain', 0.81529176)], [('n02130308', 'cheetah', 0.89988446)], [('n02130308', 'cheetah', 0.96629167)], [('n02130308', 'cheetah', 0.61320436)], [('n02130308', 'cheetah', 0.14980881)], [('n02965783', 'car_mirror', 0.23677605)], [('n02130308', 'cheetah', 0.3487371)], [('n03891251', 'park_bench', 0.2376939)], [('n03042490', 'cliff_dwelling', 0.20955718)], [('n03388043', 'fountain', 0.9593757)], [('n02130308', 'cheetah', 0.99884605)], [('n03388043', 'fountain', 0.71160334)], [('n02480855', 'gorilla', 0.12362564)], [('n04371774', 'swing', 0.13717847)], [('n03388043', 'fountain', 0.43130776)], [('n02130308', 'cheetah', 0.98772824)], [('n02114712', 'red_wolf', 0.06660006)], [('n02130308', 'cheetah', 0.7423791)], [('n04371774', 'swing', 0.17694165)], [('n03388043', 'fountain', 0.83970535)], [('n02130308', 'cheetah', 0.773151)], [('n03388043', 'fountain', 0.28408396)], [('n02114855', 'coyote', 0.16416213)], [('n03891251', 'park_bench', 0.11990029)], [('n03891251', 'park_bench', 0.3869262)], [('n02130308', 'cheetah', 0.62957007)], [('n04275548', 'spider_web', 0.20240924)], [('n03388043', 'fountain', 0.12622023)], [('n03788365', 'mosquito_net', 0.24009304)], [('n02130308', 'cheetah', 0.94060045)], [('n03788365', 'mosquito_net', 0.3993382)], [('n02130308', 'cheetah', 0.6464014)], [('n02130308', 'cheetah', 0.9848267)], [('n03388043', 'fountain', 0.4820479)], [('n04423845', 'thimble', 0.35451493)], [('n02114855', 'coyote', 0.1635395)], [('n03788365', 'mosquito_net', 0.46529052)], [('n04423845', 'thimble', 0.44826984)], [('n02423022', 'gazelle', 0.2166104)], [('n03388043', 'fountain', 0.11446848)], [('n03388043', 'fountain', 0.5442703)], [('n02130308', 'cheetah', 0.9557983)], [('n03388043', 'fountain', 0.33026958)], [('n02130308', 'cheetah', 0.30738673)], [('n04423845', 'thimble', 0.3560228)], [('n03388043', 'fountain', 0.93396133)], [('n02130308', 'cheetah', 0.995773)], [('n01675722', 'banded_gecko', 0.74774796)], [('n02114367', 'timber_wolf', 0.26674628)], [('n02391049', 'zebra', 0.14227398)], [('n03388043', 'fountain', 0.79994696)], [('n02965783', 'car_mirror', 0.17328143)], [('n02437312', 'Arabian_camel', 0.11890948)], [('n02125311', 'cougar', 0.11515069)], [('n03388043', 'fountain', 0.7222348)], [('n03788365', 'mosquito_net', 0.23672834)], [('n02965783', 'car_mirror', 0.44614118)], [('n03891251', 'park_bench', 0.1760558)], [('n02130308', 'cheetah', 0.92722064)], [('n02965783', 'car_mirror', 0.45029095)], [('n02130308', 'cheetah', 0.675678)], [('n07248320', 'book_jacket', 0.11487341)], [('n03388043', 'fountain', 0.42319804)], [('n03388043', 'fountain', 0.99740714)], [('n03388043', 'fountain', 0.9402979)], [('n02497673', 'Madagascar_cat', 0.14350045)], [('n03388043', 'fountain', 0.8683176)], [('n02130308', 'cheetah', 0.5131575)], [('n03388043', 'fountain', 0.99793965)], [('n03388043', 'fountain', 0.80816084)], [('n04371774', 'swing', 0.2672755)], [('n03388043', 'fountain', 0.99533737)], [('n01675722', 'banded_gecko', 0.07499794)], [('n02965783', 'car_mirror', 0.34779748)], [('n02110341', 'dalmatian', 0.5382874)], [('n03788365', 'mosquito_net', 0.6381791)], [('n03788365', 'mosquito_net', 0.27241823)], [('n02130308', 'cheetah', 0.99808013)], [('n09229709', 'bubble', 0.182145)], [('n03388043', 'fountain', 0.69920313)], [('n07248320', 'book_jacket', 0.15865116)], [('n02504013', 'Indian_elephant', 0.13916671)], [('n03388043', 'fountain', 0.21192554)], [('n03532672', 'hook', 0.15085618)], [('n02130308', 'cheetah', 0.71922696)], [('n02130308', 'cheetah', 0.6775324)], [('n03388043', 'fountain', 0.8193065)], [('n02130308', 'cheetah', 0.9371807)], [('n03388043', 'fountain', 0.30113974)], [('n03891251', 'park_bench', 0.1026173)], [('n02130308', 'cheetah', 0.98898715)], [('n02130308', 'cheetah', 0.98889625)], [('n02130308', 'cheetah', 0.98718655)], [('n03388043', 'fountain', 0.4826219)], [('n03891251', 'park_bench', 0.17280051)], [('n03743016', 'megalith', 0.67133796)], [('n03388043', 'fountain', 0.21135794)], [('n03388043', 'fountain', 0.9342021)], [('n02130308', 'cheetah', 0.62857604)], [('n03388043', 'fountain', 0.9825053)], [('n02130308', 'cheetah', 0.67664325)], [('n02130308', 'cheetah', 0.7831781)], [('n03891251', 'park_bench', 0.32180727)], [('n03891251', 'park_bench', 0.1021743)], [('n02130308', 'cheetah', 0.12495731)], [('n02130308', 'cheetah', 0.71054757)], [('n04423845', 'thimble', 0.97381616)], [('n02808440', 'bathtub', 0.40467072)], [('n03788365', 'mosquito_net', 0.27194482)], [('n02423022', 'gazelle', 0.14266442)], [('n02130308', 'cheetah', 0.93314314)], [('n03788365', 'mosquito_net', 0.9006317)], [('n02130308', 'cheetah', 0.7887323)], [('n03388043', 'fountain', 0.62746817)], [('n03388043', 'fountain', 0.45981532)], [('n03388043', 'fountain', 0.2958693)], [('n03891251', 'park_bench', 0.08508815)], [('n04606251', 'wreck', 0.3884765)], [('n03388043', 'fountain', 0.60451496)], [('n03788365', 'mosquito_net', 0.42910153)], [('n04507155', 'umbrella', 0.4878025)], [('n03388043', 'fountain', 0.20583226)], [('n02410509', 'bison', 0.28987625)], [('n02130308', 'cheetah', 0.8080396)], [('n03388043', 'fountain', 0.17847477)], [('n03388043', 'fountain', 0.48877403)], [('n02111500', 'Great_Pyrenees', 0.5578028)], [('n02130308', 'cheetah', 0.22954415)], [('n02130308', 'cheetah', 0.9797934)], [('n02130308', 'cheetah', 0.9991683)], [('n02104365', 'schipperke', 0.15392324)], [('n02130308', 'cheetah', 0.32673818)], [('n03388043', 'fountain', 0.9125438)], [('n04366367', 'suspension_bridge', 0.4208713)], [('n02130308', 'cheetah', 0.9698439)], [('n03891251', 'park_bench', 0.26399618)], [('n03388043', 'fountain', 0.18105613)], [('n02130308', 'cheetah', 0.52173233)], [('n03388043', 'fountain', 0.90261716)], [('n03388043', 'fountain', 0.9988194)], [('n02130308', 'cheetah', 0.7523169)], [('n02130308', 'cheetah', 0.99146855)], [('n02100735', 'English_setter', 0.6156989)], [('n07248320', 'book_jacket', 0.22833958)], [('n02130308', 'cheetah', 0.91683346)], [('n03388043', 'fountain', 0.889703)], [('n02130308', 'cheetah', 0.99287206)], [('n03388043', 'fountain', 0.74511045)], [('n02130308', 'cheetah', 0.9601639)], [('n02130308', 'cheetah', 0.9755195)], [('n02130308', 'cheetah', 0.49557617)], [('n03891251', 'park_bench', 0.1116777)], [('n02130308', 'cheetah', 0.5222089)], [('n02130308', 'cheetah', 0.8238675)], [('n03388043', 'fountain', 0.92843634)], [('n03388043', 'fountain', 0.89048344)], [('n03388043', 'fountain', 0.53411275)], [('n02130308', 'cheetah', 0.86449677)], [('n03388043', 'fountain', 0.88507545)], [('n03042490', 'cliff_dwelling', 0.24728589)], [('n02130308', 'cheetah', 0.9834472)], [('n03388043', 'fountain', 0.8845265)], [('n03388043', 'fountain', 0.46644133)], [('n03788365', 'mosquito_net', 0.28353837)], [('n07248320', 'book_jacket', 0.21940799)], [('n02391049', 'zebra', 0.24987149)], [('n02133161', 'American_black_bear', 0.10957599)], [('n03388043', 'fountain', 0.99761754)], [('n03388043', 'fountain', 0.6495728)], [('n02130308', 'cheetah', 0.9939275)], [('n02965783', 'car_mirror', 0.37551475)], [('n03532672', 'hook', 0.1693555)], [('n03388043', 'fountain', 0.9125776)], [('n02497673', 'Madagascar_cat', 0.15165487)], [('n04589890', 'window_screen', 0.26427594)], [('n03388043', 'fountain', 0.16903073)], [('n02130308', 'cheetah', 0.52934384)], [('n02130308', 'cheetah', 0.6872709)], [('n02504458', 'African_elephant', 0.34150782)], [('n03891251', 'park_bench', 0.096476085)], [('n03891251', 'park_bench', 0.09941593)], [('n07248320', 'book_jacket', 0.10488692)], [('n03388043', 'fountain', 0.56309223)], [('n04589890', 'window_screen', 0.16732742)], [('n03388043', 'fountain', 0.48037422)], [('n02130308', 'cheetah', 0.8223172)], [('n03891251', 'park_bench', 0.07145076)], [('n02130308', 'cheetah', 0.3895373)], [('n02128385', 'leopard', 0.8155543)], [('n03388043', 'fountain', 0.4830183)], [('n03388043', 'fountain', 0.59408766)], [('n03388043', 'fountain', 0.31683943)], [('n02130308', 'cheetah', 0.9719499)], [('n02130308', 'cheetah', 0.9966389)], [('n03388043', 'fountain', 0.879486)], [('n02114855', 'coyote', 0.23640147)], [('n03388043', 'fountain', 0.9044741)], [('n03388043', 'fountain', 0.51171416)], [('n02130308', 'cheetah', 0.7031681)], [('n03788365', 'mosquito_net', 0.74790263)], [('n03388043', 'fountain', 0.32989368)], [('n03388043', 'fountain', 0.9503225)], [('n03388043', 'fountain', 0.81255877)], [('n03388043', 'fountain', 0.984979)], [('n02403003', 'ox', 0.52643454)], [('n02130308', 'cheetah', 0.9926859)], [('n04589890', 'window_screen', 0.13828176)], [('n02130308', 'cheetah', 0.91013336)], [('n02130308', 'cheetah', 0.98893625)], [('n02109047', 'Great_Dane', 0.6554597)], [('n03388043', 'fountain', 0.89283407)], [('n03388043', 'fountain', 0.7740253)], [('n02395406', 'hog', 0.2019401)], [('n02130308', 'cheetah', 0.5828654)], [('n02130308', 'cheetah', 0.527014)], [('n03388043', 'fountain', 0.85983604)], [('n02125311', 'cougar', 0.27026734)], [('n03388043', 'fountain', 0.2969861)], [('n04423845', 'thimble', 0.99791604)], [('n03958227', 'plastic_bag', 0.122443244)], [('n09246464', 'cliff', 0.3606204)], [('n03388043', 'fountain', 0.6995433)], [('n02130308', 'cheetah', 0.73197013)], [('n02130308', 'cheetah', 0.8135253)], [('n02965783', 'car_mirror', 0.28341714)], [('n02130308', 'cheetah', 0.53747207)], [('n02130308', 'cheetah', 0.09478946)], [('n06359193', 'web_site', 0.060809605)], [('n03388043', 'fountain', 0.98203677)], [('n03388043', 'fountain', 0.78356886)], [('n02417914', 'ibex', 0.49508458)], [('n02130308', 'cheetah', 0.8099162)], [('n03891251', 'park_bench', 0.08665435)], [('n02125311', 'cougar', 0.1670257)], [('n02130308', 'cheetah', 0.4455136)], [('n03388043', 'fountain', 0.09471082)], [('n02417914', 'ibex', 0.13193022)], [('n03388043', 'fountain', 0.8148407)], [('n04589890', 'window_screen', 0.06080134)], [('n02130308', 'cheetah', 0.07078994)], [('n03388043', 'fountain', 0.61762494)], [('n02130308', 'cheetah', 0.6599215)], [('n02130308', 'cheetah', 0.9552468)], [('n02999410', 'chain', 0.23431419)], [('n02130308', 'cheetah', 0.9875514)], [('n02130308', 'cheetah', 0.9421153)], [('n03891251', 'park_bench', 0.08400569)], [('n03788365', 'mosquito_net', 0.5656883)], [('n02130308', 'cheetah', 0.88711554)], [('n03388043', 'fountain', 0.19112818)], [('n02391049', 'zebra', 0.42311534)], [('n03388043', 'fountain', 0.8062512)], [('n02130308', 'cheetah', 0.4769591)], [('n02107312', 'miniature_pinscher', 0.1536188)], [('n03388043', 'fountain', 0.24125247)], [('n02965783', 'car_mirror', 0.37035)], [('n02125311', 'cougar', 0.14090215)], [('n03388043', 'fountain', 0.7966511)], [('n03388043', 'fountain', 0.73419756)], [('n03788365', 'mosquito_net', 0.5945804)], [('n03388043', 'fountain', 0.0916459)], [('n02130308', 'cheetah', 0.17869619)], [('n02480855', 'gorilla', 0.16637138)], [('n02965783', 'car_mirror', 0.2583796)], [('n02130308', 'cheetah', 0.84657377)], [('n03388043', 'fountain', 0.11729756)], [('n02130308', 'cheetah', 0.20597798)], [('n02130308', 'cheetah', 0.96439725)], [('n03388043', 'fountain', 0.18451358)], [('n02130308', 'cheetah', 0.32736337)], [('n02130308', 'cheetah', 0.9687262)], [('n02130308', 'cheetah', 0.31039324)], [('n02130308', 'cheetah', 0.99204105)], [('n02130308', 'cheetah', 0.9682689)], [('n03388043', 'fountain', 0.39820647)], [('n03388043', 'fountain', 0.68480444)], [('n02120505', 'grey_fox', 0.37839055)], [('n03891251', 'park_bench', 0.20582642)], [('n03063689', 'coffeepot', 0.21848437)], [('n03388043', 'fountain', 0.8574251)], [('n03388043', 'fountain', 0.17578298)], [('n02130308', 'cheetah', 0.35085532)], [('n02643566', 'lionfish', 0.09309779)], [('n03388043', 'fountain', 0.6728599)], [('n02130308', 'cheetah', 0.9899921)], [('n03042490', 'cliff_dwelling', 0.29949751)], [('n03042490', 'cliff_dwelling', 0.09931975)], [('n04589890', 'window_screen', 0.081041284)], [('n03388043', 'fountain', 0.27782765)], [('n02130308', 'cheetah', 0.9892371)], [('n03388043', 'fountain', 0.5853718)], [('n02130308', 'cheetah', 0.8751419)], [('n04371774', 'swing', 0.82843864)], [('n03388043', 'fountain', 0.53967184)], [('n02130308', 'cheetah', 0.69572985)], [('n07248320', 'book_jacket', 0.14503278)], [('n03388043', 'fountain', 0.75624245)], [('n03160309', 'dam', 0.15382472)], [('n03388043', 'fountain', 0.5004064)], [('n02115641', 'dingo', 0.1613866)], [('n02130308', 'cheetah', 0.95393926)], [('n02480855', 'gorilla', 0.14123948)], [('n03388043', 'fountain', 0.9866181)], [('n03388043', 'fountain', 0.2841917)], [('n03388043', 'fountain', 0.88548064)], [('n02130308', 'cheetah', 0.44841567)], [('n03388043', 'fountain', 0.27538982)], [('n04589890', 'window_screen', 0.38828263)], [('n02391049', 'zebra', 0.28611243)], [('n02130308', 'cheetah', 0.5822802)], [('n02808440', 'bathtub', 0.36215526)], [('n02130308', 'cheetah', 0.4970743)], [('n03388043', 'fountain', 0.54585844)], [('n03388043', 'fountain', 0.7613267)], [('n02130308', 'cheetah', 0.5619429)], [('n02965783', 'car_mirror', 0.1148753)], [('n03388043', 'fountain', 0.80835766)], [('n02130308', 'cheetah', 0.5508322)], [('n03388043', 'fountain', 0.855549)], [('n02130308', 'cheetah', 0.75662607)], [('n03388043', 'fountain', 0.25432044)], [('n02130308', 'cheetah', 0.8133302)], [('n02130308', 'cheetah', 0.3899516)], [('n02130308', 'cheetah', 0.987199)], [('n03788365', 'mosquito_net', 0.4131633)], [('n02130308', 'cheetah', 0.53467715)], [('n03042490', 'cliff_dwelling', 0.11294933)], [('n02130308', 'cheetah', 0.9974861)], [('n02130308', 'cheetah', 0.8914729)], [('n02130308', 'cheetah', 0.5289625)], [('n03891251', 'park_bench', 0.32996607)], [('n04589890', 'window_screen', 0.28070575)], [('n03388043', 'fountain', 0.16820341)], [('n03891251', 'park_bench', 0.09212285)], [('n03388043', 'fountain', 0.53151536)], [('n02317335', 'starfish', 0.07966616)], [('n03388043', 'fountain', 0.9807553)], [('n03388043', 'fountain', 0.40086943)], [('n02130308', 'cheetah', 0.9471651)], [('n04589890', 'window_screen', 0.19430083)], [('n04589890', 'window_screen', 0.10641129)], [('n03388043', 'fountain', 0.8895795)], [('n04589890', 'window_screen', 0.34849)], [('n02504458', 'African_elephant', 0.21211608)], [('n02965783', 'car_mirror', 0.25610846)], [('n02130308', 'cheetah', 0.9828386)], [('n03388043', 'fountain', 0.15414208)], [('n02480855', 'gorilla', 0.72069955)], [('n03388043', 'fountain', 0.8622431)], [('n03891251', 'park_bench', 0.23587209)], [('n03388043', 'fountain', 0.3474213)], [('n03788365', 'mosquito_net', 0.37131372)], [('n02130308', 'cheetah', 0.8294534)], [('n03891251', 'park_bench', 0.18915002)], [('n03388043', 'fountain', 0.22597136)], [('n02130308', 'cheetah', 0.67752004)], [('n02130308', 'cheetah', 0.8038486)], [('n02130308', 'cheetah', 0.93333817)], [('n03388043', 'fountain', 0.72471786)], [('n02130308', 'cheetah', 0.708249)], [('n03388043', 'fountain', 0.094287634)], [('n04371774', 'swing', 0.6875983)], [('n03388043', 'fountain', 0.18025656)], [('n03388043', 'fountain', 0.0968533)], [('n03891251', 'park_bench', 0.3184461)], [('n02130308', 'cheetah', 0.99542737)], [('n03388043', 'fountain', 0.67007667)], [('n03388043', 'fountain', 0.44489163)], [('n02130308', 'cheetah', 0.13762267)], [('n02480855', 'gorilla', 0.22005183)], [('n02437312', 'Arabian_camel', 0.60017544)], [('n02110185', 'Siberian_husky', 0.20003876)], [('n02130308', 'cheetah', 0.9958067)], [('n03788365', 'mosquito_net', 0.578417)], [('n02130308', 'cheetah', 0.98554647)], [('n03388043', 'fountain', 0.64907634)], [('n03388043', 'fountain', 0.3110883)], [('n03388043', 'fountain', 0.43283933)], [('n02130308', 'cheetah', 0.5095302)], [('n03388043', 'fountain', 0.85370713)], [('n03498962', 'hatchet', 0.04869315)], [('n02130308', 'cheetah', 0.9822031)], [('n02114855', 'coyote', 0.2859738)], [('n02130308', 'cheetah', 0.3384838)], [('n02130308', 'cheetah', 0.9883388)], [('n03388043', 'fountain', 0.8069856)], [('n02130308', 'cheetah', 0.22116417)], [('n02130308', 'cheetah', 0.9945629)], [('n03388043', 'fountain', 0.77135533)], [('n02130308', 'cheetah', 0.8602344)], [('n03388043', 'fountain', 0.37420171)], [('n03388043', 'fountain', 0.19087824)], [('n03388043', 'fountain', 0.9130586)], [('n03788365', 'mosquito_net', 0.32654837)], [('n03388043', 'fountain', 0.60083705)], [('n02125311', 'cougar', 0.23659484)], [('n03388043', 'fountain', 0.35031235)], [('n02130308', 'cheetah', 0.98150074)], [('n02130308', 'cheetah', 0.35859364)], [('n02130308', 'cheetah', 0.16223015)], [('n02130308', 'cheetah', 0.79320866)], [('n02130308', 'cheetah', 0.5531956)], [('n03891251', 'park_bench', 0.40269652)], [('n03388043', 'fountain', 0.7832925)], [('n03388043', 'fountain', 0.494487)], [('n03388043', 'fountain', 0.23997)], [('n02114367', 'timber_wolf', 0.42195606)], [('n02655020', 'puffer', 0.5164087)], [('n02480855', 'gorilla', 0.15280361)], [('n02114712', 'red_wolf', 0.123651005)], [('n03788365', 'mosquito_net', 0.408947)], [('n03388043', 'fountain', 0.96192)], [('n04423845', 'thimble', 0.5999674)], [('n03388043', 'fountain', 0.27747974)], [('n02130308', 'cheetah', 0.951348)], [('n03388043', 'fountain', 0.40820184)], [('n02130308', 'cheetah', 0.9391688)], [('n02130308', 'cheetah', 0.32276893)], [('n02114367', 'timber_wolf', 0.32505098)], [('n03388043', 'fountain', 0.57340276)], [('n02130308', 'cheetah', 0.49656036)], [('n02130308', 'cheetah', 0.6485467)], [('n03388043', 'fountain', 0.84917694)], [('n03388043', 'fountain', 0.46060655)], [('n03388043', 'fountain', 0.6017422)], [('n02130308', 'cheetah', 0.38994235)], [('n02130308', 'cheetah', 0.75512564)], [('n03388043', 'fountain', 0.7441534)], [('n02130308', 'cheetah', 0.98591655)], [('n03388043', 'fountain', 0.39002183)], [('n03388043', 'fountain', 0.91626513)], [('n02454379', 'armadillo', 0.65184045)], [('n02099712', 'Labrador_retriever', 0.2502963)], [('n03788365', 'mosquito_net', 0.49298805)], [('n02130308', 'cheetah', 0.9834358)], [('n02363005', 'beaver', 0.182969)], [('n07753592', 'banana', 0.07656967)], [('n09246464', 'cliff', 0.45122644)], [('n03891251', 'park_bench', 0.09750536)], [('n03042490', 'cliff_dwelling', 0.37939018)], [('n04371774', 'swing', 0.20756821)], [('n02130308', 'cheetah', 0.6503399)], [('n04371774', 'swing', 0.79653347)], [('n02130308', 'cheetah', 0.45879698)], [('n03388043', 'fountain', 0.952873)], [('n04371774', 'swing', 0.5629922)], [('n03388043', 'fountain', 0.33398896)], [('n04423845', 'thimble', 0.77671844)], [('n02808440', 'bathtub', 0.1513299)], [('n03388043', 'fountain', 0.64196473)], [('n02504013', 'Indian_elephant', 0.3214336)], [('n03388043', 'fountain', 0.8646253)], [('n02130308', 'cheetah', 0.9038933)], [('n02130308', 'cheetah', 0.9910657)], [('n02130308', 'cheetah', 0.19084628)], [('n02130308', 'cheetah', 0.9842429)], [('n03388043', 'fountain', 0.9926589)], [('n03388043', 'fountain', 0.2797513)], [('n02437616', 'llama', 0.23035486)], [('n02808440', 'bathtub', 0.39099264)], [('n04366367', 'suspension_bridge', 0.11432352)], [('n02130308', 'cheetah', 0.9921409)], [('n03388043', 'fountain', 0.54450697)], [('n02130308', 'cheetah', 0.7365759)], [('n02410509', 'bison', 0.13387448)], [('n02130308', 'cheetah', 0.9356721)], [('n02130308', 'cheetah', 0.6633745)], [('n02130308', 'cheetah', 0.8382527)], [('n03388043', 'fountain', 0.73114115)], [('n03388043', 'fountain', 0.31394538)], [('n02130308', 'cheetah', 0.89072895)], [('n03891251', 'park_bench', 0.10722305)], [('n04371774', 'swing', 0.22158654)], [('n02130308', 'cheetah', 0.9833053)], [('n02130308', 'cheetah', 0.98589534)], [('n02130308', 'cheetah', 0.9729408)], [('n02504458', 'African_elephant', 0.19710687)], [('n03388043', 'fountain', 0.6394817)], [('n03388043', 'fountain', 0.31470734)], [('n04589890', 'window_screen', 0.13717501)], [('n02130308', 'cheetah', 0.9998735)], [('n02100735', 'English_setter', 0.59696156)], [('n02965783', 'car_mirror', 0.24856834)], [('n03388043', 'fountain', 0.86021125)], [('n04371774', 'swing', 0.15473579)], [('n03891251', 'park_bench', 0.07968118)], [('n02130308', 'cheetah', 0.9755798)], [('n02130308', 'cheetah', 0.7766973)], [('n04371774', 'swing', 0.12795357)], [('n03388043', 'fountain', 0.9879246)], [('n02480855', 'gorilla', 0.15076396)], [('n02130308', 'cheetah', 0.56558865)], [('n07248320', 'book_jacket', 0.061149158)], [('n01855672', 'goose', 0.2644035)], [('n03388043', 'fountain', 0.7546797)], [('n03388043', 'fountain', 0.9417483)], [('n02965783', 'car_mirror', 0.39019322)], [('n02965783', 'car_mirror', 0.33029974)], [('n03388043', 'fountain', 0.812143)], [('n03388043', 'fountain', 0.993349)], [('n03388043', 'fountain', 0.093587615)], [('n02130308', 'cheetah', 0.24627425)], [('n03388043', 'fountain', 0.83202565)], [('n02114855', 'coyote', 0.1898771)], [('n03388043', 'fountain', 0.31720352)], [('n02114548', 'white_wolf', 0.22285666)], [('n03388043', 'fountain', 0.43541706)], [('n02130308', 'cheetah', 0.7838947)], [('n03388043', 'fountain', 0.71640795)], [('n02130308', 'cheetah', 0.46148822)], [('n03388043', 'fountain', 0.85034686)], [('n07248320', 'book_jacket', 0.149477)], [('n02130308', 'cheetah', 0.9053668)], [('n03388043', 'fountain', 0.39306715)], [('n03388043', 'fountain', 0.75365925)], [('n02415577', 'bighorn', 0.24028794)], [('n02130308', 'cheetah', 0.903755)], [('n02130308', 'cheetah', 0.7507806)], [('n03388043', 'fountain', 0.29564327)], [('n03388043', 'fountain', 0.9973483)], [('n03042490', 'cliff_dwelling', 0.25470692)], [('n03891251', 'park_bench', 0.17601876)], [('n02114367', 'timber_wolf', 0.21850225)], [('n02114855', 'coyote', 0.3525087)], [('n09246464', 'cliff', 0.23663603)], [('n02130308', 'cheetah', 0.94633704)], [('n02130308', 'cheetah', 0.8222053)], [('n03891251', 'park_bench', 0.29800007)], [('n03388043', 'fountain', 0.28213075)], [('n04589890', 'window_screen', 0.17748743)], [('n03788365', 'mosquito_net', 0.8227797)], [('n03388043', 'fountain', 0.9643867)], [('n02391049', 'zebra', 0.52846944)], [('n02417914', 'ibex', 0.07311582)], [('n02130308', 'cheetah', 0.9920827)], [('n03388043', 'fountain', 0.71333146)], [('n03388043', 'fountain', 0.1943638)], [('n03388043', 'fountain', 0.8406177)], [('n03388043', 'fountain', 0.9164166)], [('n02130308', 'cheetah', 0.9441171)], [('n03388043', 'fountain', 0.9918794)], [('n02130308', 'cheetah', 0.582005)], [('n02130308', 'cheetah', 0.54611546)], [('n03388043', 'fountain', 0.19471578)], [('n03891251', 'park_bench', 0.12954982)], [('n03388043', 'fountain', 0.49637896)], [('n01877812', 'wallaby', 0.13237937)], [('n03388043', 'fountain', 0.89355695)], [('n02130308', 'cheetah', 0.9945024)], [('n03388043', 'fountain', 0.6975016)], [('n03788365', 'mosquito_net', 0.49175265)], [('n02130308', 'cheetah', 0.97345823)], [('n03388043', 'fountain', 0.9801917)], [('n02130308', 'cheetah', 0.9206267)], [('n04423845', 'thimble', 0.71802616)], [('n02504458', 'African_elephant', 0.54318726)], [('n02130308', 'cheetah', 0.5874797)], [('n03388043', 'fountain', 0.6227261)], [('n02965783', 'car_mirror', 0.4303286)], [('n02130308', 'cheetah', 0.18746567)], [('n02130308', 'cheetah', 0.48599735)], [('n03788365', 'mosquito_net', 0.22401454)], [('n03388043', 'fountain', 0.7163957)], [('n03388043', 'fountain', 0.7492481)], [('n03958227', 'plastic_bag', 0.10617014)], [('n02130308', 'cheetah', 0.97350353)], [('n02130308', 'cheetah', 0.9980135)], [('n02480855', 'gorilla', 0.16637138)], [('n03388043', 'fountain', 0.81796014)], [('n01855672', 'goose', 0.2644035)], [('n02423022', 'gazelle', 0.1889775)], [('n03388043', 'fountain', 0.64352185)], [('n03788365', 'mosquito_net', 0.86886436)], [('n03388043', 'fountain', 0.4929051)], [('n02130308', 'cheetah', 0.99204105)], [('n04589890', 'window_screen', 0.19430083)], [('n03388043', 'fountain', 0.9125776)], [('n02110341', 'dalmatian', 0.104983896)], [('n04371774', 'swing', 0.17962627)], [('n02130308', 'cheetah', 0.97166765)], [('n02110341', 'dalmatian', 0.939961)], [('n03498962', 'hatchet', 0.08375412)], [('n02130308', 'cheetah', 0.9659305)], [('n03891251', 'park_bench', 0.08400569)], [('n02130308', 'cheetah', 0.9032757)], [('n03743016', 'megalith', 0.22741283)], [('n03388043', 'fountain', 0.3474213)], [('n02437616', 'llama', 0.42894307)], [('n02965783', 'car_mirror', 0.25510183)], [('n02504013', 'Indian_elephant', 0.08797813)], [('n03388043', 'fountain', 0.9988194)], [('n03388043', 'fountain', 0.22233868)], [('n03388043', 'fountain', 0.49637896)], [('n02130308', 'cheetah', 0.93314314)], [('n02130308', 'cheetah', 0.7831782)], [('n03788365', 'mosquito_net', 0.56158733)], [('n02130308', 'cheetah', 0.9836474)], [('n03388043', 'fountain', 0.9820342)], [('n03388043', 'fountain', 0.21135794)], [('n02130308', 'cheetah', 0.9528929)], [('n02130308', 'cheetah', 0.68013906)], [('n02130308', 'cheetah', 0.9945024)], [('n02130308', 'cheetah', 0.9700154)], [('n03042490', 'cliff_dwelling', 0.19041564)], [('n02504013', 'Indian_elephant', 0.25328785)], [('n03388043', 'fountain', 0.71640795)], [('n02130308', 'cheetah', 0.7736311)], [('n03388043', 'fountain', 0.43174177)], [('n03388043', 'fountain', 0.83618623)], [('n03388043', 'fountain', 0.7796511)], [('n03891251', 'park_bench', 0.68136907)], [('n03388043', 'fountain', 0.33398896)], [('n02504013', 'Indian_elephant', 0.4654535)], [('n03388043', 'fountain', 0.5790054)], [('n07248320', 'book_jacket', 0.2080608)], [('n02346627', 'porcupine', 0.09624559)], [('n03388043', 'fountain', 0.66047144)], [('n03388043', 'fountain', 0.16026351)], [('n02130308', 'cheetah', 0.9997607)], [('n03388043', 'fountain', 0.71435875)], [('n04371774', 'swing', 0.16992536)], [('n03388043', 'fountain', 0.53411275)], [('n03388043', 'fountain', 0.89355695)], [('n02410509', 'bison', 0.23474261)], [('n03388043', 'fountain', 0.95038164)], [('n03388043', 'fountain', 0.6779015)], [('n02965783', 'car_mirror', 0.44614094)], [('n07248320', 'book_jacket', 0.23245472)]]\n"
     ]
    }
   ],
   "source": [
    "pred = decode_predictions(evaluation2, top=1)\n",
    "print('Predicted:', pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der ImageNet-Datensatz auch die Klassen cheetah und leopard enthält, können wir sogar ohne transfer learning das vortrainierte Netzwerk evaluieren. Interpretiere alle Klassen außer cheetah und leopard als unknown und berechne wie im vorherigen Schritt die Confusion matrix und den ROC AUC score für die Klasse cheetah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n02114855', 'unknown', 0.4485118)]\n",
      "[('n03788365', 'unknown', 0.2686611)]\n",
      "[('n03891251', 'unknown', 0.10064046)]\n",
      "[('n04371774', 'unknown', 0.22957754)]\n",
      "[('n02114855', 'unknown', 0.45637178)]\n",
      "[('n03388043', 'unknown', 0.97615653)]\n",
      "[('n03891251', 'unknown', 0.113026984)]\n",
      "[('n02130308', 'cheetah', 0.91280824)]\n",
      "[('n03388043', 'unknown', 0.18641663)]\n",
      "[('n03388043', 'unknown', 0.96286756)]\n",
      "[('n03388043', 'unknown', 0.97800064)]\n",
      "[('n03743016', 'unknown', 0.46531516)]\n",
      "[('n15075141', 'unknown', 0.63400984)]\n",
      "[('n02130308', 'cheetah', 0.36803973)]\n",
      "[('n03788365', 'unknown', 0.33781677)]\n",
      "[('n03388043', 'unknown', 0.63867)]\n",
      "[('n03388043', 'unknown', 0.7120134)]\n",
      "[('n02125311', 'unknown', 0.16781376)]\n",
      "[('n03388043', 'unknown', 0.2860591)]\n",
      "[('n09193705', 'unknown', 0.24350822)]\n",
      "[('n02130308', 'cheetah', 0.17853816)]\n",
      "[('n01877812', 'unknown', 0.428212)]\n",
      "[('n02130308', 'cheetah', 0.8734413)]\n",
      "[('n02391049', 'unknown', 0.46828696)]\n",
      "[('n02130308', 'cheetah', 0.9901253)]\n",
      "[('n04371774', 'unknown', 0.15860552)]\n",
      "[('n03388043', 'unknown', 0.25812358)]\n",
      "[('n03388043', 'unknown', 0.7995078)]\n",
      "[('n02497673', 'unknown', 0.8590698)]\n",
      "[('n03388043', 'unknown', 0.96922195)]\n",
      "[('n02130308', 'cheetah', 0.5669322)]\n",
      "[('n03388043', 'unknown', 0.21539517)]\n",
      "[('n03388043', 'unknown', 0.9742063)]\n",
      "[('n04371774', 'unknown', 0.8624022)]\n",
      "[('n03388043', 'unknown', 0.84824264)]\n",
      "[('n02965783', 'unknown', 0.27982944)]\n",
      "[('n03388043', 'unknown', 0.50372356)]\n",
      "[('n03388043', 'unknown', 0.3379324)]\n",
      "[('n02105412', 'unknown', 0.13040696)]\n",
      "[('n02130308', 'cheetah', 0.9422332)]\n",
      "[('n01855672', 'unknown', 0.21248884)]\n",
      "[('n02130308', 'cheetah', 0.9340594)]\n",
      "[('n03388043', 'unknown', 0.5655494)]\n",
      "[('n02128925', 'unknown', 0.37905586)]\n",
      "[('n02130308', 'cheetah', 0.17885485)]\n",
      "[('n02130308', 'cheetah', 0.93868583)]\n",
      "[('n03388043', 'unknown', 0.27300423)]\n",
      "[('n02130308', 'cheetah', 0.9113838)]\n",
      "[('n03498962', 'unknown', 0.08375412)]\n",
      "[('n02130308', 'cheetah', 0.9979772)]\n",
      "[('n02130308', 'cheetah', 0.98583996)]\n",
      "[('n03388043', 'unknown', 0.17576833)]\n",
      "[('n02480855', 'unknown', 0.07467955)]\n",
      "[('n03788365', 'unknown', 0.88445264)]\n",
      "[('n02391049', 'unknown', 0.8323043)]\n",
      "[('n02410509', 'unknown', 0.2890928)]\n",
      "[('n03388043', 'unknown', 0.08426755)]\n",
      "[('n03388043', 'unknown', 0.20591642)]\n",
      "[('n02130308', 'cheetah', 0.68013906)]\n",
      "[('n02114548', 'unknown', 0.40428647)]\n",
      "[('n02965783', 'unknown', 0.17723554)]\n",
      "[('n03388043', 'unknown', 0.5720468)]\n",
      "[('n03388043', 'unknown', 0.8849891)]\n",
      "[('n02130308', 'cheetah', 0.8978765)]\n",
      "[('n03388043', 'unknown', 0.52928525)]\n",
      "[('n03388043', 'unknown', 0.8750907)]\n",
      "[('n03958227', 'unknown', 0.24608329)]\n",
      "[('n03042490', 'unknown', 0.15751168)]\n",
      "[('n02410509', 'unknown', 0.65539706)]\n",
      "[('n03388043', 'unknown', 0.95038164)]\n",
      "[('n03042490', 'unknown', 0.19041564)]\n",
      "[('n02130308', 'cheetah', 0.36671934)]\n",
      "[('n01756291', 'unknown', 0.43752557)]\n",
      "[('n03388043', 'unknown', 0.69088364)]\n",
      "[('n03388043', 'unknown', 0.17273818)]\n",
      "[('n03388043', 'unknown', 0.9401031)]\n",
      "[('n03388043', 'unknown', 0.544642)]\n",
      "[('n02130308', 'cheetah', 0.26873538)]\n",
      "[('n02130308', 'cheetah', 0.99646497)]\n",
      "[('n02130308', 'cheetah', 0.30068493)]\n",
      "[('n02130308', 'cheetah', 0.18951732)]\n",
      "[('n02130308', 'cheetah', 0.48314652)]\n",
      "[('n03388043', 'unknown', 0.6513552)]\n",
      "[('n02130308', 'cheetah', 0.9955244)]\n",
      "[('n03388043', 'unknown', 0.43448028)]\n",
      "[('n02128385', 'leopard', 0.44170153)]\n",
      "[('n03388043', 'unknown', 0.69503754)]\n",
      "[('n02965783', 'unknown', 0.26490712)]\n",
      "[('n03388043', 'unknown', 0.66229516)]\n",
      "[('n03388043', 'unknown', 0.8716154)]\n",
      "[('n03388043', 'unknown', 0.8900832)]\n",
      "[('n02130308', 'cheetah', 0.70363945)]\n",
      "[('n02098286', 'unknown', 0.08118564)]\n",
      "[('n02130308', 'cheetah', 0.842136)]\n",
      "[('n03388043', 'unknown', 0.98118526)]\n",
      "[('n03388043', 'unknown', 0.9671561)]\n",
      "[('n02130308', 'cheetah', 0.27657798)]\n",
      "[('n03388043', 'unknown', 0.9093265)]\n",
      "[('n03388043', 'unknown', 0.8627345)]\n",
      "[('n03388043', 'unknown', 0.15254612)]\n",
      "[('n02130308', 'cheetah', 0.99566746)]\n",
      "[('n03388043', 'unknown', 0.7822586)]\n",
      "[('n03891251', 'unknown', 0.332368)]\n",
      "[('n02130308', 'cheetah', 0.6180662)]\n",
      "[('n03388043', 'unknown', 0.64342374)]\n",
      "[('n03388043', 'unknown', 0.95780426)]\n",
      "[('n02410509', 'unknown', 0.06358359)]\n",
      "[('n03788365', 'unknown', 0.16614729)]\n",
      "[('n02130308', 'cheetah', 0.98817027)]\n",
      "[('n02965783', 'unknown', 0.36270612)]\n",
      "[('n03388043', 'unknown', 0.6909481)]\n",
      "[('n02892201', 'unknown', 0.11124743)]\n",
      "[('n03388043', 'unknown', 0.82719713)]\n",
      "[('n04371774', 'unknown', 0.09934311)]\n",
      "[('n02965783', 'unknown', 0.3823005)]\n",
      "[('n03891251', 'unknown', 0.20658867)]\n",
      "[('n04589890', 'unknown', 0.20688571)]\n",
      "[('n03388043', 'unknown', 0.22233868)]\n",
      "[('n03388043', 'unknown', 0.36211878)]\n",
      "[('n02130308', 'cheetah', 0.91404283)]\n",
      "[('n03388043', 'unknown', 0.17328684)]\n",
      "[('n02130308', 'cheetah', 0.9854945)]\n",
      "[('n04423845', 'unknown', 0.38958976)]\n",
      "[('n02130308', 'cheetah', 0.9137152)]\n",
      "[('n03388043', 'unknown', 0.33872053)]\n",
      "[('n03388043', 'unknown', 0.30891278)]\n",
      "[('n03160309', 'unknown', 0.15776281)]\n",
      "[('n02130308', 'cheetah', 0.9748312)]\n",
      "[('n02107312', 'unknown', 0.40338418)]\n",
      "[('n02417914', 'unknown', 0.17281748)]\n",
      "[('n03388043', 'unknown', 0.91531986)]\n",
      "[('n02130308', 'cheetah', 0.3372228)]\n",
      "[('n02965783', 'unknown', 0.2966119)]\n",
      "[('n03388043', 'unknown', 0.29685786)]\n",
      "[('n03388043', 'unknown', 0.6345985)]\n",
      "[('n02130308', 'cheetah', 0.80193067)]\n",
      "[('n02130308', 'cheetah', 0.3388494)]\n",
      "[('n02130308', 'cheetah', 0.94871575)]\n",
      "[('n03042490', 'unknown', 0.1345378)]\n",
      "[('n03388043', 'unknown', 0.99032146)]\n",
      "[('n02130308', 'cheetah', 0.9612684)]\n",
      "[('n03388043', 'unknown', 0.84723204)]\n",
      "[('n02480855', 'unknown', 0.1577619)]\n",
      "[('n03388043', 'unknown', 0.94693595)]\n",
      "[('n03388043', 'unknown', 0.9983339)]\n",
      "[('n04371774', 'unknown', 0.1979082)]\n",
      "[('n03891251', 'unknown', 0.72263587)]\n",
      "[('n03388043', 'unknown', 0.97680306)]\n",
      "[('n03388043', 'unknown', 0.8674678)]\n",
      "[('n03388043', 'unknown', 0.9330591)]\n",
      "[('n03042490', 'unknown', 0.11448119)]\n",
      "[('n02130308', 'cheetah', 0.95007056)]\n",
      "[('n02130308', 'cheetah', 0.7936924)]\n",
      "[('n02130308', 'cheetah', 0.72003686)]\n",
      "[('n03388043', 'unknown', 0.72507733)]\n",
      "[('n02130308', 'cheetah', 0.42630067)]\n",
      "[('n03388043', 'unknown', 0.4813579)]\n",
      "[('n02094433', 'unknown', 0.16299687)]\n",
      "[('n02793495', 'unknown', 0.08154502)]\n",
      "[('n02130308', 'cheetah', 0.97193253)]\n",
      "[('n02130308', 'cheetah', 0.6784697)]\n",
      "[('n07248320', 'unknown', 0.2080608)]\n",
      "[('n02965783', 'unknown', 0.26654622)]\n",
      "[('n02130308', 'cheetah', 0.9083858)]\n",
      "[('n03388043', 'unknown', 0.9957795)]\n",
      "[('n02130308', 'cheetah', 0.463532)]\n",
      "[('n02130308', 'cheetah', 0.61389387)]\n",
      "[('n03388043', 'unknown', 0.8223227)]\n",
      "[('n03388043', 'unknown', 0.76999176)]\n",
      "[('n01855672', 'unknown', 0.20069627)]\n",
      "[('n03388043', 'unknown', 0.55104315)]\n",
      "[('n02130308', 'cheetah', 0.84459317)]\n",
      "[('n02130308', 'cheetah', 0.99978906)]\n",
      "[('n02130308', 'cheetah', 0.90853566)]\n",
      "[('n03388043', 'unknown', 0.23016347)]\n",
      "[('n03388043', 'unknown', 0.10317724)]\n",
      "[('n03788365', 'unknown', 0.22873986)]\n",
      "[('n03388043', 'unknown', 0.24585073)]\n",
      "[('n03958227', 'unknown', 0.23734029)]\n",
      "[('n03388043', 'unknown', 0.7296057)]\n",
      "[('n03388043', 'unknown', 0.6204165)]\n",
      "[('n03388043', 'unknown', 0.85723585)]\n",
      "[('n02130308', 'cheetah', 0.9485855)]\n",
      "[('n03388043', 'unknown', 0.4022922)]\n",
      "[('n02130308', 'cheetah', 0.99725145)]\n",
      "[('n03388043', 'unknown', 0.68323153)]\n",
      "[('n03388043', 'unknown', 0.45160627)]\n",
      "[('n03388043', 'unknown', 0.9013916)]\n",
      "[('n03388043', 'unknown', 0.938639)]\n",
      "[('n02130308', 'cheetah', 0.14133337)]\n",
      "[('n03388043', 'unknown', 0.91380703)]\n",
      "[('n02391049', 'unknown', 0.28651562)]\n",
      "[('n03388043', 'unknown', 0.89541495)]\n",
      "[('n02130308', 'cheetah', 0.4318297)]\n",
      "[('n03388043', 'unknown', 0.5252564)]\n",
      "[('n02423022', 'unknown', 0.10487956)]\n",
      "[('n02130308', 'cheetah', 0.30881703)]\n",
      "[('n03388043', 'unknown', 0.25616103)]\n",
      "[('n02130308', 'cheetah', 0.28578338)]\n",
      "[('n02105056', 'unknown', 0.23671672)]\n",
      "[('n03891251', 'unknown', 0.18261498)]\n",
      "[('n02130308', 'cheetah', 0.5133224)]\n",
      "[('n02130308', 'cheetah', 0.80240613)]\n",
      "[('n02114548', 'unknown', 0.7770068)]\n",
      "[('n02130308', 'cheetah', 0.7640214)]\n",
      "[('n03388043', 'unknown', 0.9017075)]\n",
      "[('n03532672', 'unknown', 0.18507257)]\n",
      "[('n02130308', 'cheetah', 0.99221873)]\n",
      "[('n04371774', 'unknown', 0.18503106)]\n",
      "[('n03042490', 'unknown', 0.3854978)]\n",
      "[('n03788365', 'unknown', 0.22940461)]\n",
      "[('n02130308', 'cheetah', 0.99559)]\n",
      "[('n02115641', 'unknown', 0.12621173)]\n",
      "[('n02130308', 'cheetah', 0.7617955)]\n",
      "[('n03388043', 'unknown', 0.92312187)]\n",
      "[('n02114367', 'unknown', 0.46315384)]\n",
      "[('n04589890', 'unknown', 0.2863952)]\n",
      "[('n02130308', 'cheetah', 0.5576128)]\n",
      "[('n02130308', 'cheetah', 0.7790939)]\n",
      "[('n02130308', 'cheetah', 0.97439843)]\n",
      "[('n03388043', 'unknown', 0.7333551)]\n",
      "[('n02130308', 'cheetah', 0.81605065)]\n",
      "[('n03891251', 'unknown', 0.42224059)]\n",
      "[('n03388043', 'unknown', 0.612895)]\n",
      "[('n02977058', 'unknown', 0.07682405)]\n",
      "[('n03388043', 'unknown', 0.9771757)]\n",
      "[('n03891251', 'unknown', 0.20562261)]\n",
      "[('n02130308', 'cheetah', 0.6616896)]\n",
      "[('n02504458', 'unknown', 0.67548203)]\n",
      "[('n03388043', 'unknown', 0.92871296)]\n",
      "[('n03788365', 'unknown', 0.24731992)]\n",
      "[('n03042490', 'unknown', 0.08003061)]\n",
      "[('n03388043', 'unknown', 0.91705644)]\n",
      "[('n07248320', 'unknown', 0.23245484)]\n",
      "[('n03388043', 'unknown', 0.87670654)]\n",
      "[('n03891251', 'unknown', 0.2627497)]\n",
      "[('n03388043', 'unknown', 0.29158902)]\n",
      "[('n02965783', 'unknown', 0.5053253)]\n",
      "[('n03388043', 'unknown', 0.2014017)]\n",
      "[('n02114367', 'unknown', 0.43000174)]\n",
      "[('n02130308', 'cheetah', 0.9265043)]\n",
      "[('n02114855', 'unknown', 0.6961738)]\n",
      "[('n03388043', 'unknown', 0.1551674)]\n",
      "[('n03388043', 'unknown', 0.9958192)]\n",
      "[('n03388043', 'unknown', 0.1935196)]\n",
      "[('n03891251', 'unknown', 0.3391802)]\n",
      "[('n04371774', 'unknown', 0.20380285)]\n",
      "[('n02130308', 'cheetah', 0.6258601)]\n",
      "[('n03388043', 'unknown', 0.7987057)]\n",
      "[('n03042490', 'unknown', 0.17992528)]\n",
      "[('n02130308', 'cheetah', 0.8096468)]\n",
      "[('n01698640', 'unknown', 0.07592856)]\n",
      "[('n02130308', 'cheetah', 0.94958425)]\n",
      "[('n02403003', 'unknown', 0.33336583)]\n",
      "[('n03388043', 'unknown', 0.97494954)]\n",
      "[('n03891251', 'unknown', 0.25069743)]\n",
      "[('n03388043', 'unknown', 0.9930647)]\n",
      "[('n03388043', 'unknown', 0.74524957)]\n",
      "[('n02437616', 'unknown', 0.5392128)]\n",
      "[('n03891251', 'unknown', 0.15817907)]\n",
      "[('n03788365', 'unknown', 0.4843419)]\n",
      "[('n03388043', 'unknown', 0.74502194)]\n",
      "[('n04589890', 'unknown', 0.08674977)]\n",
      "[('n03388043', 'unknown', 0.55838597)]\n",
      "[('n02130308', 'cheetah', 0.9754916)]\n",
      "[('n02130308', 'cheetah', 0.9957106)]\n",
      "[('n03388043', 'unknown', 0.41213593)]\n",
      "[('n03388043', 'unknown', 0.47554132)]\n",
      "[('n02130308', 'cheetah', 0.2698031)]\n",
      "[('n03891251', 'unknown', 0.107062906)]\n",
      "[('n03388043', 'unknown', 0.47577614)]\n",
      "[('n02100735', 'unknown', 0.63496655)]\n",
      "[('n03388043', 'unknown', 0.24348928)]\n",
      "[('n02130308', 'cheetah', 0.22366455)]\n",
      "[('n02130308', 'cheetah', 0.8148926)]\n",
      "[('n02130308', 'cheetah', 0.9749347)]\n",
      "[('n03388043', 'unknown', 0.9348767)]\n",
      "[('n02130308', 'cheetah', 0.9522158)]\n",
      "[('n02130308', 'cheetah', 0.9417154)]\n",
      "[('n02130308', 'cheetah', 0.2583309)]\n",
      "[('n02130308', 'cheetah', 0.40988266)]\n",
      "[('n02130308', 'cheetah', 0.48182157)]\n",
      "[('n03388043', 'unknown', 0.6990998)]\n",
      "[('n03388043', 'unknown', 0.89722645)]\n",
      "[('n03388043', 'unknown', 0.9924942)]\n",
      "[('n03788365', 'unknown', 0.47747263)]\n",
      "[('n02130308', 'cheetah', 0.7664311)]\n",
      "[('n02480855', 'unknown', 0.12743221)]\n",
      "[('n02130308', 'cheetah', 0.8005285)]\n",
      "[('n02130308', 'cheetah', 0.90335375)]\n",
      "[('n03388043', 'unknown', 0.77632684)]\n",
      "[('n03388043', 'unknown', 0.1868203)]\n",
      "[('n04371774', 'unknown', 0.11419992)]\n",
      "[('n02130308', 'cheetah', 0.9906827)]\n",
      "[('n03388043', 'unknown', 0.36015958)]\n",
      "[('n03388043', 'unknown', 0.913669)]\n",
      "[('n03388043', 'unknown', 0.20013437)]\n",
      "[('n02117135', 'unknown', 0.17369452)]\n",
      "[('n03388043', 'unknown', 0.8659595)]\n",
      "[('n03788365', 'unknown', 0.8547006)]\n",
      "[('n04606251', 'unknown', 0.12478996)]\n",
      "[('n03891251', 'unknown', 0.17084864)]\n",
      "[('n03388043', 'unknown', 0.47427592)]\n",
      "[('n02114548', 'unknown', 0.51987964)]\n",
      "[('n03388043', 'unknown', 0.9295071)]\n",
      "[('n04371774', 'unknown', 0.47866565)]\n",
      "[('n02130308', 'cheetah', 0.9749572)]\n",
      "[('n03388043', 'unknown', 0.736127)]\n",
      "[('n02130308', 'cheetah', 0.9032757)]\n",
      "[('n03388043', 'unknown', 0.10089963)]\n",
      "[('n03388043', 'unknown', 0.22431743)]\n",
      "[('n03042490', 'unknown', 0.22266039)]\n",
      "[('n02130308', 'cheetah', 0.9010836)]\n",
      "[('n02437312', 'unknown', 0.19658297)]\n",
      "[('n02130308', 'cheetah', 0.20675497)]\n",
      "[('n03388043', 'unknown', 0.66047144)]\n",
      "[('n02130308', 'cheetah', 0.86761487)]\n",
      "[('n03388043', 'unknown', 0.5410964)]\n",
      "[('n02130308', 'cheetah', 0.6177604)]\n",
      "[('n02130308', 'cheetah', 0.80177385)]\n",
      "[('n03388043', 'unknown', 0.16087054)]\n",
      "[('n03388043', 'unknown', 0.9201312)]\n",
      "[('n02130308', 'cheetah', 0.40921938)]\n",
      "[('n03388043', 'unknown', 0.67688125)]\n",
      "[('n02130308', 'cheetah', 0.6972959)]\n",
      "[('n01855672', 'unknown', 0.1633371)]\n",
      "[('n03388043', 'unknown', 0.9413987)]\n",
      "[('n03388043', 'unknown', 0.06916297)]\n",
      "[('n07248320', 'unknown', 0.4426976)]\n",
      "[('n03388043', 'unknown', 0.20848206)]\n",
      "[('n02125311', 'unknown', 0.63224804)]\n",
      "[('n02115641', 'unknown', 0.1177609)]\n",
      "[('n02130308', 'cheetah', 0.9501236)]\n",
      "[('n02130308', 'cheetah', 0.36070713)]\n",
      "[('n03042490', 'unknown', 0.13773875)]\n",
      "[('n02130308', 'cheetah', 0.619408)]\n",
      "[('n03891251', 'unknown', 0.08493599)]\n",
      "[('n03388043', 'unknown', 0.7918797)]\n",
      "[('n01910747', 'unknown', 0.7401728)]\n",
      "[('n03042490', 'unknown', 0.17045258)]\n",
      "[('n02130308', 'cheetah', 0.49297044)]\n",
      "[('n03388043', 'unknown', 0.8267985)]\n",
      "[('n02130308', 'cheetah', 0.9868587)]\n",
      "[('n02115641', 'unknown', 0.447603)]\n",
      "[('n02130308', 'cheetah', 0.7837954)]\n",
      "[('n02965783', 'unknown', 0.34751478)]\n",
      "[('n02317335', 'unknown', 0.18712609)]\n",
      "[('n02130308', 'cheetah', 0.9900322)]\n",
      "[('n03388043', 'unknown', 0.43815556)]\n",
      "[('n03788365', 'unknown', 0.44757676)]\n",
      "[('n03788365', 'unknown', 0.5799771)]\n",
      "[('n04423845', 'unknown', 0.6558767)]\n",
      "[('n03388043', 'unknown', 0.2689571)]\n",
      "[('n03388043', 'unknown', 0.976383)]\n",
      "[('n03388043', 'unknown', 0.929828)]\n",
      "[('n03388043', 'unknown', 0.88552684)]\n",
      "[('n02130308', 'cheetah', 0.75241446)]\n",
      "[('n03388043', 'unknown', 0.3955288)]\n",
      "[('n03388043', 'unknown', 0.61022866)]\n",
      "[('n02130308', 'cheetah', 0.74622846)]\n",
      "[('n02130308', 'cheetah', 0.9900129)]\n",
      "[('n03788365', 'unknown', 0.6018483)]\n",
      "[('n03891251', 'unknown', 0.33498552)]\n",
      "[('n02130308', 'cheetah', 0.9659182)]\n",
      "[('n02130308', 'cheetah', 0.80368894)]\n",
      "[('n02437616', 'unknown', 0.42894307)]\n",
      "[('n03388043', 'unknown', 0.9770141)]\n",
      "[('n02389026', 'unknown', 0.06807605)]\n",
      "[('n03388043', 'unknown', 0.8009772)]\n",
      "[('n03388043', 'unknown', 0.99565214)]\n",
      "[('n03388043', 'unknown', 0.8654328)]\n",
      "[('n02130308', 'cheetah', 0.23058096)]\n",
      "[('n03388043', 'unknown', 0.7000695)]\n",
      "[('n02437616', 'unknown', 0.18722375)]\n",
      "[('n02130308', 'cheetah', 0.99146956)]\n",
      "[('n03388043', 'unknown', 0.9744883)]\n",
      "[('n03388043', 'unknown', 0.83618623)]\n",
      "[('n04493381', 'unknown', 0.14436927)]\n",
      "[('n03388043', 'unknown', 0.83797157)]\n",
      "[('n02965783', 'unknown', 0.14527714)]\n",
      "[('n03388043', 'unknown', 0.73040664)]\n",
      "[('n02130308', 'cheetah', 0.9777386)]\n",
      "[('n01687978', 'unknown', 0.08535272)]\n",
      "[('n04589890', 'unknown', 0.18377624)]\n",
      "[('n03388043', 'unknown', 0.9843567)]\n",
      "[('n02130308', 'cheetah', 0.37714687)]\n",
      "[('n03000134', 'unknown', 0.44829878)]\n",
      "[('n02130308', 'cheetah', 0.9034129)]\n",
      "[('n02130308', 'cheetah', 0.9572687)]\n",
      "[('n03388043', 'unknown', 0.8753842)]\n",
      "[('n02130308', 'cheetah', 0.5269292)]\n",
      "[('n03388043', 'unknown', 0.5963916)]\n",
      "[('n03891251', 'unknown', 0.35324934)]\n",
      "[('n02130308', 'cheetah', 0.46145776)]\n",
      "[('n03388043', 'unknown', 0.61035377)]\n",
      "[('n02130308', 'cheetah', 0.5955861)]\n",
      "[('n02130308', 'cheetah', 0.89494926)]\n",
      "[('n03388043', 'unknown', 0.23843601)]\n",
      "[('n04371774', 'unknown', 0.1585096)]\n",
      "[('n04371774', 'unknown', 0.11884119)]\n",
      "[('n03388043', 'unknown', 0.68080896)]\n",
      "[('n02127052', 'unknown', 0.23655091)]\n",
      "[('n03388043', 'unknown', 0.9757371)]\n",
      "[('n03891251', 'unknown', 0.088747755)]\n",
      "[('n02130308', 'cheetah', 0.78972566)]\n",
      "[('n03388043', 'unknown', 0.85175914)]\n",
      "[('n03042490', 'unknown', 0.20861137)]\n",
      "[('n03388043', 'unknown', 0.47475788)]\n",
      "[('n03388043', 'unknown', 0.6779015)]\n",
      "[('n03388043', 'unknown', 0.27930003)]\n",
      "[('n03388043', 'unknown', 0.7653905)]\n",
      "[('n03388043', 'unknown', 0.83233356)]\n",
      "[('n03388043', 'unknown', 0.9985688)]\n",
      "[('n02130308', 'cheetah', 0.9346624)]\n",
      "[('n02130308', 'cheetah', 0.9981919)]\n",
      "[('n03388043', 'unknown', 0.48547664)]\n",
      "[('n04332243', 'unknown', 0.39598647)]\n",
      "[('n02110341', 'unknown', 0.7377885)]\n",
      "[('n03388043', 'unknown', 0.6597005)]\n",
      "[('n02130308', 'cheetah', 0.87923354)]\n",
      "[('n03388043', 'unknown', 0.11059603)]\n",
      "[('n02130308', 'cheetah', 0.90462905)]\n",
      "[('n02130308', 'cheetah', 0.07473535)]\n",
      "[('n03388043', 'unknown', 0.6363751)]\n",
      "[('n01877812', 'unknown', 0.13878979)]\n",
      "[('n04371774', 'unknown', 0.20415898)]\n",
      "[('n02130308', 'cheetah', 0.7800831)]\n",
      "[('n02130308', 'cheetah', 0.24974215)]\n",
      "[('n04589890', 'unknown', 0.19625922)]\n",
      "[('n02504013', 'unknown', 0.20606272)]\n",
      "[('n03388043', 'unknown', 0.99805546)]\n",
      "[('n02497673', 'unknown', 0.21619624)]\n",
      "[('n03388043', 'unknown', 0.1426817)]\n",
      "[('n03388043', 'unknown', 0.63827306)]\n",
      "[('n02130308', 'cheetah', 0.9051469)]\n",
      "[('n02130308', 'cheetah', 0.9637554)]\n",
      "[('n03388043', 'unknown', 0.5052158)]\n",
      "[('n03042490', 'unknown', 0.12398182)]\n",
      "[('n02130308', 'cheetah', 0.25548366)]\n",
      "[('n02130308', 'cheetah', 0.49210986)]\n",
      "[('n02130308', 'cheetah', 0.9867611)]\n",
      "[('n03388043', 'unknown', 0.2589586)]\n",
      "[('n03388043', 'unknown', 0.97710085)]\n",
      "[('n02130308', 'cheetah', 0.8061891)]\n",
      "[('n03388043', 'unknown', 0.67330116)]\n",
      "[('n03388043', 'unknown', 0.84715724)]\n",
      "[('n02130308', 'cheetah', 0.98354256)]\n",
      "[('n02965783', 'unknown', 0.29859117)]\n",
      "[('n02130308', 'cheetah', 0.93505096)]\n",
      "[('n01748264', 'unknown', 0.26811585)]\n",
      "[('n02130308', 'cheetah', 0.9937251)]\n",
      "[('n03042490', 'unknown', 0.33016354)]\n",
      "[('n02130308', 'cheetah', 0.95586324)]\n",
      "[('n02130308', 'cheetah', 0.65010625)]\n",
      "[('n03891251', 'unknown', 0.16362077)]\n",
      "[('n02107312', 'unknown', 0.24767153)]\n",
      "[('n04589890', 'unknown', 0.2879168)]\n",
      "[('n02115641', 'unknown', 0.064950444)]\n",
      "[('n02808440', 'unknown', 0.405127)]\n",
      "[('n02130308', 'cheetah', 0.7379434)]\n",
      "[('n03388043', 'unknown', 0.68961954)]\n",
      "[('n01748264', 'unknown', 0.19265541)]\n",
      "[('n04589890', 'unknown', 0.2562227)]\n",
      "[('n02130308', 'cheetah', 0.9534872)]\n",
      "[('n02130308', 'cheetah', 0.45709762)]\n",
      "[('n02130308', 'cheetah', 0.97099113)]\n",
      "[('n03388043', 'unknown', 0.7661337)]\n",
      "[('n02391049', 'unknown', 0.29456615)]\n",
      "[('n03388043', 'unknown', 0.6865408)]\n",
      "[('n03388043', 'unknown', 0.9857371)]\n",
      "[('n03388043', 'unknown', 0.60831314)]\n",
      "[('n02130308', 'cheetah', 0.9865486)]\n",
      "[('n02130308', 'cheetah', 0.97946703)]\n",
      "[('n01883070', 'unknown', 0.31391296)]\n",
      "[('n03788365', 'unknown', 0.86894095)]\n",
      "[('n04366367', 'unknown', 0.20164117)]\n",
      "[('n03388043', 'unknown', 0.96794564)]\n",
      "[('n03388043', 'unknown', 0.5822387)]\n",
      "[('n02130308', 'cheetah', 0.93294066)]\n",
      "[('n02130308', 'cheetah', 0.96936274)]\n",
      "[('n02130308', 'cheetah', 0.9997607)]\n",
      "[('n03743016', 'unknown', 0.24399962)]\n",
      "[('n04371774', 'unknown', 0.2057642)]\n",
      "[('n02130308', 'cheetah', 0.6225737)]\n",
      "[('n02130308', 'cheetah', 0.97166765)]\n",
      "[('n03388043', 'unknown', 0.31363043)]\n",
      "[('n03388043', 'unknown', 0.7530831)]\n",
      "[('n03042490', 'unknown', 0.09184262)]\n",
      "[('n02504013', 'unknown', 0.25328785)]\n",
      "[('n02504013', 'unknown', 0.4654535)]\n",
      "[('n03388043', 'unknown', 0.30571628)]\n",
      "[('n02130308', 'cheetah', 0.8834719)]\n",
      "[('n02088632', 'unknown', 0.17044936)]\n",
      "[('n02130308', 'cheetah', 0.9389889)]\n",
      "[('n03743016', 'unknown', 0.19442339)]\n",
      "[('n02389026', 'unknown', 0.07213969)]\n",
      "[('n04371774', 'unknown', 0.06279561)]\n",
      "[('n03388043', 'unknown', 0.77036643)]\n",
      "[('n03788365', 'unknown', 0.3012318)]\n",
      "[('n03388043', 'unknown', 0.6257039)]\n",
      "[('n02130308', 'cheetah', 0.98510736)]\n",
      "[('n02130308', 'cheetah', 0.9770567)]\n",
      "[('n02013706', 'unknown', 0.527552)]\n",
      "[('n02130308', 'cheetah', 0.9106028)]\n",
      "[('n03388043', 'unknown', 0.51998997)]\n",
      "[('n02437312', 'unknown', 0.48404387)]\n",
      "[('n02130308', 'cheetah', 0.39041388)]\n",
      "[('n07248320', 'unknown', 0.503584)]\n",
      "[('n03788365', 'unknown', 0.28189087)]\n",
      "[('n03388043', 'unknown', 0.6224247)]\n",
      "[('n03388043', 'unknown', 0.45496944)]\n",
      "[('n02130308', 'cheetah', 0.14468591)]\n",
      "[('n02130308', 'cheetah', 0.77204096)]\n",
      "[('n02965783', 'unknown', 0.40834326)]\n",
      "[('n03743016', 'unknown', 0.22741283)]\n",
      "[('n03388043', 'unknown', 0.70222056)]\n",
      "[('n09246464', 'unknown', 0.10458993)]\n",
      "[('n02130308', 'cheetah', 0.1980521)]\n",
      "[('n03388043', 'unknown', 0.78186697)]\n",
      "[('n03388043', 'unknown', 0.9401943)]\n",
      "[('n02130308', 'cheetah', 0.90202785)]\n",
      "[('n03788365', 'unknown', 0.18441074)]\n",
      "[('n03891251', 'unknown', 0.17138326)]\n",
      "[('n02231487', 'unknown', 0.25048864)]\n",
      "[('n03042490', 'unknown', 0.1747923)]\n",
      "[('n03388043', 'unknown', 0.7610027)]\n",
      "[('n03388043', 'unknown', 0.16444153)]\n",
      "[('n02130308', 'cheetah', 0.5034014)]\n",
      "[('n03388043', 'unknown', 0.64352185)]\n",
      "[('n02130308', 'cheetah', 0.4131326)]\n",
      "[('n02130308', 'cheetah', 0.925042)]\n",
      "[('n02130308', 'cheetah', 0.9661873)]\n",
      "[('n03891251', 'unknown', 0.15451221)]\n",
      "[('n02130308', 'cheetah', 0.7736311)]\n",
      "[('n02130308', 'cheetah', 0.8173801)]\n",
      "[('n07248320', 'unknown', 0.44159544)]\n",
      "[('n02130308', 'cheetah', 0.97350353)]\n",
      "[('n04589890', 'unknown', 0.3081844)]\n",
      "[('n02130308', 'cheetah', 0.9233834)]\n",
      "[('n03788365', 'unknown', 0.25037533)]\n",
      "[('n02130308', 'cheetah', 0.5791791)]\n",
      "[('n02480855', 'unknown', 0.1576769)]\n",
      "[('n02130308', 'cheetah', 0.10758358)]\n",
      "[('n02793495', 'unknown', 0.12006405)]\n",
      "[('n03388043', 'unknown', 0.42622364)]\n",
      "[('n03388043', 'unknown', 0.82920396)]\n",
      "[('n04371774', 'unknown', 0.1666468)]\n",
      "[('n02130308', 'cheetah', 0.99125576)]\n",
      "[('n02130308', 'cheetah', 0.85149556)]\n",
      "[('n01877812', 'unknown', 0.5721826)]\n",
      "[('n03388043', 'unknown', 0.27281502)]\n",
      "[('n02130308', 'cheetah', 0.9932115)]\n",
      "[('n02965783', 'unknown', 0.27970782)]\n",
      "[('n02965783', 'unknown', 0.27738714)]\n",
      "[('n03388043', 'unknown', 0.70071524)]\n",
      "[('n03388043', 'unknown', 0.98749393)]\n",
      "[('n03891251', 'unknown', 0.21555)]\n",
      "[('n04371774', 'unknown', 0.100422)]\n",
      "[('n04493381', 'unknown', 0.132748)]\n",
      "[('n02123159', 'unknown', 0.5392494)]\n",
      "[('n04371774', 'unknown', 0.46971172)]\n",
      "[('n02115641', 'unknown', 0.06779094)]\n",
      "[('n02130308', 'cheetah', 0.9605037)]\n",
      "[('n02130308', 'cheetah', 0.6478821)]\n",
      "[('n02130308', 'cheetah', 0.99009484)]\n",
      "[('n03388043', 'unknown', 0.18749556)]\n",
      "[('n02130308', 'cheetah', 0.99707735)]\n",
      "[('n03388043', 'unknown', 0.3208865)]\n",
      "[('n03388043', 'unknown', 0.89687175)]\n",
      "[('n03891251', 'unknown', 0.12158043)]\n",
      "[('n03388043', 'unknown', 0.9228643)]\n",
      "[('n02793495', 'unknown', 0.1611584)]\n",
      "[('n03788365', 'unknown', 0.12560989)]\n",
      "[('n02130308', 'cheetah', 0.6770753)]\n",
      "[('n02977058', 'unknown', 0.09669482)]\n",
      "[('n02965783', 'unknown', 0.38588724)]\n",
      "[('n02130308', 'cheetah', 0.6850624)]\n",
      "[('n03388043', 'unknown', 0.93562555)]\n",
      "[('n02130308', 'cheetah', 0.8358352)]\n",
      "[('n04371774', 'unknown', 0.11850129)]\n",
      "[('n01877812', 'unknown', 0.2166286)]\n",
      "[('n03388043', 'unknown', 0.9055973)]\n",
      "[('n02130308', 'cheetah', 0.99349797)]\n",
      "[('n03788365', 'unknown', 0.4464121)]\n",
      "[('n02130308', 'cheetah', 0.8545347)]\n",
      "[('n02130308', 'cheetah', 0.85847193)]\n",
      "[('n03891251', 'unknown', 0.10016612)]\n",
      "[('n04589890', 'unknown', 0.23157388)]\n",
      "[('n02133161', 'unknown', 0.2923692)]\n",
      "[('n03388043', 'unknown', 0.18979432)]\n",
      "[('n02130308', 'cheetah', 0.85461694)]\n",
      "[('n02130308', 'cheetah', 0.9473697)]\n",
      "[('n02130308', 'cheetah', 0.88119674)]\n",
      "[('n03388043', 'unknown', 0.77554494)]\n",
      "[('n02130308', 'cheetah', 0.89586717)]\n",
      "[('n02130308', 'cheetah', 0.5995932)]\n",
      "[('n03388043', 'unknown', 0.6003021)]\n",
      "[('n02130308', 'cheetah', 0.44769362)]\n",
      "[('n03891251', 'unknown', 0.18806577)]\n",
      "[('n01855672', 'unknown', 0.22456874)]\n",
      "[('n03891251', 'unknown', 0.241724)]\n",
      "[('n03388043', 'unknown', 0.4769351)]\n",
      "[('n02454379', 'unknown', 0.26137573)]\n",
      "[('n04371774', 'unknown', 0.4338064)]\n",
      "[('n04371774', 'unknown', 0.34044835)]\n",
      "[('n02480855', 'unknown', 0.12064496)]\n",
      "[('n03388043', 'unknown', 0.72539914)]\n",
      "[('n03788365', 'unknown', 0.41985613)]\n",
      "[('n02130308', 'cheetah', 0.92908084)]\n",
      "[('n02437312', 'unknown', 0.60206056)]\n",
      "[('n02130308', 'cheetah', 0.56716764)]\n",
      "[('n02130308', 'cheetah', 0.95105195)]\n",
      "[('n02114855', 'unknown', 0.70992833)]\n",
      "[('n03388043', 'unknown', 0.96572846)]\n",
      "[('n02130308', 'cheetah', 0.9648542)]\n",
      "[('n02130308', 'cheetah', 0.9528929)]\n",
      "[('n03388043', 'unknown', 0.96979314)]\n",
      "[('n03388043', 'unknown', 0.44747376)]\n",
      "[('n03388043', 'unknown', 0.95657915)]\n",
      "[('n02130308', 'cheetah', 0.9368013)]\n",
      "[('n02127052', 'unknown', 0.1820534)]\n",
      "[('n02130308', 'cheetah', 0.9880724)]\n",
      "[('n02114855', 'unknown', 0.44905904)]\n",
      "[('n02130308', 'cheetah', 0.73309815)]\n",
      "[('n03388043', 'unknown', 0.56051105)]\n",
      "[('n03388043', 'unknown', 0.8214951)]\n",
      "[('n03388043', 'unknown', 0.9716304)]\n",
      "[('n02130308', 'cheetah', 0.9944878)]\n",
      "[('n03388043', 'unknown', 0.5389355)]\n",
      "[('n02130308', 'cheetah', 0.351326)]\n",
      "[('n03388043', 'unknown', 0.57607555)]\n",
      "[('n02130308', 'cheetah', 0.9640341)]\n",
      "[('n03788365', 'unknown', 0.65271467)]\n",
      "[('n03160309', 'unknown', 0.35026163)]\n",
      "[('n02130308', 'cheetah', 0.97234815)]\n",
      "[('n02130308', 'cheetah', 0.9712506)]\n",
      "[('n03388043', 'unknown', 0.87201697)]\n",
      "[('n02504458', 'unknown', 0.06381175)]\n",
      "[('n02130308', 'cheetah', 0.45792508)]\n",
      "[('n03891251', 'unknown', 0.09519778)]\n",
      "[('n02130308', 'cheetah', 0.8538495)]\n",
      "[('n02130308', 'cheetah', 0.99674857)]\n",
      "[('n03388043', 'unknown', 0.9634136)]\n",
      "[('n02130308', 'cheetah', 0.4232692)]\n",
      "[('n07802026', 'unknown', 0.14927468)]\n",
      "[('n03388043', 'unknown', 0.43291104)]\n",
      "[('n02130308', 'cheetah', 0.9379049)]\n",
      "[('n02114367', 'unknown', 0.2988538)]\n",
      "[('n03788365', 'unknown', 0.524431)]\n",
      "[('n03788365', 'unknown', 0.13927554)]\n",
      "[('n02100735', 'unknown', 0.31369132)]\n",
      "[('n03388043', 'unknown', 0.18646367)]\n",
      "[('n03388043', 'unknown', 0.3155158)]\n",
      "[('n03388043', 'unknown', 0.59394985)]\n",
      "[('n02437312', 'unknown', 0.5318943)]\n",
      "[('n03000134', 'unknown', 0.48799938)]\n",
      "[('n02130308', 'cheetah', 0.94064796)]\n",
      "[('n02965783', 'unknown', 0.24220309)]\n",
      "[('n03388043', 'unknown', 0.679585)]\n",
      "[('n03388043', 'unknown', 0.4929051)]\n",
      "[('n02130308', 'cheetah', 0.98518735)]\n",
      "[('n02130308', 'cheetah', 0.9585263)]\n",
      "[('n02965783', 'unknown', 0.19749494)]\n",
      "[('n03891251', 'unknown', 0.26240665)]\n",
      "[('n02130308', 'cheetah', 0.99475807)]\n",
      "[('n02391049', 'unknown', 0.4388931)]\n",
      "[('n02130308', 'cheetah', 0.7680213)]\n",
      "[('n02130308', 'cheetah', 0.9947747)]\n",
      "[('n02130308', 'cheetah', 0.9659305)]\n",
      "[('n03388043', 'unknown', 0.509526)]\n",
      "[('n02497673', 'unknown', 0.96014136)]\n",
      "[('n02130308', 'cheetah', 0.9935277)]\n",
      "[('n03388043', 'unknown', 0.87508935)]\n",
      "[('n02417914', 'unknown', 0.20470287)]\n",
      "[('n02130308', 'cheetah', 0.9763581)]\n",
      "[('n03388043', 'unknown', 0.24222831)]\n",
      "[('n02130308', 'cheetah', 0.32832375)]\n",
      "[('n03743016', 'unknown', 0.22399293)]\n",
      "[('n03388043', 'unknown', 0.84474343)]\n",
      "[('n02504013', 'unknown', 0.19645604)]\n",
      "[('n03042490', 'unknown', 0.13351354)]\n",
      "[('n03958227', 'unknown', 0.12895812)]\n",
      "[('n02130308', 'cheetah', 0.6670938)]\n",
      "[('n02128925', 'unknown', 0.18187582)]\n",
      "[('n02130308', 'cheetah', 0.9883555)]\n",
      "[('n03388043', 'unknown', 0.60071856)]\n",
      "[('n03388043', 'unknown', 0.40014005)]\n",
      "[('n02130308', 'cheetah', 0.37142485)]\n",
      "[('n02130308', 'cheetah', 0.221341)]\n",
      "[('n02437312', 'unknown', 0.22484866)]\n",
      "[('n02130308', 'cheetah', 0.9494358)]\n",
      "[('n03388043', 'unknown', 0.96318626)]\n",
      "[('n03788365', 'unknown', 0.4280261)]\n",
      "[('n02130308', 'cheetah', 0.9418832)]\n",
      "[('n02130308', 'cheetah', 0.9852064)]\n",
      "[('n03388043', 'unknown', 0.21100737)]\n",
      "[('n02130308', 'cheetah', 0.55151653)]\n",
      "[('n03788365', 'unknown', 0.7442884)]\n",
      "[('n02325366', 'unknown', 0.68997926)]\n",
      "[('n03388043', 'unknown', 0.76316595)]\n",
      "[('n02130308', 'cheetah', 0.63095057)]\n",
      "[('n03388043', 'unknown', 0.94165885)]\n",
      "[('n02965783', 'unknown', 0.42925537)]\n",
      "[('n03388043', 'unknown', 0.8073652)]\n",
      "[('n03388043', 'unknown', 0.8971921)]\n",
      "[('n03388043', 'unknown', 0.43478)]\n",
      "[('n02130308', 'cheetah', 0.90152013)]\n",
      "[('n03388043', 'unknown', 0.67808694)]\n",
      "[('n03388043', 'unknown', 0.08960592)]\n",
      "[('n03388043', 'unknown', 0.7886164)]\n",
      "[('n03388043', 'unknown', 0.81796014)]\n",
      "[('n03388043', 'unknown', 0.9046078)]\n",
      "[('n02480855', 'unknown', 0.084751695)]\n",
      "[('n01855672', 'unknown', 0.18806271)]\n",
      "[('n02114855', 'unknown', 0.19669461)]\n",
      "[('n03891251', 'unknown', 0.51043755)]\n",
      "[('n03388043', 'unknown', 0.9593513)]\n",
      "[('n02480855', 'unknown', 0.15271857)]\n",
      "[('n04371774', 'unknown', 0.19867495)]\n",
      "[('n03891251', 'unknown', 0.14422974)]\n",
      "[('n04371774', 'unknown', 0.40435788)]\n",
      "[('n02130308', 'cheetah', 0.9967278)]\n",
      "[('n02130308', 'cheetah', 0.2046805)]\n",
      "[('n03388043', 'unknown', 0.7096143)]\n",
      "[('n03388043', 'unknown', 0.6617482)]\n",
      "[('n03388043', 'unknown', 0.66315866)]\n",
      "[('n03388043', 'unknown', 0.68647945)]\n",
      "[('n02130308', 'cheetah', 0.90601236)]\n",
      "[('n02130308', 'cheetah', 0.97850716)]\n",
      "[('n03388043', 'unknown', 0.9303661)]\n",
      "[('n02130308', 'cheetah', 0.35388532)]\n",
      "[('n03388043', 'unknown', 0.9063668)]\n",
      "[('n03388043', 'unknown', 0.7143723)]\n",
      "[('n02130308', 'cheetah', 0.9964089)]\n",
      "[('n03388043', 'unknown', 0.9961571)]\n",
      "[('n03388043', 'unknown', 0.95831996)]\n",
      "[('n02808440', 'unknown', 0.2519923)]\n",
      "[('n09229709', 'unknown', 0.11376262)]\n",
      "[('n03000134', 'unknown', 0.3407187)]\n",
      "[('n02130308', 'cheetah', 0.9936579)]\n",
      "[('n03388043', 'unknown', 0.85346705)]\n",
      "[('n02130308', 'cheetah', 0.6497548)]\n",
      "[('n02130308', 'cheetah', 0.8010895)]\n",
      "[('n02130308', 'cheetah', 0.99105096)]\n",
      "[('n02130308', 'cheetah', 0.43300074)]\n",
      "[('n03388043', 'unknown', 0.29292327)]\n",
      "[('n02130308', 'cheetah', 0.29865152)]\n",
      "[('n03388043', 'unknown', 0.28825113)]\n",
      "[('n03388043', 'unknown', 0.9797775)]\n",
      "[('n02808440', 'unknown', 0.18293642)]\n",
      "[('n02504458', 'unknown', 0.6447565)]\n",
      "[('n03388043', 'unknown', 0.67281103)]\n",
      "[('n02130308', 'cheetah', 0.9267372)]\n",
      "[('n02396427', 'unknown', 0.1318092)]\n",
      "[('n03388043', 'unknown', 0.89694995)]\n",
      "[('n02130308', 'cheetah', 0.13651833)]\n",
      "[('n04589890', 'unknown', 0.20030397)]\n",
      "[('n03388043', 'unknown', 0.69445336)]\n",
      "[('n02130308', 'cheetah', 0.991861)]\n",
      "[('n02130308', 'cheetah', 0.7448943)]\n",
      "[('n02130308', 'cheetah', 0.92536175)]\n",
      "[('n02130308', 'cheetah', 0.99237216)]\n",
      "[('n03388043', 'unknown', 0.49317107)]\n",
      "[('n03891251', 'unknown', 0.09456409)]\n",
      "[('n02130308', 'cheetah', 0.39856207)]\n",
      "[('n02130308', 'cheetah', 0.31108055)]\n",
      "[('n02130308', 'cheetah', 0.9423946)]\n",
      "[('n03388043', 'unknown', 0.062173508)]\n",
      "[('n03388043', 'unknown', 0.95323974)]\n",
      "[('n03481172', 'unknown', 0.1297492)]\n",
      "[('n03891251', 'unknown', 0.14560932)]\n",
      "[('n03388043', 'unknown', 0.84963596)]\n",
      "[('n03388043', 'unknown', 0.9668122)]\n",
      "[('n03388043', 'unknown', 0.8542653)]\n",
      "[('n02398521', 'unknown', 0.23941994)]\n",
      "[('n02437312', 'unknown', 0.4208287)]\n",
      "[('n03388043', 'unknown', 0.9960444)]\n",
      "[('n02130308', 'cheetah', 0.78178084)]\n",
      "[('n03788365', 'unknown', 0.399955)]\n",
      "[('n02130308', 'cheetah', 0.9514134)]\n",
      "[('n02130308', 'cheetah', 0.5086038)]\n",
      "[('n02130308', 'cheetah', 0.53655326)]\n",
      "[('n03388043', 'unknown', 0.7046256)]\n",
      "[('n02504458', 'unknown', 0.07675048)]\n",
      "[('n03388043', 'unknown', 0.10992675)]\n",
      "[('n02965783', 'unknown', 0.2539234)]\n",
      "[('n04404412', 'unknown', 0.06759575)]\n",
      "[('n03388043', 'unknown', 0.14549904)]\n",
      "[('n02130308', 'cheetah', 0.58491117)]\n",
      "[('n03388043', 'unknown', 0.7796511)]\n",
      "[('n03388043', 'unknown', 0.45611158)]\n",
      "[('n02130308', 'cheetah', 0.93884444)]\n",
      "[('n02391049', 'unknown', 0.11592631)]\n",
      "[('n03388043', 'unknown', 0.54215145)]\n",
      "[('n02130308', 'cheetah', 0.96005136)]\n",
      "[('n03388043', 'unknown', 0.9972134)]\n",
      "[('n02504458', 'unknown', 0.101804584)]\n",
      "[('n02130308', 'cheetah', 0.4193449)]\n",
      "[('n03891251', 'unknown', 0.19657919)]\n",
      "[('n03042490', 'unknown', 0.21666405)]\n",
      "[('n03388043', 'unknown', 0.79094565)]\n",
      "[('n02130308', 'cheetah', 0.123095356)]\n",
      "[('n02130308', 'cheetah', 0.52448875)]\n",
      "[('n03388043', 'unknown', 0.17477655)]\n",
      "[('n03388043', 'unknown', 0.9285479)]\n",
      "[('n02130308', 'cheetah', 0.47942826)]\n",
      "[('n02130308', 'cheetah', 0.5078136)]\n",
      "[('n03388043', 'unknown', 0.9449477)]\n",
      "[('n02130308', 'cheetah', 0.9849502)]\n",
      "[('n01751748', 'unknown', 0.28506407)]\n",
      "[('n03388043', 'unknown', 0.7085145)]\n",
      "[('n02130308', 'cheetah', 0.9803759)]\n",
      "[('n03891251', 'unknown', 0.17362797)]\n",
      "[('n02504013', 'unknown', 0.10893508)]\n",
      "[('n02130308', 'cheetah', 0.96859556)]\n",
      "[('n02130308', 'cheetah', 0.94861627)]\n",
      "[('n02437312', 'unknown', 0.5676301)]\n",
      "[('n02130308', 'cheetah', 0.8727589)]\n",
      "[('n03788365', 'unknown', 0.82672)]\n",
      "[('n03388043', 'unknown', 0.13641955)]\n",
      "[('n04589890', 'unknown', 0.35730937)]\n",
      "[('n02130308', 'cheetah', 0.85103226)]\n",
      "[('n02130308', 'cheetah', 0.9968065)]\n",
      "[('n02130308', 'cheetah', 0.2017593)]\n",
      "[('n02115641', 'unknown', 0.3877763)]\n",
      "[('n07248320', 'unknown', 0.42034167)]\n",
      "[('n02410509', 'unknown', 0.3193938)]\n",
      "[('n04371774', 'unknown', 0.16600966)]\n",
      "[('n02130308', 'cheetah', 0.74558485)]\n",
      "[('n01756291', 'unknown', 0.16742067)]\n",
      "[('n02130308', 'cheetah', 0.21899866)]\n",
      "[('n02130308', 'cheetah', 0.9339893)]\n",
      "[('n02130308', 'cheetah', 0.83122057)]\n",
      "[('n03388043', 'unknown', 0.15879063)]\n",
      "[('n03388043', 'unknown', 0.9820342)]\n",
      "[('n03388043', 'unknown', 0.86736584)]\n",
      "[('n03388043', 'unknown', 0.604569)]\n",
      "[('n03042490', 'unknown', 0.25026685)]\n",
      "[('n02130308', 'cheetah', 0.9700154)]\n",
      "[('n03388043', 'unknown', 0.31141105)]\n",
      "[('n03388043', 'unknown', 0.998708)]\n",
      "[('n03388043', 'unknown', 0.49455532)]\n",
      "[('n02130308', 'cheetah', 0.9836474)]\n",
      "[('n03388043', 'unknown', 0.38742512)]\n",
      "[('n02130308', 'cheetah', 0.9844422)]\n",
      "[('n03042490', 'unknown', 0.14637968)]\n",
      "[('n02130308', 'cheetah', 0.9666137)]\n",
      "[('n04371774', 'unknown', 0.15406106)]\n",
      "[('n02130308', 'cheetah', 0.47673056)]\n",
      "[('n02130308', 'cheetah', 0.99482155)]\n",
      "[('n03388043', 'unknown', 0.54639995)]\n",
      "[('n03388043', 'unknown', 0.9850028)]\n",
      "[('n02130308', 'cheetah', 0.46283916)]\n",
      "[('n02130308', 'cheetah', 0.9703128)]\n",
      "[('n03388043', 'unknown', 0.45225605)]\n",
      "[('n02130308', 'cheetah', 0.4324649)]\n",
      "[('n03388043', 'unknown', 0.7172298)]\n",
      "[('n02110341', 'unknown', 0.939961)]\n",
      "[('n02130308', 'cheetah', 0.9445147)]\n",
      "[('n02130308', 'cheetah', 0.9518949)]\n",
      "[('n02130308', 'cheetah', 0.83536166)]\n",
      "[('n02130308', 'cheetah', 0.9943646)]\n",
      "[('n03388043', 'unknown', 0.825309)]\n",
      "[('n03388043', 'unknown', 0.09311957)]\n",
      "[('n03388043', 'unknown', 0.9617154)]\n",
      "[('n02130308', 'cheetah', 0.8037729)]\n",
      "[('n03388043', 'unknown', 0.09386698)]\n",
      "[('n03388043', 'unknown', 0.32331112)]\n",
      "[('n04275548', 'unknown', 0.12182998)]\n",
      "[('n02130308', 'cheetah', 0.4603846)]\n",
      "[('n03388043', 'unknown', 0.47873685)]\n",
      "[('n03388043', 'unknown', 0.2671524)]\n",
      "[('n02480855', 'unknown', 0.1547686)]\n",
      "[('n02130308', 'cheetah', 0.6326983)]\n",
      "[('n03388043', 'unknown', 0.6287586)]\n",
      "[('n03388043', 'unknown', 0.7168042)]\n",
      "[('n02130308', 'cheetah', 0.9980597)]\n",
      "[('n03388043', 'unknown', 0.8864494)]\n",
      "[('n03788365', 'unknown', 0.86886436)]\n",
      "[('n03788365', 'unknown', 0.54278606)]\n",
      "[('n03388043', 'unknown', 0.5346504)]\n",
      "[('n03388043', 'unknown', 0.7592817)]\n",
      "[('n03388043', 'unknown', 0.45957074)]\n",
      "[('n02130308', 'cheetah', 0.5751046)]\n",
      "[('n02130308', 'cheetah', 0.9847926)]\n",
      "[('n02130308', 'cheetah', 0.9763387)]\n",
      "[('n03388043', 'unknown', 0.41635337)]\n",
      "[('n02130308', 'cheetah', 0.32189256)]\n",
      "[('n02114855', 'unknown', 0.43566802)]\n",
      "[('n03388043', 'unknown', 0.73864114)]\n",
      "[('n02130308', 'cheetah', 0.9996543)]\n",
      "[('n02099712', 'unknown', 0.092879355)]\n",
      "[('n03388043', 'unknown', 0.15756997)]\n",
      "[('n01855672', 'unknown', 0.16860889)]\n",
      "[('n03042490', 'unknown', 0.12983927)]\n",
      "[('n03042490', 'unknown', 0.2660512)]\n",
      "[('n02130308', 'cheetah', 0.38025364)]\n",
      "[('n02130308', 'cheetah', 0.88023317)]\n",
      "[('n03388043', 'unknown', 0.80823547)]\n",
      "[('n03388043', 'unknown', 0.33666977)]\n",
      "[('n03042490', 'unknown', 0.4076954)]\n",
      "[('n02130308', 'cheetah', 0.20739716)]\n",
      "[('n03388043', 'unknown', 0.10307834)]\n",
      "[('n03388043', 'unknown', 0.60496414)]\n",
      "[('n03958227', 'unknown', 0.10617014)]\n",
      "[('n04589890', 'unknown', 0.24700151)]\n",
      "[('n02130308', 'cheetah', 0.77407646)]\n",
      "[('n03388043', 'unknown', 0.7792868)]\n",
      "[('n02480855', 'unknown', 0.07807285)]\n",
      "[('n03388043', 'unknown', 0.24279517)]\n",
      "[('n02115641', 'unknown', 0.6582343)]\n",
      "[('n02114855', 'unknown', 0.17088278)]\n",
      "[('n02130308', 'cheetah', 0.8100101)]\n",
      "[('n02130308', 'cheetah', 0.9994273)]\n",
      "[('n03388043', 'unknown', 0.1571989)]\n",
      "[('n02130308', 'cheetah', 0.43014288)]\n",
      "[('n02130308', 'cheetah', 0.95722306)]\n",
      "[('n03388043', 'unknown', 0.41241282)]\n",
      "[('n02130308', 'cheetah', 0.9973103)]\n",
      "[('n02130308', 'cheetah', 0.6148177)]\n",
      "[('n03388043', 'unknown', 0.90612566)]\n",
      "[('n02130308', 'cheetah', 0.97568107)]\n",
      "[('n02130308', 'cheetah', 0.99474573)]\n",
      "[('n03388043', 'unknown', 0.97691035)]\n",
      "[('n02130308', 'cheetah', 0.968113)]\n",
      "[('n03042490', 'unknown', 0.21543491)]\n",
      "[('n02130308', 'cheetah', 0.8197078)]\n",
      "[('n03000134', 'unknown', 0.11125712)]\n",
      "[('n02130308', 'cheetah', 0.34685457)]\n",
      "[('n02130308', 'cheetah', 0.98700386)]\n",
      "[('n03891251', 'unknown', 0.68136907)]\n",
      "[('n03958227', 'unknown', 0.16192566)]\n",
      "[('n02130308', 'cheetah', 0.99598527)]\n",
      "[('n02114548', 'unknown', 0.3596033)]\n",
      "[('n02130308', 'cheetah', 0.85456115)]\n",
      "[('n03388043', 'unknown', 0.98194444)]\n",
      "[('n07248320', 'unknown', 0.29660255)]\n",
      "[('n03388043', 'unknown', 0.83157414)]\n",
      "[('n02130308', 'cheetah', 0.8388279)]\n",
      "[('n03743016', 'unknown', 0.15137708)]\n",
      "[('n02130308', 'cheetah', 0.8165182)]\n",
      "[('n02130308', 'cheetah', 0.16761911)]\n",
      "[('n02417914', 'unknown', 0.09632848)]\n",
      "[('n02130308', 'cheetah', 0.90398866)]\n",
      "[('n03388043', 'unknown', 0.36240682)]\n",
      "[('n07248320', 'unknown', 0.15818584)]\n",
      "[('n03388043', 'unknown', 0.10503531)]\n",
      "[('n02437616', 'unknown', 0.29997304)]\n",
      "[('n03788365', 'unknown', 0.561587)]\n",
      "[('n03388043', 'unknown', 0.23701964)]\n",
      "[('n02130308', 'cheetah', 0.98719865)]\n",
      "[('n02125311', 'unknown', 0.19482514)]\n",
      "[('n04371774', 'unknown', 0.08880147)]\n",
      "[('n03388043', 'unknown', 0.8613517)]\n",
      "[('n03388043', 'unknown', 0.3520048)]\n",
      "[('n03388043', 'unknown', 0.22920848)]\n",
      "[('n02130308', 'cheetah', 0.8700119)]\n",
      "[('n02130308', 'cheetah', 0.27749282)]\n",
      "[('n02130308', 'cheetah', 0.5376926)]\n",
      "[('n02130308', 'cheetah', 0.7487131)]\n",
      "[('n02110341', 'unknown', 0.104983896)]\n",
      "[('n02134084', 'unknown', 0.18382812)]\n",
      "[('n02130308', 'cheetah', 0.85691977)]\n",
      "[('n03388043', 'unknown', 0.14270817)]\n",
      "[('n03042490', 'unknown', 0.30236238)]\n",
      "[('n02130308', 'cheetah', 0.17150311)]\n",
      "[('n02965783', 'unknown', 0.3196115)]\n",
      "[('n04371774', 'unknown', 0.17024292)]\n",
      "[('n02130308', 'cheetah', 0.99168384)]\n",
      "[('n02130308', 'cheetah', 0.8953599)]\n",
      "[('n07753592', 'unknown', 0.20233187)]\n",
      "[('n02130308', 'cheetah', 0.9980135)]\n",
      "[('n03388043', 'unknown', 0.81412476)]\n",
      "[('n02110341', 'unknown', 0.6352027)]\n",
      "[('n03388043', 'unknown', 0.7365158)]\n",
      "[('n03388043', 'unknown', 0.5323641)]\n",
      "[('n02965783', 'unknown', 0.25510183)]\n",
      "[('n02130308', 'cheetah', 0.3900264)]\n",
      "[('n03388043', 'unknown', 0.6621719)]\n",
      "[('n02130308', 'cheetah', 0.96425927)]\n",
      "[('n02437616', 'unknown', 0.5691273)]\n",
      "[('n02133161', 'unknown', 0.24446605)]\n",
      "[('n02130308', 'cheetah', 0.67767715)]\n",
      "[('n02125311', 'unknown', 0.162105)]\n",
      "[('n03388043', 'unknown', 0.13695243)]\n",
      "[('n03388043', 'unknown', 0.9044142)]\n",
      "[('n02114855', 'unknown', 0.082299225)]\n",
      "[('n04589890', 'unknown', 0.25251454)]\n",
      "[('n03388043', 'unknown', 0.5011996)]\n",
      "[('n03891251', 'unknown', 0.6193404)]\n",
      "[('n03388043', 'unknown', 0.93240154)]\n",
      "[('n03388043', 'unknown', 0.8627663)]\n",
      "[('n03388043', 'unknown', 0.6152578)]\n",
      "[('n02130308', 'cheetah', 0.56347215)]\n",
      "[('n02130308', 'cheetah', 0.49129173)]\n",
      "[('n03388043', 'unknown', 0.10173483)]\n",
      "[('n02130308', 'cheetah', 0.59600055)]\n",
      "[('n03388043', 'unknown', 0.92299867)]\n",
      "[('n02410509', 'unknown', 0.22068985)]\n",
      "[('n02130308', 'cheetah', 0.6381334)]\n",
      "[('n02130308', 'cheetah', 0.99556714)]\n",
      "[('n03388043', 'unknown', 0.7084504)]\n",
      "[('n03388043', 'unknown', 0.9744228)]\n",
      "[('n03388043', 'unknown', 0.4921973)]\n",
      "[('n02130308', 'cheetah', 0.8047618)]\n",
      "[('n03388043', 'unknown', 0.7396712)]\n",
      "[('n02130308', 'cheetah', 0.66602033)]\n",
      "[('n04326547', 'unknown', 0.04903343)]\n",
      "[('n03388043', 'unknown', 0.9532906)]\n",
      "[('n03388043', 'unknown', 0.6517602)]\n",
      "[('n03388043', 'unknown', 0.9889515)]\n",
      "[('n03388043', 'unknown', 0.9855112)]\n",
      "[('n01855672', 'unknown', 0.14926298)]\n",
      "[('n03788365', 'unknown', 0.09278791)]\n",
      "[('n02130308', 'cheetah', 0.92502576)]\n",
      "[('n02130308', 'cheetah', 0.9729662)]\n",
      "[('n02130308', 'cheetah', 0.9921295)]\n",
      "[('n03891251', 'unknown', 0.18674983)]\n",
      "[('n04589890', 'unknown', 0.13469723)]\n",
      "[('n02130308', 'cheetah', 0.98887515)]\n",
      "[('n02130308', 'cheetah', 0.9929858)]\n",
      "[('n03388043', 'unknown', 0.43174177)]\n",
      "[('n03388043', 'unknown', 0.9755106)]\n",
      "[('n02130308', 'cheetah', 0.520409)]\n",
      "[('n03388043', 'unknown', 0.37116972)]\n",
      "[('n04423845', 'unknown', 0.8435431)]\n",
      "[('n03388043', 'unknown', 0.5666149)]\n",
      "[('n03743016', 'unknown', 0.12681785)]\n",
      "[('n02808440', 'unknown', 0.321718)]\n",
      "[('n03388043', 'unknown', 0.73355514)]\n",
      "[('n02130308', 'cheetah', 0.98791516)]\n",
      "[('n03388043', 'unknown', 0.95194143)]\n",
      "[('n02130308', 'cheetah', 0.28192475)]\n",
      "[('n03788365', 'unknown', 0.3197199)]\n",
      "[('n02130308', 'cheetah', 0.93328166)]\n",
      "[('n02130308', 'cheetah', 0.29834118)]\n",
      "[('n02130308', 'cheetah', 0.86553377)]\n",
      "[('n03388043', 'unknown', 0.8742507)]\n",
      "[('n02130308', 'cheetah', 0.98470795)]\n",
      "[('n02130308', 'cheetah', 0.9642321)]\n",
      "[('n02480855', 'unknown', 0.13770849)]\n",
      "[('n03388043', 'unknown', 0.94725895)]\n",
      "[('n04371774', 'unknown', 0.18147008)]\n",
      "[('n02130308', 'cheetah', 0.5392784)]\n",
      "[('n09246464', 'unknown', 0.28114903)]\n",
      "[('n02965783', 'unknown', 0.40150866)]\n",
      "[('n02130308', 'cheetah', 0.6841345)]\n",
      "[('n03388043', 'unknown', 0.16095152)]\n",
      "[('n02130308', 'cheetah', 0.26437387)]\n",
      "[('n03388043', 'unknown', 0.45557272)]\n",
      "[('n03388043', 'unknown', 0.7379797)]\n",
      "[('n03388043', 'unknown', 0.5221809)]\n",
      "[('n03891251', 'unknown', 0.37290218)]\n",
      "[('n03388043', 'unknown', 0.21144252)]\n",
      "[('n03388043', 'unknown', 0.2008764)]\n",
      "[('n03388043', 'unknown', 0.89499325)]\n",
      "[('n03388043', 'unknown', 0.2596641)]\n",
      "[('n02130308', 'cheetah', 0.9860465)]\n",
      "[('n02130308', 'cheetah', 0.9870172)]\n",
      "[('n04371774', 'unknown', 0.26658183)]\n",
      "[('n03388043', 'unknown', 0.8126748)]\n",
      "[('n02130308', 'cheetah', 0.80074155)]\n",
      "[('n03743016', 'unknown', 0.28515694)]\n",
      "[('n02130308', 'cheetah', 0.81653965)]\n",
      "[('n02130308', 'cheetah', 0.83673406)]\n",
      "[('n03958227', 'unknown', 0.29346892)]\n",
      "[('n09246464', 'unknown', 0.47808683)]\n",
      "[('n03388043', 'unknown', 0.46912116)]\n",
      "[('n04423845', 'unknown', 0.97712165)]\n",
      "[('n02130308', 'cheetah', 0.36871797)]\n",
      "[('n03891251', 'unknown', 0.19310248)]\n",
      "[('n03788365', 'unknown', 0.41526625)]\n",
      "[('n02130308', 'cheetah', 0.9977348)]\n",
      "[('n02125311', 'unknown', 0.26417798)]\n",
      "[('n04371774', 'unknown', 0.29832405)]\n",
      "[('n02130308', 'cheetah', 0.96558636)]\n",
      "[('n03388043', 'unknown', 0.5083944)]\n",
      "[('n02128385', 'leopard', 0.54014385)]\n",
      "[('n02107312', 'unknown', 0.44167054)]\n",
      "[('n02130308', 'cheetah', 0.82453233)]\n",
      "[('n07248320', 'unknown', 0.10677735)]\n",
      "[('n04371774', 'unknown', 0.17962627)]\n",
      "[('n02114548', 'unknown', 0.16718562)]\n",
      "[('n02130308', 'cheetah', 0.9107293)]\n",
      "[('n02115641', 'unknown', 0.9516452)]\n",
      "[('n03388043', 'unknown', 0.8032525)]\n",
      "[('n02130308', 'cheetah', 0.8921053)]\n",
      "[('n03891251', 'unknown', 0.14680922)]\n",
      "[('n03388043', 'unknown', 0.51400405)]\n",
      "[('n03788365', 'unknown', 0.8867632)]\n",
      "[('n02130308', 'cheetah', 0.873212)]\n",
      "[('n02130308', 'cheetah', 0.25480643)]\n",
      "[('n02130308', 'cheetah', 0.4068876)]\n",
      "[('n03388043', 'unknown', 0.5441685)]\n",
      "[('n02130308', 'cheetah', 0.9873518)]\n",
      "[('n03388043', 'unknown', 0.47598287)]\n",
      "[('n02346627', 'unknown', 0.09624559)]\n",
      "[('n03891251', 'unknown', 0.16378748)]\n",
      "[('n02130308', 'cheetah', 0.97906494)]\n",
      "[('n02504013', 'unknown', 0.100349635)]\n",
      "[('n03388043', 'unknown', 0.16665117)]\n",
      "[('n03388043', 'unknown', 0.5150262)]\n",
      "[('n03388043', 'unknown', 0.81792974)]\n",
      "[('n02130308', 'cheetah', 0.9576994)]\n",
      "[('n03388043', 'unknown', 0.8214986)]\n",
      "[('n03388043', 'unknown', 0.98517555)]\n",
      "[('n03388043', 'unknown', 0.996234)]\n",
      "[('n02965783', 'unknown', 0.33435386)]\n",
      "[('n02130308', 'cheetah', 0.9887581)]\n",
      "[('n02130308', 'cheetah', 0.13121508)]\n",
      "[('n02130308', 'cheetah', 0.99877983)]\n",
      "[('n02127052', 'unknown', 0.23228872)]\n",
      "[('n03388043', 'unknown', 0.19850224)]\n",
      "[('n02130308', 'cheetah', 0.99531245)]\n",
      "[('n02504458', 'unknown', 0.05856052)]\n",
      "[('n03388043', 'unknown', 0.9508953)]\n",
      "[('n02130308', 'cheetah', 0.31605554)]\n",
      "[('n02130308', 'cheetah', 0.2976949)]\n",
      "[('n02130308', 'cheetah', 0.7939272)]\n",
      "[('n03388043', 'unknown', 0.34276858)]\n",
      "[('n03388043', 'unknown', 0.6267337)]\n",
      "[('n04371774', 'unknown', 0.16992536)]\n",
      "[('n02130308', 'cheetah', 0.77277553)]\n",
      "[('n03042490', 'unknown', 0.2129241)]\n",
      "[('n02326432', 'unknown', 0.22265215)]\n",
      "[('n03388043', 'unknown', 0.869672)]\n",
      "[('n02965783', 'unknown', 0.24823943)]\n",
      "[('n02130308', 'cheetah', 0.19071704)]\n",
      "[('n03388043', 'unknown', 0.95597476)]\n",
      "[('n07248320', 'unknown', 0.5416864)]\n",
      "[('n03788365', 'unknown', 0.810308)]\n",
      "[('n02130308', 'cheetah', 0.22883123)]\n",
      "[('n03388043', 'unknown', 0.62582815)]\n",
      "[('n02085620', 'unknown', 0.06568755)]\n",
      "[('n02130308', 'cheetah', 0.63729316)]\n",
      "[('n03388043', 'unknown', 0.26033708)]\n",
      "[('n02480855', 'unknown', 0.11600904)]\n",
      "[('n02114855', 'unknown', 0.06735386)]\n",
      "[('n03388043', 'unknown', 0.65644336)]\n",
      "[('n03388043', 'unknown', 0.6231625)]\n",
      "[('n04371774', 'unknown', 0.21982838)]\n",
      "[('n02130308', 'cheetah', 0.9559052)]\n",
      "[('n02965783', 'unknown', 0.26542425)]\n",
      "[('n04275548', 'unknown', 0.09871946)]\n",
      "[('n03388043', 'unknown', 0.5790054)]\n",
      "[('n02130308', 'cheetah', 0.97957486)]\n",
      "[('n03042490', 'unknown', 0.32107958)]\n",
      "[('n03388043', 'unknown', 0.86074877)]\n",
      "[('n02130308', 'cheetah', 0.6580637)]\n",
      "[('n02130308', 'cheetah', 0.9942987)]\n",
      "[('n07248320', 'unknown', 0.2572471)]\n",
      "[('n03788365', 'unknown', 0.89837444)]\n",
      "[('n04371774', 'unknown', 0.23723277)]\n",
      "[('n03388043', 'unknown', 0.8920967)]\n",
      "[('n02391049', 'unknown', 0.8535444)]\n",
      "[('n03388043', 'unknown', 0.13492812)]\n",
      "[('n02125311', 'unknown', 0.42351806)]\n",
      "[('n03388043', 'unknown', 0.8623801)]\n",
      "[('n02965783', 'unknown', 0.26198983)]\n",
      "[('n02130308', 'cheetah', 0.9989116)]\n",
      "[('n03788365', 'unknown', 0.39634842)]\n",
      "[('n03388043', 'unknown', 0.48053643)]\n",
      "[('n03388043', 'unknown', 0.91986173)]\n",
      "[('n02391049', 'unknown', 0.22911012)]\n",
      "[('n03388043', 'unknown', 0.8473956)]\n",
      "[('n03788365', 'unknown', 0.3256397)]\n",
      "[('n02480855', 'unknown', 0.07698156)]\n",
      "[('n02130308', 'cheetah', 0.9701418)]\n",
      "[('n02125311', 'unknown', 0.17799011)]\n",
      "[('n02130308', 'cheetah', 0.98745805)]\n",
      "[('n03388043', 'unknown', 0.9991721)]\n",
      "[('n02130308', 'cheetah', 0.82581246)]\n",
      "[('n02130308', 'cheetah', 0.777069)]\n",
      "[('n03388043', 'unknown', 0.97369677)]\n",
      "[('n02130308', 'cheetah', 0.69673294)]\n",
      "[('n03388043', 'unknown', 0.33750373)]\n",
      "[('n07248320', 'unknown', 0.07480544)]\n",
      "[('n02114855', 'unknown', 0.6500089)]\n",
      "[('n02130308', 'cheetah', 0.55497175)]\n",
      "[('n02130308', 'cheetah', 0.77852035)]\n",
      "[('n04371774', 'unknown', 0.852901)]\n",
      "[('n02130308', 'cheetah', 0.92492783)]\n",
      "[('n02110185', 'unknown', 0.14462768)]\n",
      "[('n02504013', 'unknown', 0.26242885)]\n",
      "[('n03388043', 'unknown', 0.9802476)]\n",
      "[('n02130308', 'cheetah', 0.8406799)]\n",
      "[('n03788365', 'unknown', 0.17570105)]\n",
      "[('n02130308', 'cheetah', 0.91170293)]\n",
      "[('n03388043', 'unknown', 0.47738242)]\n",
      "[('n03788365', 'unknown', 0.86167413)]\n",
      "[('n02130308', 'cheetah', 0.47922942)]\n",
      "[('n02130308', 'cheetah', 0.9948856)]\n",
      "[('n07248320', 'unknown', 0.2620156)]\n",
      "[('n02415577', 'unknown', 0.3291312)]\n",
      "[('n02130308', 'cheetah', 0.8126156)]\n",
      "[('n03388043', 'unknown', 0.85340905)]\n",
      "[('n02130308', 'cheetah', 0.8709358)]\n",
      "[('n03388043', 'unknown', 0.753239)]\n",
      "[('n03388043', 'unknown', 0.82041323)]\n",
      "[('n03388043', 'unknown', 0.94080764)]\n",
      "[('n03388043', 'unknown', 0.38002017)]\n",
      "[('n02130308', 'cheetah', 0.48882514)]\n",
      "[('n02130308', 'cheetah', 0.22730945)]\n",
      "[('n03388043', 'unknown', 0.7081985)]\n",
      "[('n02123159', 'unknown', 0.3752692)]\n",
      "[('n03788365', 'unknown', 0.60540485)]\n",
      "[('n03388043', 'unknown', 0.6233162)]\n",
      "[('n03388043', 'unknown', 0.3275634)]\n",
      "[('n02130308', 'cheetah', 0.91687435)]\n",
      "[('n02130308', 'cheetah', 0.5127541)]\n",
      "[('n03388043', 'unknown', 0.74769473)]\n",
      "[('n02454379', 'unknown', 0.70940787)]\n",
      "[('n03042490', 'unknown', 0.1848493)]\n",
      "[('n02643566', 'unknown', 0.21222246)]\n",
      "[('n02130308', 'cheetah', 0.994007)]\n",
      "[('n04589890', 'unknown', 0.10749079)]\n",
      "[('n09229709', 'unknown', 0.2674213)]\n",
      "[('n02130308', 'cheetah', 0.9712752)]\n",
      "[('n03388043', 'unknown', 0.08462649)]\n",
      "[('n02130308', 'cheetah', 0.63065773)]\n",
      "[('n03788365', 'unknown', 0.24758586)]\n",
      "[('n03388043', 'unknown', 0.42246446)]\n",
      "[('n03388043', 'unknown', 0.30767366)]\n",
      "[('n02130308', 'cheetah', 0.9221915)]\n",
      "[('n03891251', 'unknown', 0.13413793)]\n",
      "[('n03388043', 'unknown', 0.39146984)]\n",
      "[('n02504013', 'unknown', 0.08797813)]\n",
      "[('n02130308', 'cheetah', 0.75742763)]\n",
      "[('n03388043', 'unknown', 0.28600377)]\n",
      "[('n03743016', 'unknown', 0.6810503)]\n",
      "[('n02130308', 'cheetah', 0.38386703)]\n",
      "[('n02130308', 'cheetah', 0.6285589)]\n",
      "[('n03388043', 'unknown', 0.670649)]\n",
      "[('n02130308', 'cheetah', 0.99127626)]\n",
      "[('n02130308', 'cheetah', 0.99661034)]\n",
      "[('n03388043', 'unknown', 0.9633969)]\n",
      "[('n03388043', 'unknown', 0.7810629)]\n",
      "[('n02130308', 'cheetah', 0.9968359)]\n",
      "[('n02130308', 'cheetah', 0.5175336)]\n",
      "[('n03388043', 'unknown', 0.76835513)]\n",
      "[('n02130308', 'cheetah', 0.22701491)]\n",
      "[('n02114548', 'unknown', 0.40581715)]\n",
      "[('n02391049', 'unknown', 0.2710949)]\n",
      "[('n01855672', 'unknown', 0.17285296)]\n",
      "[('n02130308', 'cheetah', 0.95635843)]\n",
      "[('n03388043', 'unknown', 0.4489337)]\n",
      "[('n02130308', 'cheetah', 0.4020017)]\n",
      "[('n02130308', 'cheetah', 0.917632)]\n",
      "[('n03788365', 'unknown', 0.7685281)]\n",
      "[('n03388043', 'unknown', 0.15970501)]\n",
      "[('n01698640', 'unknown', 0.28275284)]\n",
      "[('n03388043', 'unknown', 0.595625)]\n",
      "[('n02130308', 'cheetah', 0.5745609)]\n",
      "[('n02130308', 'cheetah', 0.91432416)]\n",
      "[('n02965783', 'unknown', 0.14222674)]\n",
      "[('n02965783', 'unknown', 0.11192344)]\n",
      "[('n03788365', 'unknown', 0.3069361)]\n",
      "[('n02497673', 'unknown', 0.35545722)]\n",
      "[('n02130308', 'cheetah', 0.39499432)]\n",
      "[('n02107312', 'unknown', 0.20680462)]\n",
      "[('n02130308', 'cheetah', 0.99901485)]\n",
      "[('n03388043', 'unknown', 0.38500673)]\n",
      "[('n03388043', 'unknown', 0.956347)]\n",
      "[('n02504458', 'unknown', 0.06465912)]\n",
      "[('n03388043', 'unknown', 0.80843866)]\n",
      "[('n07248320', 'unknown', 0.28922963)]\n",
      "[('n02130308', 'cheetah', 0.65541726)]\n",
      "[('n02130308', 'cheetah', 0.09501839)]\n",
      "[('n03388043', 'unknown', 0.98885137)]\n",
      "[('n02130308', 'cheetah', 0.8494039)]\n",
      "[('n02125311', 'unknown', 0.30566117)]\n",
      "[('n03891251', 'unknown', 0.28888166)]\n",
      "[('n03388043', 'unknown', 0.97864586)]\n",
      "[('n02110341', 'unknown', 0.33029512)]\n",
      "[('n03388043', 'unknown', 0.88191545)]\n",
      "[('n02130308', 'cheetah', 0.9805679)]\n",
      "[('n03788365', 'unknown', 0.43872228)]\n",
      "[('n03891251', 'unknown', 0.11909788)]\n",
      "[('n03891251', 'unknown', 0.46001127)]\n",
      "[('n02130308', 'cheetah', 0.9391096)]\n",
      "[('n01748264', 'unknown', 0.45463192)]\n",
      "[('n02123159', 'unknown', 0.08604425)]\n",
      "[('n01855672', 'unknown', 0.18648402)]\n",
      "[('n03042490', 'unknown', 0.48309496)]\n",
      "[('n03388043', 'unknown', 0.21666622)]\n",
      "[('n02130308', 'cheetah', 0.6154845)]\n",
      "[('n01695060', 'unknown', 0.07781505)]\n",
      "[('n03388043', 'unknown', 0.81529176)]\n",
      "[('n02130308', 'cheetah', 0.89988446)]\n",
      "[('n02130308', 'cheetah', 0.96629167)]\n",
      "[('n02130308', 'cheetah', 0.61320436)]\n",
      "[('n02130308', 'cheetah', 0.14980881)]\n",
      "[('n02965783', 'unknown', 0.23677605)]\n",
      "[('n02130308', 'cheetah', 0.3487371)]\n",
      "[('n03891251', 'unknown', 0.2376939)]\n",
      "[('n03042490', 'unknown', 0.20955718)]\n",
      "[('n03388043', 'unknown', 0.9593757)]\n",
      "[('n02130308', 'cheetah', 0.99884605)]\n",
      "[('n03388043', 'unknown', 0.71160334)]\n",
      "[('n02480855', 'unknown', 0.12362564)]\n",
      "[('n04371774', 'unknown', 0.13717847)]\n",
      "[('n03388043', 'unknown', 0.43130776)]\n",
      "[('n02130308', 'cheetah', 0.98772824)]\n",
      "[('n02114712', 'unknown', 0.06660006)]\n",
      "[('n02130308', 'cheetah', 0.7423791)]\n",
      "[('n04371774', 'unknown', 0.17694165)]\n",
      "[('n03388043', 'unknown', 0.83970535)]\n",
      "[('n02130308', 'cheetah', 0.773151)]\n",
      "[('n03388043', 'unknown', 0.28408396)]\n",
      "[('n02114855', 'unknown', 0.16416213)]\n",
      "[('n03891251', 'unknown', 0.11990029)]\n",
      "[('n03891251', 'unknown', 0.3869262)]\n",
      "[('n02130308', 'cheetah', 0.62957007)]\n",
      "[('n04275548', 'unknown', 0.20240924)]\n",
      "[('n03388043', 'unknown', 0.12622023)]\n",
      "[('n03788365', 'unknown', 0.24009304)]\n",
      "[('n02130308', 'cheetah', 0.94060045)]\n",
      "[('n03788365', 'unknown', 0.3993382)]\n",
      "[('n02130308', 'cheetah', 0.6464014)]\n",
      "[('n02130308', 'cheetah', 0.9848267)]\n",
      "[('n03388043', 'unknown', 0.4820479)]\n",
      "[('n04423845', 'unknown', 0.35451493)]\n",
      "[('n02114855', 'unknown', 0.1635395)]\n",
      "[('n03788365', 'unknown', 0.46529052)]\n",
      "[('n04423845', 'unknown', 0.44826984)]\n",
      "[('n02423022', 'unknown', 0.2166104)]\n",
      "[('n03388043', 'unknown', 0.11446848)]\n",
      "[('n03388043', 'unknown', 0.5442703)]\n",
      "[('n02130308', 'cheetah', 0.9557983)]\n",
      "[('n03388043', 'unknown', 0.33026958)]\n",
      "[('n02130308', 'cheetah', 0.30738673)]\n",
      "[('n04423845', 'unknown', 0.3560228)]\n",
      "[('n03388043', 'unknown', 0.93396133)]\n",
      "[('n02130308', 'cheetah', 0.995773)]\n",
      "[('n01675722', 'unknown', 0.74774796)]\n",
      "[('n02114367', 'unknown', 0.26674628)]\n",
      "[('n02391049', 'unknown', 0.14227398)]\n",
      "[('n03388043', 'unknown', 0.79994696)]\n",
      "[('n02965783', 'unknown', 0.17328143)]\n",
      "[('n02437312', 'unknown', 0.11890948)]\n",
      "[('n02125311', 'unknown', 0.11515069)]\n",
      "[('n03388043', 'unknown', 0.7222348)]\n",
      "[('n03788365', 'unknown', 0.23672834)]\n",
      "[('n02965783', 'unknown', 0.44614118)]\n",
      "[('n03891251', 'unknown', 0.1760558)]\n",
      "[('n02130308', 'cheetah', 0.92722064)]\n",
      "[('n02965783', 'unknown', 0.45029095)]\n",
      "[('n02130308', 'cheetah', 0.675678)]\n",
      "[('n07248320', 'unknown', 0.11487341)]\n",
      "[('n03388043', 'unknown', 0.42319804)]\n",
      "[('n03388043', 'unknown', 0.99740714)]\n",
      "[('n03388043', 'unknown', 0.9402979)]\n",
      "[('n02497673', 'unknown', 0.14350045)]\n",
      "[('n03388043', 'unknown', 0.8683176)]\n",
      "[('n02130308', 'cheetah', 0.5131575)]\n",
      "[('n03388043', 'unknown', 0.99793965)]\n",
      "[('n03388043', 'unknown', 0.80816084)]\n",
      "[('n04371774', 'unknown', 0.2672755)]\n",
      "[('n03388043', 'unknown', 0.99533737)]\n",
      "[('n01675722', 'unknown', 0.07499794)]\n",
      "[('n02965783', 'unknown', 0.34779748)]\n",
      "[('n02110341', 'unknown', 0.5382874)]\n",
      "[('n03788365', 'unknown', 0.6381791)]\n",
      "[('n03788365', 'unknown', 0.27241823)]\n",
      "[('n02130308', 'cheetah', 0.99808013)]\n",
      "[('n09229709', 'unknown', 0.182145)]\n",
      "[('n03388043', 'unknown', 0.69920313)]\n",
      "[('n07248320', 'unknown', 0.15865116)]\n",
      "[('n02504013', 'unknown', 0.13916671)]\n",
      "[('n03388043', 'unknown', 0.21192554)]\n",
      "[('n03532672', 'unknown', 0.15085618)]\n",
      "[('n02130308', 'cheetah', 0.71922696)]\n",
      "[('n02130308', 'cheetah', 0.6775324)]\n",
      "[('n03388043', 'unknown', 0.8193065)]\n",
      "[('n02130308', 'cheetah', 0.9371807)]\n",
      "[('n03388043', 'unknown', 0.30113974)]\n",
      "[('n03891251', 'unknown', 0.1026173)]\n",
      "[('n02130308', 'cheetah', 0.98898715)]\n",
      "[('n02130308', 'cheetah', 0.98889625)]\n",
      "[('n02130308', 'cheetah', 0.98718655)]\n",
      "[('n03388043', 'unknown', 0.4826219)]\n",
      "[('n03891251', 'unknown', 0.17280051)]\n",
      "[('n03743016', 'unknown', 0.67133796)]\n",
      "[('n03388043', 'unknown', 0.21135794)]\n",
      "[('n03388043', 'unknown', 0.9342021)]\n",
      "[('n02130308', 'cheetah', 0.62857604)]\n",
      "[('n03388043', 'unknown', 0.9825053)]\n",
      "[('n02130308', 'cheetah', 0.67664325)]\n",
      "[('n02130308', 'cheetah', 0.7831781)]\n",
      "[('n03891251', 'unknown', 0.32180727)]\n",
      "[('n03891251', 'unknown', 0.1021743)]\n",
      "[('n02130308', 'cheetah', 0.12495731)]\n",
      "[('n02130308', 'cheetah', 0.71054757)]\n",
      "[('n04423845', 'unknown', 0.97381616)]\n",
      "[('n02808440', 'unknown', 0.40467072)]\n",
      "[('n03788365', 'unknown', 0.27194482)]\n",
      "[('n02423022', 'unknown', 0.14266442)]\n",
      "[('n02130308', 'cheetah', 0.93314314)]\n",
      "[('n03788365', 'unknown', 0.9006317)]\n",
      "[('n02130308', 'cheetah', 0.7887323)]\n",
      "[('n03388043', 'unknown', 0.62746817)]\n",
      "[('n03388043', 'unknown', 0.45981532)]\n",
      "[('n03388043', 'unknown', 0.2958693)]\n",
      "[('n03891251', 'unknown', 0.08508815)]\n",
      "[('n04606251', 'unknown', 0.3884765)]\n",
      "[('n03388043', 'unknown', 0.60451496)]\n",
      "[('n03788365', 'unknown', 0.42910153)]\n",
      "[('n04507155', 'unknown', 0.4878025)]\n",
      "[('n03388043', 'unknown', 0.20583226)]\n",
      "[('n02410509', 'unknown', 0.28987625)]\n",
      "[('n02130308', 'cheetah', 0.8080396)]\n",
      "[('n03388043', 'unknown', 0.17847477)]\n",
      "[('n03388043', 'unknown', 0.48877403)]\n",
      "[('n02111500', 'unknown', 0.5578028)]\n",
      "[('n02130308', 'cheetah', 0.22954415)]\n",
      "[('n02130308', 'cheetah', 0.9797934)]\n",
      "[('n02130308', 'cheetah', 0.9991683)]\n",
      "[('n02104365', 'unknown', 0.15392324)]\n",
      "[('n02130308', 'cheetah', 0.32673818)]\n",
      "[('n03388043', 'unknown', 0.9125438)]\n",
      "[('n04366367', 'unknown', 0.4208713)]\n",
      "[('n02130308', 'cheetah', 0.9698439)]\n",
      "[('n03891251', 'unknown', 0.26399618)]\n",
      "[('n03388043', 'unknown', 0.18105613)]\n",
      "[('n02130308', 'cheetah', 0.52173233)]\n",
      "[('n03388043', 'unknown', 0.90261716)]\n",
      "[('n03388043', 'unknown', 0.9988194)]\n",
      "[('n02130308', 'cheetah', 0.7523169)]\n",
      "[('n02130308', 'cheetah', 0.99146855)]\n",
      "[('n02100735', 'unknown', 0.6156989)]\n",
      "[('n07248320', 'unknown', 0.22833958)]\n",
      "[('n02130308', 'cheetah', 0.91683346)]\n",
      "[('n03388043', 'unknown', 0.889703)]\n",
      "[('n02130308', 'cheetah', 0.99287206)]\n",
      "[('n03388043', 'unknown', 0.74511045)]\n",
      "[('n02130308', 'cheetah', 0.9601639)]\n",
      "[('n02130308', 'cheetah', 0.9755195)]\n",
      "[('n02130308', 'cheetah', 0.49557617)]\n",
      "[('n03891251', 'unknown', 0.1116777)]\n",
      "[('n02130308', 'cheetah', 0.5222089)]\n",
      "[('n02130308', 'cheetah', 0.8238675)]\n",
      "[('n03388043', 'unknown', 0.92843634)]\n",
      "[('n03388043', 'unknown', 0.89048344)]\n",
      "[('n03388043', 'unknown', 0.53411275)]\n",
      "[('n02130308', 'cheetah', 0.86449677)]\n",
      "[('n03388043', 'unknown', 0.88507545)]\n",
      "[('n03042490', 'unknown', 0.24728589)]\n",
      "[('n02130308', 'cheetah', 0.9834472)]\n",
      "[('n03388043', 'unknown', 0.8845265)]\n",
      "[('n03388043', 'unknown', 0.46644133)]\n",
      "[('n03788365', 'unknown', 0.28353837)]\n",
      "[('n07248320', 'unknown', 0.21940799)]\n",
      "[('n02391049', 'unknown', 0.24987149)]\n",
      "[('n02133161', 'unknown', 0.10957599)]\n",
      "[('n03388043', 'unknown', 0.99761754)]\n",
      "[('n03388043', 'unknown', 0.6495728)]\n",
      "[('n02130308', 'cheetah', 0.9939275)]\n",
      "[('n02965783', 'unknown', 0.37551475)]\n",
      "[('n03532672', 'unknown', 0.1693555)]\n",
      "[('n03388043', 'unknown', 0.9125776)]\n",
      "[('n02497673', 'unknown', 0.15165487)]\n",
      "[('n04589890', 'unknown', 0.26427594)]\n",
      "[('n03388043', 'unknown', 0.16903073)]\n",
      "[('n02130308', 'cheetah', 0.52934384)]\n",
      "[('n02130308', 'cheetah', 0.6872709)]\n",
      "[('n02504458', 'unknown', 0.34150782)]\n",
      "[('n03891251', 'unknown', 0.096476085)]\n",
      "[('n03891251', 'unknown', 0.09941593)]\n",
      "[('n07248320', 'unknown', 0.10488692)]\n",
      "[('n03388043', 'unknown', 0.56309223)]\n",
      "[('n04589890', 'unknown', 0.16732742)]\n",
      "[('n03388043', 'unknown', 0.48037422)]\n",
      "[('n02130308', 'cheetah', 0.8223172)]\n",
      "[('n03891251', 'unknown', 0.07145076)]\n",
      "[('n02130308', 'cheetah', 0.3895373)]\n",
      "[('n02128385', 'leopard', 0.8155543)]\n",
      "[('n03388043', 'unknown', 0.4830183)]\n",
      "[('n03388043', 'unknown', 0.59408766)]\n",
      "[('n03388043', 'unknown', 0.31683943)]\n",
      "[('n02130308', 'cheetah', 0.9719499)]\n",
      "[('n02130308', 'cheetah', 0.9966389)]\n",
      "[('n03388043', 'unknown', 0.879486)]\n",
      "[('n02114855', 'unknown', 0.23640147)]\n",
      "[('n03388043', 'unknown', 0.9044741)]\n",
      "[('n03388043', 'unknown', 0.51171416)]\n",
      "[('n02130308', 'cheetah', 0.7031681)]\n",
      "[('n03788365', 'unknown', 0.74790263)]\n",
      "[('n03388043', 'unknown', 0.32989368)]\n",
      "[('n03388043', 'unknown', 0.9503225)]\n",
      "[('n03388043', 'unknown', 0.81255877)]\n",
      "[('n03388043', 'unknown', 0.984979)]\n",
      "[('n02403003', 'unknown', 0.52643454)]\n",
      "[('n02130308', 'cheetah', 0.9926859)]\n",
      "[('n04589890', 'unknown', 0.13828176)]\n",
      "[('n02130308', 'cheetah', 0.91013336)]\n",
      "[('n02130308', 'cheetah', 0.98893625)]\n",
      "[('n02109047', 'unknown', 0.6554597)]\n",
      "[('n03388043', 'unknown', 0.89283407)]\n",
      "[('n03388043', 'unknown', 0.7740253)]\n",
      "[('n02395406', 'unknown', 0.2019401)]\n",
      "[('n02130308', 'cheetah', 0.5828654)]\n",
      "[('n02130308', 'cheetah', 0.527014)]\n",
      "[('n03388043', 'unknown', 0.85983604)]\n",
      "[('n02125311', 'unknown', 0.27026734)]\n",
      "[('n03388043', 'unknown', 0.2969861)]\n",
      "[('n04423845', 'unknown', 0.99791604)]\n",
      "[('n03958227', 'unknown', 0.122443244)]\n",
      "[('n09246464', 'unknown', 0.3606204)]\n",
      "[('n03388043', 'unknown', 0.6995433)]\n",
      "[('n02130308', 'cheetah', 0.73197013)]\n",
      "[('n02130308', 'cheetah', 0.8135253)]\n",
      "[('n02965783', 'unknown', 0.28341714)]\n",
      "[('n02130308', 'cheetah', 0.53747207)]\n",
      "[('n02130308', 'cheetah', 0.09478946)]\n",
      "[('n06359193', 'unknown', 0.060809605)]\n",
      "[('n03388043', 'unknown', 0.98203677)]\n",
      "[('n03388043', 'unknown', 0.78356886)]\n",
      "[('n02417914', 'unknown', 0.49508458)]\n",
      "[('n02130308', 'cheetah', 0.8099162)]\n",
      "[('n03891251', 'unknown', 0.08665435)]\n",
      "[('n02125311', 'unknown', 0.1670257)]\n",
      "[('n02130308', 'cheetah', 0.4455136)]\n",
      "[('n03388043', 'unknown', 0.09471082)]\n",
      "[('n02417914', 'unknown', 0.13193022)]\n",
      "[('n03388043', 'unknown', 0.8148407)]\n",
      "[('n04589890', 'unknown', 0.06080134)]\n",
      "[('n02130308', 'cheetah', 0.07078994)]\n",
      "[('n03388043', 'unknown', 0.61762494)]\n",
      "[('n02130308', 'cheetah', 0.6599215)]\n",
      "[('n02130308', 'cheetah', 0.9552468)]\n",
      "[('n02999410', 'unknown', 0.23431419)]\n",
      "[('n02130308', 'cheetah', 0.9875514)]\n",
      "[('n02130308', 'cheetah', 0.9421153)]\n",
      "[('n03891251', 'unknown', 0.08400569)]\n",
      "[('n03788365', 'unknown', 0.5656883)]\n",
      "[('n02130308', 'cheetah', 0.88711554)]\n",
      "[('n03388043', 'unknown', 0.19112818)]\n",
      "[('n02391049', 'unknown', 0.42311534)]\n",
      "[('n03388043', 'unknown', 0.8062512)]\n",
      "[('n02130308', 'cheetah', 0.4769591)]\n",
      "[('n02107312', 'unknown', 0.1536188)]\n",
      "[('n03388043', 'unknown', 0.24125247)]\n",
      "[('n02965783', 'unknown', 0.37035)]\n",
      "[('n02125311', 'unknown', 0.14090215)]\n",
      "[('n03388043', 'unknown', 0.7966511)]\n",
      "[('n03388043', 'unknown', 0.73419756)]\n",
      "[('n03788365', 'unknown', 0.5945804)]\n",
      "[('n03388043', 'unknown', 0.0916459)]\n",
      "[('n02130308', 'cheetah', 0.17869619)]\n",
      "[('n02480855', 'unknown', 0.16637138)]\n",
      "[('n02965783', 'unknown', 0.2583796)]\n",
      "[('n02130308', 'cheetah', 0.84657377)]\n",
      "[('n03388043', 'unknown', 0.11729756)]\n",
      "[('n02130308', 'cheetah', 0.20597798)]\n",
      "[('n02130308', 'cheetah', 0.96439725)]\n",
      "[('n03388043', 'unknown', 0.18451358)]\n",
      "[('n02130308', 'cheetah', 0.32736337)]\n",
      "[('n02130308', 'cheetah', 0.9687262)]\n",
      "[('n02130308', 'cheetah', 0.31039324)]\n",
      "[('n02130308', 'cheetah', 0.99204105)]\n",
      "[('n02130308', 'cheetah', 0.9682689)]\n",
      "[('n03388043', 'unknown', 0.39820647)]\n",
      "[('n03388043', 'unknown', 0.68480444)]\n",
      "[('n02120505', 'unknown', 0.37839055)]\n",
      "[('n03891251', 'unknown', 0.20582642)]\n",
      "[('n03063689', 'unknown', 0.21848437)]\n",
      "[('n03388043', 'unknown', 0.8574251)]\n",
      "[('n03388043', 'unknown', 0.17578298)]\n",
      "[('n02130308', 'cheetah', 0.35085532)]\n",
      "[('n02643566', 'unknown', 0.09309779)]\n",
      "[('n03388043', 'unknown', 0.6728599)]\n",
      "[('n02130308', 'cheetah', 0.9899921)]\n",
      "[('n03042490', 'unknown', 0.29949751)]\n",
      "[('n03042490', 'unknown', 0.09931975)]\n",
      "[('n04589890', 'unknown', 0.081041284)]\n",
      "[('n03388043', 'unknown', 0.27782765)]\n",
      "[('n02130308', 'cheetah', 0.9892371)]\n",
      "[('n03388043', 'unknown', 0.5853718)]\n",
      "[('n02130308', 'cheetah', 0.8751419)]\n",
      "[('n04371774', 'unknown', 0.82843864)]\n",
      "[('n03388043', 'unknown', 0.53967184)]\n",
      "[('n02130308', 'cheetah', 0.69572985)]\n",
      "[('n07248320', 'unknown', 0.14503278)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n03388043', 'unknown', 0.75624245)]\n",
      "[('n03160309', 'unknown', 0.15382472)]\n",
      "[('n03388043', 'unknown', 0.5004064)]\n",
      "[('n02115641', 'unknown', 0.1613866)]\n",
      "[('n02130308', 'cheetah', 0.95393926)]\n",
      "[('n02480855', 'unknown', 0.14123948)]\n",
      "[('n03388043', 'unknown', 0.9866181)]\n",
      "[('n03388043', 'unknown', 0.2841917)]\n",
      "[('n03388043', 'unknown', 0.88548064)]\n",
      "[('n02130308', 'cheetah', 0.44841567)]\n",
      "[('n03388043', 'unknown', 0.27538982)]\n",
      "[('n04589890', 'unknown', 0.38828263)]\n",
      "[('n02391049', 'unknown', 0.28611243)]\n",
      "[('n02130308', 'cheetah', 0.5822802)]\n",
      "[('n02808440', 'unknown', 0.36215526)]\n",
      "[('n02130308', 'cheetah', 0.4970743)]\n",
      "[('n03388043', 'unknown', 0.54585844)]\n",
      "[('n03388043', 'unknown', 0.7613267)]\n",
      "[('n02130308', 'cheetah', 0.5619429)]\n",
      "[('n02965783', 'unknown', 0.1148753)]\n",
      "[('n03388043', 'unknown', 0.80835766)]\n",
      "[('n02130308', 'cheetah', 0.5508322)]\n",
      "[('n03388043', 'unknown', 0.855549)]\n",
      "[('n02130308', 'cheetah', 0.75662607)]\n",
      "[('n03388043', 'unknown', 0.25432044)]\n",
      "[('n02130308', 'cheetah', 0.8133302)]\n",
      "[('n02130308', 'cheetah', 0.3899516)]\n",
      "[('n02130308', 'cheetah', 0.987199)]\n",
      "[('n03788365', 'unknown', 0.4131633)]\n",
      "[('n02130308', 'cheetah', 0.53467715)]\n",
      "[('n03042490', 'unknown', 0.11294933)]\n",
      "[('n02130308', 'cheetah', 0.9974861)]\n",
      "[('n02130308', 'cheetah', 0.8914729)]\n",
      "[('n02130308', 'cheetah', 0.5289625)]\n",
      "[('n03891251', 'unknown', 0.32996607)]\n",
      "[('n04589890', 'unknown', 0.28070575)]\n",
      "[('n03388043', 'unknown', 0.16820341)]\n",
      "[('n03891251', 'unknown', 0.09212285)]\n",
      "[('n03388043', 'unknown', 0.53151536)]\n",
      "[('n02317335', 'unknown', 0.07966616)]\n",
      "[('n03388043', 'unknown', 0.9807553)]\n",
      "[('n03388043', 'unknown', 0.40086943)]\n",
      "[('n02130308', 'cheetah', 0.9471651)]\n",
      "[('n04589890', 'unknown', 0.19430083)]\n",
      "[('n04589890', 'unknown', 0.10641129)]\n",
      "[('n03388043', 'unknown', 0.8895795)]\n",
      "[('n04589890', 'unknown', 0.34849)]\n",
      "[('n02504458', 'unknown', 0.21211608)]\n",
      "[('n02965783', 'unknown', 0.25610846)]\n",
      "[('n02130308', 'cheetah', 0.9828386)]\n",
      "[('n03388043', 'unknown', 0.15414208)]\n",
      "[('n02480855', 'unknown', 0.72069955)]\n",
      "[('n03388043', 'unknown', 0.8622431)]\n",
      "[('n03891251', 'unknown', 0.23587209)]\n",
      "[('n03388043', 'unknown', 0.3474213)]\n",
      "[('n03788365', 'unknown', 0.37131372)]\n",
      "[('n02130308', 'cheetah', 0.8294534)]\n",
      "[('n03891251', 'unknown', 0.18915002)]\n",
      "[('n03388043', 'unknown', 0.22597136)]\n",
      "[('n02130308', 'cheetah', 0.67752004)]\n",
      "[('n02130308', 'cheetah', 0.8038486)]\n",
      "[('n02130308', 'cheetah', 0.93333817)]\n",
      "[('n03388043', 'unknown', 0.72471786)]\n",
      "[('n02130308', 'cheetah', 0.708249)]\n",
      "[('n03388043', 'unknown', 0.094287634)]\n",
      "[('n04371774', 'unknown', 0.6875983)]\n",
      "[('n03388043', 'unknown', 0.18025656)]\n",
      "[('n03388043', 'unknown', 0.0968533)]\n",
      "[('n03891251', 'unknown', 0.3184461)]\n",
      "[('n02130308', 'cheetah', 0.99542737)]\n",
      "[('n03388043', 'unknown', 0.67007667)]\n",
      "[('n03388043', 'unknown', 0.44489163)]\n",
      "[('n02130308', 'cheetah', 0.13762267)]\n",
      "[('n02480855', 'unknown', 0.22005183)]\n",
      "[('n02437312', 'unknown', 0.60017544)]\n",
      "[('n02110185', 'unknown', 0.20003876)]\n",
      "[('n02130308', 'cheetah', 0.9958067)]\n",
      "[('n03788365', 'unknown', 0.578417)]\n",
      "[('n02130308', 'cheetah', 0.98554647)]\n",
      "[('n03388043', 'unknown', 0.64907634)]\n",
      "[('n03388043', 'unknown', 0.3110883)]\n",
      "[('n03388043', 'unknown', 0.43283933)]\n",
      "[('n02130308', 'cheetah', 0.5095302)]\n",
      "[('n03388043', 'unknown', 0.85370713)]\n",
      "[('n03498962', 'unknown', 0.04869315)]\n",
      "[('n02130308', 'cheetah', 0.9822031)]\n",
      "[('n02114855', 'unknown', 0.2859738)]\n",
      "[('n02130308', 'cheetah', 0.3384838)]\n",
      "[('n02130308', 'cheetah', 0.9883388)]\n",
      "[('n03388043', 'unknown', 0.8069856)]\n",
      "[('n02130308', 'cheetah', 0.22116417)]\n",
      "[('n02130308', 'cheetah', 0.9945629)]\n",
      "[('n03388043', 'unknown', 0.77135533)]\n",
      "[('n02130308', 'cheetah', 0.8602344)]\n",
      "[('n03388043', 'unknown', 0.37420171)]\n",
      "[('n03388043', 'unknown', 0.19087824)]\n",
      "[('n03388043', 'unknown', 0.9130586)]\n",
      "[('n03788365', 'unknown', 0.32654837)]\n",
      "[('n03388043', 'unknown', 0.60083705)]\n",
      "[('n02125311', 'unknown', 0.23659484)]\n",
      "[('n03388043', 'unknown', 0.35031235)]\n",
      "[('n02130308', 'cheetah', 0.98150074)]\n",
      "[('n02130308', 'cheetah', 0.35859364)]\n",
      "[('n02130308', 'cheetah', 0.16223015)]\n",
      "[('n02130308', 'cheetah', 0.79320866)]\n",
      "[('n02130308', 'cheetah', 0.5531956)]\n",
      "[('n03891251', 'unknown', 0.40269652)]\n",
      "[('n03388043', 'unknown', 0.7832925)]\n",
      "[('n03388043', 'unknown', 0.494487)]\n",
      "[('n03388043', 'unknown', 0.23997)]\n",
      "[('n02114367', 'unknown', 0.42195606)]\n",
      "[('n02655020', 'unknown', 0.5164087)]\n",
      "[('n02480855', 'unknown', 0.15280361)]\n",
      "[('n02114712', 'unknown', 0.123651005)]\n",
      "[('n03788365', 'unknown', 0.408947)]\n",
      "[('n03388043', 'unknown', 0.96192)]\n",
      "[('n04423845', 'unknown', 0.5999674)]\n",
      "[('n03388043', 'unknown', 0.27747974)]\n",
      "[('n02130308', 'cheetah', 0.951348)]\n",
      "[('n03388043', 'unknown', 0.40820184)]\n",
      "[('n02130308', 'cheetah', 0.9391688)]\n",
      "[('n02130308', 'cheetah', 0.32276893)]\n",
      "[('n02114367', 'unknown', 0.32505098)]\n",
      "[('n03388043', 'unknown', 0.57340276)]\n",
      "[('n02130308', 'cheetah', 0.49656036)]\n",
      "[('n02130308', 'cheetah', 0.6485467)]\n",
      "[('n03388043', 'unknown', 0.84917694)]\n",
      "[('n03388043', 'unknown', 0.46060655)]\n",
      "[('n03388043', 'unknown', 0.6017422)]\n",
      "[('n02130308', 'cheetah', 0.38994235)]\n",
      "[('n02130308', 'cheetah', 0.75512564)]\n",
      "[('n03388043', 'unknown', 0.7441534)]\n",
      "[('n02130308', 'cheetah', 0.98591655)]\n",
      "[('n03388043', 'unknown', 0.39002183)]\n",
      "[('n03388043', 'unknown', 0.91626513)]\n",
      "[('n02454379', 'unknown', 0.65184045)]\n",
      "[('n02099712', 'unknown', 0.2502963)]\n",
      "[('n03788365', 'unknown', 0.49298805)]\n",
      "[('n02130308', 'cheetah', 0.9834358)]\n",
      "[('n02363005', 'unknown', 0.182969)]\n",
      "[('n07753592', 'unknown', 0.07656967)]\n",
      "[('n09246464', 'unknown', 0.45122644)]\n",
      "[('n03891251', 'unknown', 0.09750536)]\n",
      "[('n03042490', 'unknown', 0.37939018)]\n",
      "[('n04371774', 'unknown', 0.20756821)]\n",
      "[('n02130308', 'cheetah', 0.6503399)]\n",
      "[('n04371774', 'unknown', 0.79653347)]\n",
      "[('n02130308', 'cheetah', 0.45879698)]\n",
      "[('n03388043', 'unknown', 0.952873)]\n",
      "[('n04371774', 'unknown', 0.5629922)]\n",
      "[('n03388043', 'unknown', 0.33398896)]\n",
      "[('n04423845', 'unknown', 0.77671844)]\n",
      "[('n02808440', 'unknown', 0.1513299)]\n",
      "[('n03388043', 'unknown', 0.64196473)]\n",
      "[('n02504013', 'unknown', 0.3214336)]\n",
      "[('n03388043', 'unknown', 0.8646253)]\n",
      "[('n02130308', 'cheetah', 0.9038933)]\n",
      "[('n02130308', 'cheetah', 0.9910657)]\n",
      "[('n02130308', 'cheetah', 0.19084628)]\n",
      "[('n02130308', 'cheetah', 0.9842429)]\n",
      "[('n03388043', 'unknown', 0.9926589)]\n",
      "[('n03388043', 'unknown', 0.2797513)]\n",
      "[('n02437616', 'unknown', 0.23035486)]\n",
      "[('n02808440', 'unknown', 0.39099264)]\n",
      "[('n04366367', 'unknown', 0.11432352)]\n",
      "[('n02130308', 'cheetah', 0.9921409)]\n",
      "[('n03388043', 'unknown', 0.54450697)]\n",
      "[('n02130308', 'cheetah', 0.7365759)]\n",
      "[('n02410509', 'unknown', 0.13387448)]\n",
      "[('n02130308', 'cheetah', 0.9356721)]\n",
      "[('n02130308', 'cheetah', 0.6633745)]\n",
      "[('n02130308', 'cheetah', 0.8382527)]\n",
      "[('n03388043', 'unknown', 0.73114115)]\n",
      "[('n03388043', 'unknown', 0.31394538)]\n",
      "[('n02130308', 'cheetah', 0.89072895)]\n",
      "[('n03891251', 'unknown', 0.10722305)]\n",
      "[('n04371774', 'unknown', 0.22158654)]\n",
      "[('n02130308', 'cheetah', 0.9833053)]\n",
      "[('n02130308', 'cheetah', 0.98589534)]\n",
      "[('n02130308', 'cheetah', 0.9729408)]\n",
      "[('n02504458', 'unknown', 0.19710687)]\n",
      "[('n03388043', 'unknown', 0.6394817)]\n",
      "[('n03388043', 'unknown', 0.31470734)]\n",
      "[('n04589890', 'unknown', 0.13717501)]\n",
      "[('n02130308', 'cheetah', 0.9998735)]\n",
      "[('n02100735', 'unknown', 0.59696156)]\n",
      "[('n02965783', 'unknown', 0.24856834)]\n",
      "[('n03388043', 'unknown', 0.86021125)]\n",
      "[('n04371774', 'unknown', 0.15473579)]\n",
      "[('n03891251', 'unknown', 0.07968118)]\n",
      "[('n02130308', 'cheetah', 0.9755798)]\n",
      "[('n02130308', 'cheetah', 0.7766973)]\n",
      "[('n04371774', 'unknown', 0.12795357)]\n",
      "[('n03388043', 'unknown', 0.9879246)]\n",
      "[('n02480855', 'unknown', 0.15076396)]\n",
      "[('n02130308', 'cheetah', 0.56558865)]\n",
      "[('n07248320', 'unknown', 0.061149158)]\n",
      "[('n01855672', 'unknown', 0.2644035)]\n",
      "[('n03388043', 'unknown', 0.7546797)]\n",
      "[('n03388043', 'unknown', 0.9417483)]\n",
      "[('n02965783', 'unknown', 0.39019322)]\n",
      "[('n02965783', 'unknown', 0.33029974)]\n",
      "[('n03388043', 'unknown', 0.812143)]\n",
      "[('n03388043', 'unknown', 0.993349)]\n",
      "[('n03388043', 'unknown', 0.093587615)]\n",
      "[('n02130308', 'cheetah', 0.24627425)]\n",
      "[('n03388043', 'unknown', 0.83202565)]\n",
      "[('n02114855', 'unknown', 0.1898771)]\n",
      "[('n03388043', 'unknown', 0.31720352)]\n",
      "[('n02114548', 'unknown', 0.22285666)]\n",
      "[('n03388043', 'unknown', 0.43541706)]\n",
      "[('n02130308', 'cheetah', 0.7838947)]\n",
      "[('n03388043', 'unknown', 0.71640795)]\n",
      "[('n02130308', 'cheetah', 0.46148822)]\n",
      "[('n03388043', 'unknown', 0.85034686)]\n",
      "[('n07248320', 'unknown', 0.149477)]\n",
      "[('n02130308', 'cheetah', 0.9053668)]\n",
      "[('n03388043', 'unknown', 0.39306715)]\n",
      "[('n03388043', 'unknown', 0.75365925)]\n",
      "[('n02415577', 'unknown', 0.24028794)]\n",
      "[('n02130308', 'cheetah', 0.903755)]\n",
      "[('n02130308', 'cheetah', 0.7507806)]\n",
      "[('n03388043', 'unknown', 0.29564327)]\n",
      "[('n03388043', 'unknown', 0.9973483)]\n",
      "[('n03042490', 'unknown', 0.25470692)]\n",
      "[('n03891251', 'unknown', 0.17601876)]\n",
      "[('n02114367', 'unknown', 0.21850225)]\n",
      "[('n02114855', 'unknown', 0.3525087)]\n",
      "[('n09246464', 'unknown', 0.23663603)]\n",
      "[('n02130308', 'cheetah', 0.94633704)]\n",
      "[('n02130308', 'cheetah', 0.8222053)]\n",
      "[('n03891251', 'unknown', 0.29800007)]\n",
      "[('n03388043', 'unknown', 0.28213075)]\n",
      "[('n04589890', 'unknown', 0.17748743)]\n",
      "[('n03788365', 'unknown', 0.8227797)]\n",
      "[('n03388043', 'unknown', 0.9643867)]\n",
      "[('n02391049', 'unknown', 0.52846944)]\n",
      "[('n02417914', 'unknown', 0.07311582)]\n",
      "[('n02130308', 'cheetah', 0.9920827)]\n",
      "[('n03388043', 'unknown', 0.71333146)]\n",
      "[('n03388043', 'unknown', 0.1943638)]\n",
      "[('n03388043', 'unknown', 0.8406177)]\n",
      "[('n03388043', 'unknown', 0.9164166)]\n",
      "[('n02130308', 'cheetah', 0.9441171)]\n",
      "[('n03388043', 'unknown', 0.9918794)]\n",
      "[('n02130308', 'cheetah', 0.582005)]\n",
      "[('n02130308', 'cheetah', 0.54611546)]\n",
      "[('n03388043', 'unknown', 0.19471578)]\n",
      "[('n03891251', 'unknown', 0.12954982)]\n",
      "[('n03388043', 'unknown', 0.49637896)]\n",
      "[('n01877812', 'unknown', 0.13237937)]\n",
      "[('n03388043', 'unknown', 0.89355695)]\n",
      "[('n02130308', 'cheetah', 0.9945024)]\n",
      "[('n03388043', 'unknown', 0.6975016)]\n",
      "[('n03788365', 'unknown', 0.49175265)]\n",
      "[('n02130308', 'cheetah', 0.97345823)]\n",
      "[('n03388043', 'unknown', 0.9801917)]\n",
      "[('n02130308', 'cheetah', 0.9206267)]\n",
      "[('n04423845', 'unknown', 0.71802616)]\n",
      "[('n02504458', 'unknown', 0.54318726)]\n",
      "[('n02130308', 'cheetah', 0.5874797)]\n",
      "[('n03388043', 'unknown', 0.6227261)]\n",
      "[('n02965783', 'unknown', 0.4303286)]\n",
      "[('n02130308', 'cheetah', 0.18746567)]\n",
      "[('n02130308', 'cheetah', 0.48599735)]\n",
      "[('n03788365', 'unknown', 0.22401454)]\n",
      "[('n03388043', 'unknown', 0.7163957)]\n",
      "[('n03388043', 'unknown', 0.7492481)]\n",
      "[('n03958227', 'unknown', 0.10617014)]\n",
      "[('n02130308', 'cheetah', 0.97350353)]\n",
      "[('n02130308', 'cheetah', 0.9980135)]\n",
      "[('n02480855', 'unknown', 0.16637138)]\n",
      "[('n03388043', 'unknown', 0.81796014)]\n",
      "[('n01855672', 'unknown', 0.2644035)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n02423022', 'unknown', 0.1889775)]\n",
      "[('n03388043', 'unknown', 0.64352185)]\n",
      "[('n03788365', 'unknown', 0.86886436)]\n",
      "[('n03388043', 'unknown', 0.4929051)]\n",
      "[('n02130308', 'cheetah', 0.99204105)]\n",
      "[('n04589890', 'unknown', 0.19430083)]\n",
      "[('n03388043', 'unknown', 0.9125776)]\n",
      "[('n02110341', 'unknown', 0.104983896)]\n",
      "[('n04371774', 'unknown', 0.17962627)]\n",
      "[('n02130308', 'cheetah', 0.97166765)]\n",
      "[('n02110341', 'unknown', 0.939961)]\n",
      "[('n03498962', 'unknown', 0.08375412)]\n",
      "[('n02130308', 'cheetah', 0.9659305)]\n",
      "[('n03891251', 'unknown', 0.08400569)]\n",
      "[('n02130308', 'cheetah', 0.9032757)]\n",
      "[('n03743016', 'unknown', 0.22741283)]\n",
      "[('n03388043', 'unknown', 0.3474213)]\n",
      "[('n02437616', 'unknown', 0.42894307)]\n",
      "[('n02965783', 'unknown', 0.25510183)]\n",
      "[('n02504013', 'unknown', 0.08797813)]\n",
      "[('n03388043', 'unknown', 0.9988194)]\n",
      "[('n03388043', 'unknown', 0.22233868)]\n",
      "[('n03388043', 'unknown', 0.49637896)]\n",
      "[('n02130308', 'cheetah', 0.93314314)]\n",
      "[('n02130308', 'cheetah', 0.7831782)]\n",
      "[('n03788365', 'unknown', 0.56158733)]\n",
      "[('n02130308', 'cheetah', 0.9836474)]\n",
      "[('n03388043', 'unknown', 0.9820342)]\n",
      "[('n03388043', 'unknown', 0.21135794)]\n",
      "[('n02130308', 'cheetah', 0.9528929)]\n",
      "[('n02130308', 'cheetah', 0.68013906)]\n",
      "[('n02130308', 'cheetah', 0.9945024)]\n",
      "[('n02130308', 'cheetah', 0.9700154)]\n",
      "[('n03042490', 'unknown', 0.19041564)]\n",
      "[('n02504013', 'unknown', 0.25328785)]\n",
      "[('n03388043', 'unknown', 0.71640795)]\n",
      "[('n02130308', 'cheetah', 0.7736311)]\n",
      "[('n03388043', 'unknown', 0.43174177)]\n",
      "[('n03388043', 'unknown', 0.83618623)]\n",
      "[('n03388043', 'unknown', 0.7796511)]\n",
      "[('n03891251', 'unknown', 0.68136907)]\n",
      "[('n03388043', 'unknown', 0.33398896)]\n",
      "[('n02504013', 'unknown', 0.4654535)]\n",
      "[('n03388043', 'unknown', 0.5790054)]\n",
      "[('n07248320', 'unknown', 0.2080608)]\n",
      "[('n02346627', 'unknown', 0.09624559)]\n",
      "[('n03388043', 'unknown', 0.66047144)]\n",
      "[('n03388043', 'unknown', 0.16026351)]\n",
      "[('n02130308', 'cheetah', 0.9997607)]\n",
      "[('n03388043', 'unknown', 0.71435875)]\n",
      "[('n04371774', 'unknown', 0.16992536)]\n",
      "[('n03388043', 'unknown', 0.53411275)]\n",
      "[('n03388043', 'unknown', 0.89355695)]\n",
      "[('n02410509', 'unknown', 0.23474261)]\n",
      "[('n03388043', 'unknown', 0.95038164)]\n",
      "[('n03388043', 'unknown', 0.6779015)]\n",
      "[('n02965783', 'unknown', 0.44614094)]\n",
      "[('n07248320', 'unknown', 0.23245472)]\n"
     ]
    }
   ],
   "source": [
    "for img in pred:\n",
    "    if img[0][1] not in izw_classes:\n",
    "        img[0] = (img[0][0],'unknown',img[0][2])\n",
    "\n",
    "for img in pred:\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "Das vortrainierte Netzwerk kann nun mit unseren Daten weitertrainiert werden. Ersetze dafür das letzte Layer in dem Netzwerk mit einem Dense Layer mit 3 Ausgaben für unsere Klassen cheetah, leopard und unknown. Du kannst selbst entscheiden, ob du nun das komplette Netzwerk mit trainierst oder nur das neu eingefügte, letzte Layer.\n",
    "\n",
    "Auch hierfür kannst du dich wieder an der keras Anleitung orientieren: https://keras.io/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x1346e3438>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x10a90f550>\n",
      "<keras.layers.convolutional.Conv2D object at 0x10a90f4a8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1346bc748>\n",
      "<keras.layers.core.Activation object at 0x109dfad68>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x109dfa7f0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x13624a5f8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1346e3be0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1363011d0>\n",
      "<keras.layers.core.Activation object at 0x136301b00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1359bdf28>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136338b70>\n",
      "<keras.layers.core.Activation object at 0x1359e3ef0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x135a848d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x135ae33c8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x135b0eac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x135b97908>\n",
      "<keras.layers.merge.Add object at 0x135c5ec18>\n",
      "<keras.layers.core.Activation object at 0x135c77b70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x135c77898>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1354513c8>\n",
      "<keras.layers.core.Activation object at 0x135451278>\n",
      "<keras.layers.convolutional.Conv2D object at 0x135481c18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x135522630>\n",
      "<keras.layers.core.Activation object at 0x135538be0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x135566f28>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x135d59c88>\n",
      "<keras.layers.merge.Add object at 0x135daa278>\n",
      "<keras.layers.core.Activation object at 0x135dc4ac8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x135dc4898>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x135e937b8>\n",
      "<keras.layers.core.Activation object at 0x135e93710>\n",
      "<keras.layers.convolutional.Conv2D object at 0x135f11e48>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x135ef3358>\n",
      "<keras.layers.core.Activation object at 0x135f8ac50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1363c64a8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1363859b0>\n",
      "<keras.layers.merge.Add object at 0x1364375f8>\n",
      "<keras.layers.core.Activation object at 0x13645fef0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13645ff98>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13665cc18>\n",
      "<keras.layers.core.Activation object at 0x13665cbe0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1366ab7f0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1367242b0>\n",
      "<keras.layers.core.Activation object at 0x1367824e0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1367b9b38>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13686bb00>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136857588>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1369123c8>\n",
      "<keras.layers.merge.Add object at 0x136943b70>\n",
      "<keras.layers.core.Activation object at 0x1369af7b8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1369afcc0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136a8c438>\n",
      "<keras.layers.core.Activation object at 0x136a8c390>\n",
      "<keras.layers.convolutional.Conv2D object at 0x136ac2d30>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136b63438>\n",
      "<keras.layers.core.Activation object at 0x136b72780>\n",
      "<keras.layers.convolutional.Conv2D object at 0x136ba1400>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136499da0>\n",
      "<keras.layers.merge.Add object at 0x1364bef28>\n",
      "<keras.layers.core.Activation object at 0x136505c88>\n",
      "<keras.layers.convolutional.Conv2D object at 0x136505be0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136d048d0>\n",
      "<keras.layers.core.Activation object at 0x136d04588>\n",
      "<keras.layers.convolutional.Conv2D object at 0x136d31e80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136d66710>\n",
      "<keras.layers.core.Activation object at 0x136dfcd68>\n",
      "<keras.layers.convolutional.Conv2D object at 0x136e43d68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x136efb240>\n",
      "<keras.layers.merge.Add object at 0x136f0f7b8>\n",
      "<keras.layers.core.Activation object at 0x136f3def0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x136f3db38>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x137004d68>\n",
      "<keras.layers.core.Activation object at 0x137004cc0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x137055908>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x137107320>\n",
      "<keras.layers.core.Activation object at 0x13712d5f8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13719bac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13717cf60>\n",
      "<keras.layers.merge.Add object at 0x137217b70>\n",
      "<keras.layers.core.Activation object at 0x137242eb8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x137242e48>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13733a278>\n",
      "<keras.layers.core.Activation object at 0x13733a128>\n",
      "<keras.layers.convolutional.Conv2D object at 0x137354c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13740d4a8>\n",
      "<keras.layers.core.Activation object at 0x137423a58>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13749ff28>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13751af60>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1374859b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1375daac8>\n",
      "<keras.layers.merge.Add object at 0x13765dd68>\n",
      "<keras.layers.core.Activation object at 0x13762ccf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13762cd30>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x137747630>\n",
      "<keras.layers.core.Activation object at 0x137747588>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1377c5da0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1377a7208>\n",
      "<keras.layers.core.Activation object at 0x13783ee48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x137890860>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1379042e8>\n",
      "<keras.layers.merge.Add object at 0x137967550>\n",
      "<keras.layers.core.Activation object at 0x13799abe0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1379b8f98>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x137a78128>\n",
      "<keras.layers.core.Activation object at 0x137a78160>\n",
      "<keras.layers.convolutional.Conv2D object at 0x137a93fd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x137b4d400>\n",
      "<keras.layers.core.Activation object at 0x137b5f9b0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139280dd8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x139265908>\n",
      "<keras.layers.merge.Add object at 0x1392f7f98>\n",
      "<keras.layers.core.Activation object at 0x13934ab00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13934ae48>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13940fba8>\n",
      "<keras.layers.core.Activation object at 0x13940f860>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1394ad278>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13948ae10>\n",
      "<keras.layers.core.Activation object at 0x1395333c8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13954ddd8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13964e5c0>\n",
      "<keras.layers.merge.Add object at 0x139664a90>\n",
      "<keras.layers.core.Activation object at 0x139692cc0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139692e10>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x139778668>\n",
      "<keras.layers.core.Activation object at 0x139778320>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1397a1a58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13984e940>\n",
      "<keras.layers.core.Activation object at 0x13986af60>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139912358>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x1398d4c88>\n",
      "<keras.layers.merge.Add object at 0x1399954a8>\n",
      "<keras.layers.core.Activation object at 0x1399afef0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x1399afba8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x139b401d0>\n",
      "<keras.layers.core.Activation object at 0x139b40080>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139bb27b8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x139b8efd0>\n",
      "<keras.layers.core.Activation object at 0x139c26908>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139ca4dd8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x139c896d8>\n",
      "<keras.layers.merge.Add object at 0x139d1ef98>\n",
      "<keras.layers.core.Activation object at 0x139d6fb00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139d6fe48>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x139e35ba8>\n",
      "<keras.layers.core.Activation object at 0x139e61fd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139e80748>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x139efc208>\n",
      "<keras.layers.core.Activation object at 0x139f59470>\n",
      "<keras.layers.convolutional.Conv2D object at 0x139f725c0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13a03fac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a02f518>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a0e64e0>\n",
      "<keras.layers.merge.Add object at 0x13a115e10>\n",
      "<keras.layers.core.Activation object at 0x13a17fcc0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13a17fa90>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a247fd0>\n",
      "<keras.layers.core.Activation object at 0x13a280278>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13a296eb8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a352358>\n",
      "<keras.layers.core.Activation object at 0x13a35f908>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13a3e2d30>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a3c5860>\n",
      "<keras.layers.merge.Add object at 0x13a45ce80>\n",
      "<keras.layers.core.Activation object at 0x13a4aaa58>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13a4aada0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a56db00>\n",
      "<keras.layers.core.Activation object at 0x13a56d7b8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13a59ff60>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a690320>\n",
      "<keras.layers.core.Activation object at 0x13a636748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x13a6adc18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x13a768518>\n",
      "<keras.layers.merge.Add object at 0x13a77c9e8>\n",
      "<keras.layers.core.Activation object at 0x13a7a8d68>\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x13a7a8b38>\n",
      "<keras.layers.core.Dense object at 0x13a7de278>\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x13a7a8b38>\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: avg_pool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-04ed36e7765a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutbound_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moutput3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: avg_pool"
     ]
    }
   ],
   "source": [
    "for layer in model2.layers:\n",
    "    layer.trainable = False\n",
    "    print(layer)\n",
    "model2.layers.pop()\n",
    "print(model2.layers.pop())\n",
    "model2.layers.pop()\n",
    "model2.summary()\n",
    "\n",
    "model2.layers[-1].outbound_nodes = []\n",
    "model2.outputs = [model2.layers[-1].output]\n",
    "output1 = model2.get_layer('avg_pool').output\n",
    "output2 = Flatten()(output2)\n",
    "output3 = Dense(output_dim=3)(output3)\n",
    "model3 = Model(model2.input,output3)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluiere das so trainierte Netzwerk wie in den letzten beiden Aufgaben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f41c22e9174b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#WARUM FUNKTIONIERT DAS SO NICHT? :-(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistory2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history2 = model3.fit_generator(train_gen, steps_per_epoch=100, nb_epoch=nb_epoch, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung\n",
    "\n",
    "Beschreibe kurz qualitativ die Resultate. Wie unterscheiden sich die trainierten Netzwerke, zum Beispiel im Bezug auf die Genauigkeit oder die Laufzeit? Welche Entscheidungen musstest du bei der Erfüllung der Aufgaben treffen und warum hast du dich für den von dir gewählten Weg entschieden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
